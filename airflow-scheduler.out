[[34m2024-07-18T07:03:48.316+0530[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2024-07-18T07:03:48.318+0530[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: LocalExecutor[0m
[[34m2024-07-18T07:03:48.364+0530[0m] {[34mscheduler_job_runner.py:[0m796} INFO[0m - Starting the scheduler[0m
[[34m2024-07-18T07:03:48.365+0530[0m] {[34mscheduler_job_runner.py:[0m803} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-07-18T07:03:48.554+0530[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 3891[0m
[[34m2024-07-18T07:03:48.556+0530[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-18T07:03:48.563+0530[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2024-07-18T07:03:48.591+0530[0m] {[34mscheduler_job_runner.py:[0m1618} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2024-07-18T07:03:48.619+0530[0m] {[34mscheduler_job_runner.py:[0m1654} INFO[0m - Reset the following 15 orphaned TaskInstances:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [running]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [running]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>[0m
[[34m2024-07-18T07:03:48.906+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 16 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:48.907+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.908+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 1/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.908+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 2/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.909+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 3/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.910+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 4/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.911+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 5/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.912+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 6/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.912+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 7/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.913+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 8/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.913+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 9/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.913+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 10/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.914+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.914+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.914+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.914+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.915+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:48.915+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:48.921+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.922+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.923+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.924+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.924+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.924+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.924+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.925+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.925+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.925+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.925+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.926+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.926+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.926+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.926+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.927+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.927+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.927+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.927+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.928+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.928+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.928+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.928+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.928+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.929+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.929+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.929+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.929+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.930+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.930+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.930+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:48.930+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.934+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.935+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.935+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.936+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.936+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.937+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.939+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.939+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.942+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.942+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.944+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.947+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.947+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.951+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.952+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:48.953+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:49.016+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.012+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.016+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.020+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.017+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.022+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.036+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.048+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.051+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.054+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.072+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.084+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.110+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.112+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.116+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.128+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:49.363+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:49.398+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:49.399+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:49.399+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:49.399+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:49.399+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:49.400+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:49.400+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:49.400+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:50.753+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:50.758+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:50.759+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:50.760+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:50.760+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:50.761+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:50.761+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:50.762+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:50.771+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:51.103+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.157+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.275+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.373+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.424+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.536+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.540+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.588+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.603+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.607+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.615+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.680+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.748+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.765+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.774+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:51.904+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.956+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.964+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.969+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:51.997+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.052+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.126+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:52.140+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:52.140+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:52.141+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:52.141+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:52.142+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:52.146+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:52.147+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:52.147+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:52.148+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:52.267+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.367+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:52.528+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.538+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:52.736+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.731+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:52.768+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:52.835+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:52.885+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:52.930+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:52.977+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:52.963+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.147+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:53.159+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:53.213+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.218+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.234+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.395+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.418+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.506+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.552+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 12 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:53.552+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 5/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.553+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 6/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.553+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 7/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.566+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 8/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.566+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 9/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.567+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 10/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.570+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.571+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.571+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.571+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.572+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.572+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.572+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:53.573+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:53.575+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.591+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:53.592+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.592+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:53.593+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.593+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:03:53.593+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.597+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.597+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.601+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.602+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.602+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.603+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.603+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.604+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.604+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.605+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.605+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.606+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.606+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.607+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.608+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:53.608+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.612+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.615+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.617+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.617+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.620+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.620+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.623+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.624+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.623+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.624+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.625+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.624+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.625+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.626+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.626+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.627+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.630+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.634+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.635+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:03:53.635+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.636+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:53.635+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:53.665+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.178349+00:00, run_end_date=2024-07-18 01:33:53.012331+00:00, run_duration=0.833982, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2573, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4137[0m
[[34m2024-07-18T07:03:53.666+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.715452+00:00, run_end_date=2024-07-18 01:33:52.569335+00:00, run_duration=0.853883, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2571, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4113[0m
[[34m2024-07-18T07:03:53.666+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.280484+00:00, run_end_date=2024-07-18 01:33:52.752804+00:00, run_duration=0.47232, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2576, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4141[0m
[[34m2024-07-18T07:03:53.667+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.363237+00:00, run_end_date=2024-07-18 01:33:53.256591+00:00, run_duration=0.893354, state=success, executor_state=failed, try_number=2, max_tries=1, job_id=2578, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4148[0m
[[34m2024-07-18T07:03:53.667+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.623242+00:00, run_end_date=2024-07-18 01:33:53.386218+00:00, run_duration=0.762976, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2580, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4159[0m
[[34m2024-07-18T07:03:53.668+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.221443+00:00, run_end_date=2024-07-18 01:33:52.981402+00:00, run_duration=0.759959, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2575, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4138[0m
[[34m2024-07-18T07:03:53.668+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.429495+00:00, run_end_date=2024-07-18 01:33:53.065000+00:00, run_duration=0.635505, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2577, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4156[0m
[[34m2024-07-18T07:03:53.669+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.911441+00:00, run_end_date=2024-07-18 01:33:52.661656+00:00, run_duration=0.750215, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2572, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4126[0m
[[34m2024-07-18T07:03:53.669+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.660445+00:00, run_end_date=2024-07-18 01:33:52.625014+00:00, run_duration=0.964569, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2570, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4119[0m
[[34m2024-07-18T07:03:53.672+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.670+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.338197+00:00, run_end_date=2024-07-18 01:33:53.200699+00:00, run_duration=0.862502, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2574, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4147[0m
[[34m2024-07-18T07:03:53.679+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.523519+00:00, run_end_date=2024-07-18 01:33:53.327690+00:00, run_duration=0.804171, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2579, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4158[0m
[[34m2024-07-18T07:03:53.726+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.748+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.765+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.786+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.788+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.798+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.784+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.796+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.811+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.828+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:53.895+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:53.968+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:53.968+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.969+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.969+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.969+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:53.970+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.970+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:53.998+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:53.999+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:53.999+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:54.014+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:54.015+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:54.015+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:54.015+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:54.051+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:54.050+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:54.068+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:54.035+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:54.075+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.118931+00:00, run_end_date=2024-07-18 01:33:53.657028+00:00, run_duration=0.538097, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2582, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4170[0m
[[34m2024-07-18T07:03:54.148+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:54.239+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:54.392+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:54.392+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:54.392+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:54.392+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:54.393+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:54.393+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:54.393+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:54.393+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:54.393+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:54.414+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:54.433+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.052748+00:00, run_end_date=2024-07-18 01:33:53.812855+00:00, run_duration=0.760107, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2581, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4169[0m
[[34m2024-07-18T07:03:54.547+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:54.569+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:54.657+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:55.533+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:55.558+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:55.649+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:55.650+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.650+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.651+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.651+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.652+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.652+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.653+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.653+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.654+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.654+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.655+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.655+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:55.660+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:55.661+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.662+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:55.663+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.663+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:55.664+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.673+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:55.674+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:55.675+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:03:55.679+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.683+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.683+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:55.685+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.360249+00:00, run_end_date=2024-07-18 01:33:54.435911+00:00, run_duration=1.07566, state=success, executor_state=failed, try_number=2, max_tries=1, job_id=2583, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4220[0m
[[34m2024-07-18T07:03:55.686+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.398163+00:00, run_end_date=2024-07-18 01:33:54.402660+00:00, run_duration=1.0045, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2584, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4198[0m
[[34m2024-07-18T07:03:55.687+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.397320+00:00, run_end_date=2024-07-18 01:33:54.371660+00:00, run_duration=0.97434, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2585, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4199[0m
[[34m2024-07-18T07:03:55.791+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:55.814+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:55.820+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:55.824+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:55.892+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:55.893+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.893+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.894+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.894+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.902+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.903+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.903+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:55.904+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:55.928+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:55.949+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.096+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.140+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.149+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.169+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.179+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.197+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.218+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.252+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.343+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.371+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.456+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.467+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.467+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.485+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.532+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.541+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.595+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.708+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:56.823+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:56.842+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:57.039+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.040+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.040+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.040+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.041+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.041+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.042+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.042+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.054+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.071+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:57.071+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.082+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.172+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.229+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:57.260+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.260+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.261+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.261+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.261+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.264+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:57.262+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.266+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.267+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.267+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.268+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.268+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.277+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:57.278+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.281+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.285+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.292+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.284446+00:00, run_end_date=2024-07-18 01:33:56.947047+00:00, run_duration=0.662601, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2586, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4453[0m
[[34m2024-07-18T07:03:57.271+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.420+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:57.499+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.564+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.564+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.565+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.565+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.565+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.566+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.566+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.575+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.575+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.577+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:57.584+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:57.584+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.585+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:57.585+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.585+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:57.586+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.604+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.620+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.624+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.603+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.628+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.629+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.647+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.533262+00:00, run_end_date=2024-07-18 01:33:57.297474+00:00, run_duration=0.764212, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2589, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4455[0m
[[34m2024-07-18T07:03:57.648+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.395458+00:00, run_end_date=2024-07-18 01:33:57.030894+00:00, run_duration=0.635436, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2587, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4454[0m
[[34m2024-07-18T07:03:57.628+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.699+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:57.696+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:57.682+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.796+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:57.845+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.888+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.888+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.889+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.889+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.889+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.890+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.890+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.898+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.899+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.899+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:57.899+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:57.900+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:57.856+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:57.924+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:03:57.924+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.924+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:03:57.925+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.938+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:57.954+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.959+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.959+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.960+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:57.964+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:57.978+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.598704+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=1, job_id=2588, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4456[0m
[[34m2024-07-18T07:03:57.979+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.780295+00:00, run_end_date=2024-07-18 01:33:57.394653+00:00, run_duration=0.614358, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2594, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4466[0m
[[34m2024-07-18T07:03:57.979+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.720978+00:00, run_end_date=2024-07-18 01:33:57.435938+00:00, run_duration=0.71496, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2590, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:54.000110+00:00, queued_by_job_id=2569, pid=4459[0m
[[34m2024-07-18T07:03:58.039+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.051+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:58.063+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:58.105+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:58.100+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.205+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.205+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.206+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.206+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.206+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.207+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.207+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.207+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.208+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.208+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.208+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.225+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:58.226+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.226+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:03:58.226+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.227+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:03:58.227+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.238+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.242+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.243+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.243+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.242+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.243+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.250+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.258+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:58.260+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.894438+00:00, run_end_date=2024-07-18 01:33:57.640639+00:00, run_duration=0.746201, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2593, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4482[0m
[[34m2024-07-18T07:03:58.261+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.855847+00:00, run_end_date=2024-07-18 01:33:57.625575+00:00, run_duration=0.769728, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2591, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4480[0m
[[34m2024-07-18T07:03:58.261+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.866844+00:00, run_end_date=2024-07-18 01:33:57.876966+00:00, run_duration=1.01012, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2595, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4481[0m
[[34m2024-07-18T07:03:58.262+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.828746+00:00, run_end_date=2024-07-18 01:33:57.813133+00:00, run_duration=0.984387, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2592, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4472[0m
[[34m2024-07-18T07:03:58.300+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:58.286+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:58.328+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.344+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.367+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.484+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.484+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.484+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.485+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.485+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.485+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.486+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.486+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.486+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.486+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.487+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.492+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:03:58.492+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.497+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.505+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.981430+00:00, run_end_date=2024-07-18 01:33:58.085032+00:00, run_duration=1.1036, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2596, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:54.000110+00:00, queued_by_job_id=2569, pid=4484[0m
[[34m2024-07-18T07:03:58.479+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:58.515+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.632+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.633+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.633+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.633+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.634+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.634+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.634+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.635+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.635+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.643+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:03:58.644+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.647+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:03:58.685+0530[0m] {[34mscheduler_job_runner.py:[0m1722} WARNING[0m - Failing (1) jobs without heartbeat after 2024-07-18 01:28:58.661441+00:00[0m
[[34m2024-07-18T07:03:58.686+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Detected zombie job: {'full_filepath': '//home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py', 'processor_subdir': '/home/kali/Desktop/projects/git/bank_data_processing/dags', 'msg': "{'DAG Id': 'parent_dag', 'Task Id': 'raw_load_bill_payments.tuncate_table', 'Run Id': 'manual__2024-07-18T01:28:18.110991+00:00', 'Hostname': 'kali'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fde483e4490>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)[0m
[[34m2024-07-18T07:03:58.671+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:58.691+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:58.692+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.707+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:03:58.904+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:03:58.904+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.904+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.905+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.905+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.905+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.905+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.906+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:03:58.906+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:03:58.908+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.908+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:03:58.913+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:57.330601+00:00, run_end_date=2024-07-18 01:33:58.305743+00:00, run_duration=0.975142, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2597, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4500[0m
[[34m2024-07-18T07:03:58.913+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:57.772257+00:00, run_end_date=2024-07-18 01:33:58.543220+00:00, run_duration=0.770963, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2598, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4540[0m
[[34m2024-07-18T07:03:59.013+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:03:59.227+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:03:59.492+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:03:59.707+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:00.055+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.062+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.100+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.089+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:00.192+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:00.193+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.194+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.195+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.195+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.210+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.211+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.211+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.211+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.212+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.212+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.212+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.213+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:00.227+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:00.227+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.228+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:00.228+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.228+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:00.229+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.230+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.243+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.252+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.254+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.258+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:00.259+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:00.259+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:00.274+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:58.751210+00:00, run_end_date=2024-07-18 01:33:59.455792+00:00, run_duration=0.704582, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2600, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4605[0m
[[34m2024-07-18T07:04:00.275+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:59.022597+00:00, run_end_date=2024-07-18 01:33:59.888286+00:00, run_duration=0.865689, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2601, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4631[0m
[[34m2024-07-18T07:04:00.275+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:58.488991+00:00, run_end_date=2024-07-18 01:33:59.319389+00:00, run_duration=0.830398, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2599, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4603[0m
[[34m2024-07-18T07:04:00.312+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.317+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.387+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.379+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:00.391+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:00.428+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:00.444+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.464+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.476+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:00.477+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.477+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.478+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.478+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.482+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.483+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.483+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.484+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.484+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.484+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:00.492+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:00.492+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.503+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:00.560+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.539+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:00.603+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.635+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:00.673+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:00.679+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.679+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:00.681+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:00.780+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.791+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:00.867+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.914+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:00.983+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:01.188+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:01.216+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:01.233+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:01.278+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:01.459+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:01.737+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:01.829+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:01.830+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:01.830+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:01.831+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:01.831+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:01.832+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:01.832+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:01.832+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:01.833+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:01.852+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:01.853+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:01.859+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:01.867+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:01.881+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:59.551010+00:00, run_end_date=2024-07-18 01:34:00.347025+00:00, run_duration=0.796015, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2602, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.055542+00:00, queued_by_job_id=2569, pid=4687[0m
[[34m2024-07-18T07:04:01.935+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:01.964+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:02.000+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:02.045+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:02.130+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:02.240+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.240+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.241+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.241+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.241+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.242+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.242+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.243+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.244+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.244+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.251+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:02.252+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.253+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:02.254+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.260+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:02.260+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.262+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.276+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.949711+00:00, run_end_date=2024-07-18 01:34:01.780446+00:00, run_duration=0.830735, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2605, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4756[0m
[[34m2024-07-18T07:04:02.356+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:02.386+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:02.359+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:02.415+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:02.452+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:02.659+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET last_scheduling_decision=%(last_scheduling_decision)s, updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'last_scheduling_decision': datetime.datetime(2024, 7, 18, 1, 34, 1, 750070), 'updated_at': datetime.datetime(2024, 7, 18, 1, 34, 1, 777636), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET last_scheduling_decision=%(last_scheduling_decision)s, updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'last_scheduling_decision': datetime.datetime(2024, 7, 18, 1, 34, 1, 750070), 'updated_at': datetime.datetime(2024, 7, 18, 1, 34, 1, 777636), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:04:02.744+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.744+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.745+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.745+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.745+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.746+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.746+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.746+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.747+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.755+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:02.756+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.762+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:02.763+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:02.770+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.780+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.870962+00:00, run_end_date=2024-07-18 01:34:01.912204+00:00, run_duration=1.04124, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2604, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.274781+00:00, queued_by_job_id=2569, pid=4755[0m
[[34m2024-07-18T07:04:02.780+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.258272+00:00, run_end_date=2024-07-18 01:34:02.151095+00:00, run_duration=0.892823, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2608, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4759[0m
[[34m2024-07-18T07:04:02.752+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'updated_at': datetime.datetime(2024, 7, 18, 1, 33, 58, 456968), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'updated_at': datetime.datetime(2024, 7, 18, 1, 33, 58, 456968), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:04:02.867+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:02.955+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:02.972+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.973+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.973+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.973+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:04:02.974+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:04:02.974+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:02.984+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:02.985+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.985+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:02.986+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.989+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.995+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:02.999+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.000+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.012+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=None[0m
[[34m2024-07-18T07:04:03.012+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:04:02.995+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:03.033+0530[0m] {[34mtaskinstance.py:[0m2907} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:04:03.088+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:03.106+0530[0m] {[34mtaskinstance.py:[0m1206} INFO[0m - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=, end_date=20240718T013403[0m
[[34m2024-07-18T07:04:03.127+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:03.129+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:04:03.184+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=None[0m
[[34m2024-07-18T07:04:03.185+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:04:03.210+0530[0m] {[34mtaskinstance.py:[0m2907} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:04:03.241+0530[0m] {[34mtaskinstance.py:[0m1206} INFO[0m - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=, end_date=20240718T013403[0m
[[34m2024-07-18T07:04:03.517+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:03.659+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:03.719+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:03.847+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:03.889+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:03.921+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:03.926+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:03.926+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:04:03.927+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:04:03.927+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:04:03.927+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:04:03.936+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:03.936+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.936+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:03.937+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.937+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:04:03.937+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.940+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.943+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.946+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:04:03.948+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.948+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.948+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.949+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.949+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:03.968+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.619264+00:00, run_end_date=2024-07-18 01:34:03.308959+00:00, run_duration=1.6897, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.901182+00:00, queued_by_job_id=2569, pid=4776[0m
[[34m2024-07-18T07:04:03.968+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.636648+00:00, run_end_date=2024-07-18 01:34:02.894218+00:00, run_duration=2.25757, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2603, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4746[0m
[[34m2024-07-18T07:04:03.969+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.601360+00:00, run_end_date=2024-07-18 01:34:02.858226+00:00, run_duration=1.25687, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2611, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4773[0m
[[34m2024-07-18T07:04:03.969+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.571884+00:00, run_end_date=2024-07-18 01:34:02.857335+00:00, run_duration=1.28545, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2610, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4769[0m
[[34m2024-07-18T07:04:03.970+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.545275+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=1, job_id=2609, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4765[0m
[[34m2024-07-18T07:04:04.020+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:04.076+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:04.096+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:04:04.572+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:04.903+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:04.915+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:05.276+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:05.300+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.373+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:05.395+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.033834+00:00, run_end_date=2024-07-18 01:34:04.294343+00:00, run_duration=3.26051, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2606, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.487932+00:00, queued_by_job_id=2569, pid=4757[0m
[[34m2024-07-18T07:04:05.627+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.671+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:05.684+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.700+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.814+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.822+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:05.857+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:04:05.876+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:05.934+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:06.057+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:06.064+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:04:06.625+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:06.626+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:06.641+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:02.203657+00:00, run_end_date=2024-07-18 01:34:05.269942+00:00, run_duration=3.06628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2613, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.636129+00:00, queued_by_job_id=2569, pid=4816[0m
[[34m2024-07-18T07:04:06.642+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.076042+00:00, run_end_date=2024-07-18 01:34:05.621482+00:00, run_duration=1.54544, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2616, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:01.834022+00:00, queued_by_job_id=2569, pid=4935[0m
[[34m2024-07-18T07:04:07.771+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.771+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.772+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.772+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.772+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.772+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.772+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.773+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.773+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:07.779+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.977032+00:00, run_end_date=2024-07-18 01:34:07.467875+00:00, run_duration=6.49084, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2607, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.901182+00:00, queued_by_job_id=2569, pid=4758[0m
[[34m2024-07-18T07:04:07.779+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.178537+00:00, run_end_date=2024-07-18 01:34:06.993625+00:00, run_duration=2.81509, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2617, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=4943[0m
[[34m2024-07-18T07:04:07.779+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.273797+00:00, run_end_date=2024-07-18 01:34:06.343563+00:00, run_duration=2.06977, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2618, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.485829+00:00, queued_by_job_id=2569, pid=4951[0m
[[34m2024-07-18T07:04:07.780+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.342433+00:00, run_end_date=2024-07-18 01:34:06.606533+00:00, run_duration=1.2641, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2619, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.245463+00:00, queued_by_job_id=2569, pid=5006[0m
[[34m2024-07-18T07:04:07.780+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.752867+00:00, run_end_date=2024-07-18 01:34:07.026116+00:00, run_duration=1.27325, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2620, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.245463+00:00, queued_by_job_id=2569, pid=5015[0m
[[34m2024-07-18T07:04:07.780+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.059850+00:00, run_end_date=2024-07-18 01:34:07.409916+00:00, run_duration=1.35007, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2622, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.748200+00:00, queued_by_job_id=2569, pid=5021[0m
[[34m2024-07-18T07:04:07.781+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.100271+00:00, run_end_date=2024-07-18 01:34:07.314235+00:00, run_duration=1.21396, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2623, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.975676+00:00, queued_by_job_id=2569, pid=5022[0m
[[34m2024-07-18T07:04:07.781+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.913053+00:00, run_end_date=2024-07-18 01:34:07.137610+00:00, run_duration=1.22456, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2621, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.975676+00:00, queued_by_job_id=2569, pid=5018[0m
[[34m2024-07-18T07:04:07.781+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.357740+00:00, run_end_date=2024-07-18 01:34:07.458216+00:00, run_duration=1.10048, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2626, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5040[0m
[[34m2024-07-18T07:04:08.796+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:08.803+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.294182+00:00, run_end_date=2024-07-18 01:34:07.663677+00:00, run_duration=1.3695, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2624, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5039[0m
[[34m2024-07-18T07:04:08.825+0530[0m] {[34mscheduler_job_runner.py:[0m1722} WARNING[0m - Failing (1) jobs without heartbeat after 2024-07-18 01:29:08.819813+00:00[0m
[[34m2024-07-18T07:04:08.826+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Detected zombie job: {'full_filepath': '//home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py', 'processor_subdir': '/home/kali/Desktop/projects/git/bank_data_processing/dags', 'msg': "{'DAG Id': 'parent_dag', 'Task Id': 'raw_load_service_charges.tuncate_table', 'Run Id': 'manual__2024-07-18T01:28:18.110991+00:00', 'Hostname': 'kali'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fde4587dc50>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)[0m
[[34m2024-07-18T07:04:12.339+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:04:12.342+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.225213+00:00, run_end_date=2024-07-18 01:34:11.234802+00:00, run_duration=5.00959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2625, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5026[0m
[[34m2024-07-18T07:05:27.597+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:27.598+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:27.598+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:27.601+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:27.601+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:27.604+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:27.637+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:28.247+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:28.325+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:28.771+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:29.506+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:29.507+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:29.507+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:29.509+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:29.509+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:29.514+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:29.513+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:29.520+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:28.438019+00:00, run_end_date=2024-07-18 01:35:28.707653+00:00, run_duration=0.269634, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2627, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:27.599412+00:00, queued_by_job_id=2569, pid=7494[0m
[[34m2024-07-18T07:05:29.544+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:30.266+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:30.376+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:30.802+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:31.572+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:31.572+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:31.573+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:31.575+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:05:31.575+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:31.581+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:31.580+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:31.588+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:30.508168+00:00, run_end_date=2024-07-18 01:35:30.741804+00:00, run_duration=0.233636, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2628, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:29.507864+00:00, queued_by_job_id=2569, pid=7531[0m
[[34m2024-07-18T07:05:31.623+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:32.375+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:32.453+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:33.852+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:33.856+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:32.574242+00:00, run_end_date=2024-07-18 01:35:33.088071+00:00, run_duration=0.513829, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2629, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:31.573588+00:00, queued_by_job_id=2569, pid=7592[0m
[[34m2024-07-18T07:05:38.889+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:38.889+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:38.889+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:38.892+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:38.892+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:38.897+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:38.935+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:39.737+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:39.811+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:40.429+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:40.640+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:40.641+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:40.641+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:40.646+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:40.647+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:40.650+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:05:40.650+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:40.654+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:39.954491+00:00, run_end_date=2024-07-18 01:35:40.331535+00:00, run_duration=0.377044, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2630, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:38.890322+00:00, queued_by_job_id=2569, pid=7808[0m
[[34m2024-07-18T07:05:40.687+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:41.820+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:41.958+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:42.582+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:42.919+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:42.919+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:42.919+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:42.922+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:05:42.923+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:42.928+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:05:42.927+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:42.937+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:42.160060+00:00, run_end_date=2024-07-18 01:35:42.487688+00:00, run_duration=0.327628, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2631, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:40.642643+00:00, queued_by_job_id=2569, pid=7879[0m
[[34m2024-07-18T07:05:42.964+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:43.763+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:43.851+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:44.144+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 35, 44, 25148), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 3, 'job_id': '2632', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 35, 44, 114673), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_atms.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 35, 44, 25148), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 3, 'job_id': '2632', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 35, 44, 114673), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_atms.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:05:45.280+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 16 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:45.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 1/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 2/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 3/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 4/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 5/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 6/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 7/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 8/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.283+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 9/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.283+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 10/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.283+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.283+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.283+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.284+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.284+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.284+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:45.288+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.288+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.288+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.289+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.289+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.289+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.290+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.290+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.290+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.290+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.291+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.291+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.293+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.293+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.294+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.294+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.295+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.295+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.296+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.296+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.296+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.297+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.297+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.298+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.298+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.298+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.299+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.299+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.299+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.300+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.300+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:45.300+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.303+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.304+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.304+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.304+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.304+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.305+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.304+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.310+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.319+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.325+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.328+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.330+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.342+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.350+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.355+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.359+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:05:45.346+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:45.369+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.372+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.375+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.373+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.409+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:32.574242+00:00, run_end_date=2024-07-18 01:35:33.088071+00:00, run_duration=0.513829, state=None, executor_state=failed, try_number=3, max_tries=3, job_id=2629, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:42.920839+00:00, queued_by_job_id=2569, pid=7592[0m
[[34m2024-07-18T07:05:45.424+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.436+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.434+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.448+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.448+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.466+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.465+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.496+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.521+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.533+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.533+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.569+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:45.965+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:45.965+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.965+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:45.966+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.966+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:45.967+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.967+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:45.968+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:45.968+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:46.337+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:46.599+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:47.531+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:47.533+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:47.535+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:47.535+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:47.536+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:47.537+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:47.537+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:47.538+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:47.538+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:47.541+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:47.838+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:48.282+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:48.379+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:48.587+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:48.598+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:48.723+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:48.781+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:48.806+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:48.825+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.054+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:49.055+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.056+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.057+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.058+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.074+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.076+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.078+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.091+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.091+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.092+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:49.090+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:49.109+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:49.114+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:49.120+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:49.130+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:05:49.140+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.172+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:47.055549+00:00, run_end_date=2024-07-18 01:35:48.071075+00:00, run_duration=1.01553, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2633, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8125[0m
[[34m2024-07-18T07:05:49.318+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.346+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:49.348+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.359+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:49.437+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:49.585+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:49.585+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.586+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.603+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.603+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.604+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.605+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.605+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:49.606+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:49.616+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.679+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:49.787+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.835+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:49.868+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:49.901+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.013+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:50.140+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:50.231+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:50.249+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.289+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:50.271+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:50.454+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.487+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.595+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.865+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:50.887+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:50.951+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:50.952+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.952+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.953+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.953+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.954+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.954+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:50.955+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:50.955+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:50.957+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:50.966+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:50.967+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.967+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:50.968+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.968+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:05:50.969+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.969+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:50.970+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.985+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.990+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:50.991+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:50.988+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.992+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:50.986+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.023+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:48.443695+00:00, run_end_date=2024-07-18 01:35:50.018314+00:00, run_duration=1.57462, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2634, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8136[0m
[[34m2024-07-18T07:05:51.024+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.593939+00:00, run_end_date=2024-07-18 01:35:50.653568+00:00, run_duration=1.05963, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2637, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8161[0m
[[34m2024-07-18T07:05:51.032+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.092+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.114+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.122+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.117+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.144+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.334+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:51.335+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.336+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.336+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.336+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.337+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:51.337+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.338+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:51.393+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.394+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:51.395+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:51.396+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:51.397+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:51.413+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:51.414+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.415+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:51.416+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.417+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:51.417+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.431+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.347+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.373+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.447+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.451+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:51.457+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-18T07:05:51.457+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:51.533+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.481339+00:00, run_end_date=2024-07-18 01:35:50.785677+00:00, run_duration=1.30434, state=success, executor_state=failed, try_number=4, max_tries=4, job_id=2636, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8160[0m
[[34m2024-07-18T07:05:51.536+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.696465+00:00, run_end_date=2024-07-18 01:35:50.842026+00:00, run_duration=1.14556, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2638, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8162[0m
[[34m2024-07-18T07:05:51.516+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.596+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.680+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.691+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:51.813+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:51.949+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:52.321+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:52.322+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.330+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.331+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.331+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.332+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:52.363+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.367+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.319+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:52.368+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.368+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.369+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.369+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.370+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.385+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.404+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.405+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.410+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.415+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.417+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.417+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.418+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.420+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.420+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.434+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.112396+00:00, run_end_date=2024-07-18 01:35:51.005846+00:00, run_duration=0.89345, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2641, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8175[0m
[[34m2024-07-18T07:05:52.435+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.322648+00:00, run_end_date=2024-07-18 01:35:51.634011+00:00, run_duration=1.31136, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2642, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8178[0m
[[34m2024-07-18T07:05:52.436+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.369401+00:00, run_end_date=2024-07-18 01:35:50.961514+00:00, run_duration=1.59211, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2635, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8152[0m
[[34m2024-07-18T07:05:52.436+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.134000+00:00, run_end_date=2024-07-18 01:35:51.392605+00:00, run_duration=1.25861, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2643, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8176[0m
[[34m2024-07-18T07:05:52.437+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.841897+00:00, run_end_date=2024-07-18 01:35:51.009356+00:00, run_duration=1.16746, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2639, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8172[0m
[[34m2024-07-18T07:05:52.435+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:52.500+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:52.483+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:52.535+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.536+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.552+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.645+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.695+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:52.696+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.697+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.697+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.698+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.700+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.702+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.703+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.704+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.704+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.705+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.706+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:52.714+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.715+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.715+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:52.716+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.723+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.727+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:52.732+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.733+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:05:52.733+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.734+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:52.758+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.675893+00:00, run_end_date=2024-07-18 01:35:52.185215+00:00, run_duration=1.50932, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2644, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8180[0m
[[34m2024-07-18T07:05:52.761+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.857828+00:00, run_end_date=2024-07-18 01:35:52.146348+00:00, run_duration=1.28852, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2645, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8181[0m
[[34m2024-07-18T07:05:52.764+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.976925+00:00, run_end_date=2024-07-18 01:35:52.240966+00:00, run_duration=1.26404, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2646, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8191[0m
[[34m2024-07-18T07:05:52.771+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.510842+00:00, run_end_date=2024-07-18 01:35:51.999120+00:00, run_duration=1.48828, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2640, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8179[0m
[[34m2024-07-18T07:05:52.898+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.937+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:52.963+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:52.965+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.970+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.971+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.971+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.972+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.972+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.973+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:52.974+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:52.980+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:53.203+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:53.312+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:53.408+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:53.498+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:53.615+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:53.627+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:53.748+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:54.129+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:54.139+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:54.209+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:54.210+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.211+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.211+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.212+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.212+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.213+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.213+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.214+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.219+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.220+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.221+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:54.229+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:54.230+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:54.231+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:54.232+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:54.237+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:54.240+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:54.243+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:54.244+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:54.255+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:51.554350+00:00, run_end_date=2024-07-18 01:35:52.969696+00:00, run_duration=1.41535, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2648, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8235[0m
[[34m2024-07-18T07:05:54.258+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.997576+00:00, run_end_date=2024-07-18 01:35:52.885925+00:00, run_duration=1.88835, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2647, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8195[0m
[[34m2024-07-18T07:05:54.364+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:54.355+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:54.382+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:54.484+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:54.558+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:54.603+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:54.604+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.604+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.604+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.605+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.605+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.606+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.606+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:54.611+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:54.830+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:55.123+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:55.186+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:55.353+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:55.451+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:55.538+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:55.543+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:55.667+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:55.759+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:55.869+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:55.904+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:56.028+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:56.096+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:56.103+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.104+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.104+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:56.104+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.111+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.111+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.112+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.112+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.112+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.113+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.114+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.131+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:56.137+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:56.148+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.149+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:56.149+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.150+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:56.150+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.151+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:56.151+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.165+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.175+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.178+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.178+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.206+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:56.206+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:56.207+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:56.212+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:56.253+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:53.926797+00:00, run_end_date=2024-07-18 01:35:54.959595+00:00, run_duration=1.0328, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2649, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8314[0m
[[34m2024-07-18T07:05:56.262+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.072107+00:00, run_end_date=2024-07-18 01:35:55.316484+00:00, run_duration=1.24438, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2650, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:49.094268+00:00, queued_by_job_id=2569, pid=8325[0m
[[34m2024-07-18T07:05:56.263+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.555721+00:00, run_end_date=2024-07-18 01:35:55.753273+00:00, run_duration=1.19755, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2651, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8341[0m
[[34m2024-07-18T07:05:56.268+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:56.306+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:56.291+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:56.368+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:56.373+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:56.393+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:56.406+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:56.541+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:56.546+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.548+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.549+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.549+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.550+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.550+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.551+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.551+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.561+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.563+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:56.571+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:56.573+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.583+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:56.610+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:56.610+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:56.641+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.975805+00:00, run_end_date=2024-07-18 01:35:56.126223+00:00, run_duration=1.15042, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2653, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8361[0m
[[34m2024-07-18T07:05:56.650+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.864954+00:00, run_end_date=2024-07-18 01:35:55.986038+00:00, run_duration=1.12108, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2652, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8352[0m
[[34m2024-07-18T07:05:56.797+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:56.823+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:56.852+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:56.855+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.858+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.866+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.867+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.867+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.867+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:56.867+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:56.868+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:57.185+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:57.293+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:57.468+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:57.692+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:57.916+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:57.997+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:58.083+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:58.172+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 8 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:58.173+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:58.176+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.177+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.177+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.178+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.183+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.184+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.184+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.185+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.186+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.191+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.192+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.193+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:58.213+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:58.214+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.215+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:05:58.216+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.216+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:05:58.217+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.217+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:05:58.218+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.219+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:05:58.219+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.229+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.237+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.246+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.247+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.251+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:58.252+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:58.253+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:58.255+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:05:58.281+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:55.609463+00:00, run_end_date=2024-07-18 01:35:56.890268+00:00, run_duration=1.2808, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2655, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8382[0m
[[34m2024-07-18T07:05:58.282+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.307397+00:00, run_end_date=2024-07-18 01:35:57.577590+00:00, run_duration=1.27019, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2656, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.710848+00:00, queued_by_job_id=2569, pid=8396[0m
[[34m2024-07-18T07:05:58.282+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:55.737761+00:00, run_end_date=2024-07-18 01:35:56.983140+00:00, run_duration=1.24538, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2654, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8383[0m
[[34m2024-07-18T07:05:58.299+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:58.334+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:58.360+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:58.369+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:58.395+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:58.427+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:58.470+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:58.464+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:58.503+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:05:58.624+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:05:58.625+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.646+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.647+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.647+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.648+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.648+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.648+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:05:58.649+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:05:58.683+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1)[0m
[[34m2024-07-18T07:05:58.684+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:05:58.708+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:58.726+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.868757+00:00, run_end_date=2024-07-18 01:35:57.864558+00:00, run_duration=0.995801, state=success, executor_state=failed, try_number=4, max_tries=4, job_id=2657, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8436[0m
[[34m2024-07-18T07:05:58.751+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.925419+00:00, run_end_date=2024-07-18 01:35:58.102473+00:00, run_duration=1.17705, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2659, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8434[0m
[[34m2024-07-18T07:05:58.894+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:58.944+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:05:58.977+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:59.111+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:05:59.321+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:05:59.627+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:00.100+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:00.101+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.101+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.102+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.111+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.112+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.112+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.113+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.113+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.122+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.123+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:00.138+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:06:00.139+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.140+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:00.145+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:00.141+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.171+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:00.172+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.193+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.198+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.198+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.206+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:00.207+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:00.255+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:57.123101+00:00, run_end_date=2024-07-18 01:35:58.553070+00:00, run_duration=1.42997, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2658, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.710848+00:00, queued_by_job_id=2569, pid=8455[0m
[[34m2024-07-18T07:06:00.256+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:57.454807+00:00, run_end_date=2024-07-18 01:35:58.649420+00:00, run_duration=1.19461, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2660, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8457[0m
[[34m2024-07-18T07:06:00.289+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:00.401+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:00.419+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:00.613+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:00.627+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:00.680+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:00.681+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.682+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.691+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.695+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.696+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.696+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.697+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:00.698+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:00.726+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:00.738+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:00.755+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.757+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:00.758+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.784+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:00.789+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.801+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:00.837+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:58.648030+00:00, run_end_date=2024-07-18 01:35:59.911863+00:00, run_duration=1.26383, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2661, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8509[0m
[[34m2024-07-18T07:06:00.868+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:00.878+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:00.826+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:00.914+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:00.927+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:01.058+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:01.073+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:01.208+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:01.209+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.209+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.210+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.210+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.220+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.220+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.220+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.220+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.221+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.221+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.221+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:01.243+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:01.244+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:01.244+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:01.245+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:01.245+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:01.257+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:01.266+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:01.266+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:01.267+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:01.267+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:01.268+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:01.295+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:58.999001+00:00, run_end_date=2024-07-18 01:36:00.554336+00:00, run_duration=1.55534, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2663, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:54.226033+00:00, queued_by_job_id=2569, pid=8526[0m
[[34m2024-07-18T07:06:01.296+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.450707+00:00, run_end_date=2024-07-18 01:36:00.392758+00:00, run_duration=0.942051, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2664, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:54.226033+00:00, queued_by_job_id=2569, pid=8530[0m
[[34m2024-07-18T07:06:01.296+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.784327+00:00, run_end_date=2024-07-18 01:36:00.655189+00:00, run_duration=0.870862, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2665, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8531[0m
[[34m2024-07-18T07:06:01.297+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.120316+00:00, run_end_date=2024-07-18 01:36:00.406986+00:00, run_duration=1.28667, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2662, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8529[0m
[[34m2024-07-18T07:06:01.336+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:01.460+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:01.518+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:01.522+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.524+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.524+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.525+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.525+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.525+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.526+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:01.526+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:01.629+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:01.903+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:01.908+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:01.895+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:02.037+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:02.116+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:02.117+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.117+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.118+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.131+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.132+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.133+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.133+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.134+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.134+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.147+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:02.175+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:02.175+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:02.189+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:02.203+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:02.218+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:02.224+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:00.174439+00:00, run_end_date=2024-07-18 01:36:01.586077+00:00, run_duration=1.41164, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2666, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.564963+00:00, queued_by_job_id=2569, pid=8559[0m
[[34m2024-07-18T07:06:02.241+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:02.263+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:02.323+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:02.356+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:02.409+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:02.638+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:02.638+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.639+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.639+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.640+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.641+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.642+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.659+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:02.659+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:02.875+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:03.050+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:03.059+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:03.024+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:03.226+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:03.330+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:03.531+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:03.625+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:04.023+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:04.026+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.027+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.028+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.028+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.029+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.029+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.030+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.039+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.040+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.041+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.042+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:04.063+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:04.064+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.065+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:04.066+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.076+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.089+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:04.087+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.090+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:04.131+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:01.364596+00:00, run_end_date=2024-07-18 01:36:02.692225+00:00, run_duration=1.32763, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2667, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8605[0m
[[34m2024-07-18T07:06:04.132+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:01.630815+00:00, run_end_date=2024-07-18 01:36:03.018463+00:00, run_duration=1.38765, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2668, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8630[0m
[[34m2024-07-18T07:06:04.215+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:04.313+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:04.327+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:04.330+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:04.376+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:04.470+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:04.552+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:04.584+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:04.774+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:04.774+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.775+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.775+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.776+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.776+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.776+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:04.777+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:04.777+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:04.809+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:04.810+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.811+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:04.811+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.811+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:04.812+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.828+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.829+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.835+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:04.838+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:04.865+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:02.914064+00:00, run_end_date=2024-07-18 01:36:04.201233+00:00, run_duration=1.28717, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2670, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8654[0m
[[34m2024-07-18T07:06:04.793+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 4, 429302), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2675', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 4, 698659), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_branches.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 4, 429302), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2675', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 4, 698659), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_branches.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:06:05.002+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:05.073+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.092+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:05.093+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:05.094+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:05.094+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:05.095+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:06:05.095+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:06:05.096+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:05.104+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:05.105+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.068+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.074+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.109+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:05.111+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:05.112+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:05.111+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.126+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.619264+00:00, run_end_date=2024-07-18 01:34:03.308959+00:00, run_duration=1.6897, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=4776[0m
[[34m2024-07-18T07:06:05.127+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:05.138+0530[0m] {[34mtaskinstance.py:[0m2907} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:05.161+0530[0m] {[34mtaskinstance.py:[0m1206} INFO[0m - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013401, end_date=20240718T013605[0m
[[34m2024-07-18T07:06:05.184+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.104349+00:00, run_end_date=2024-07-18 01:36:04.632059+00:00, run_duration=1.52771, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2672, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8658[0m
[[34m2024-07-18T07:06:05.185+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.084483+00:00, run_end_date=2024-07-18 01:36:04.324532+00:00, run_duration=1.24005, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2671, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8659[0m
[[34m2024-07-18T07:06:05.324+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:05.334+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 2 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:05.335+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:05.336+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:06:05.337+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:05.348+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:05.349+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.350+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:05.354+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.373+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:05.374+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.381+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:05.405+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.362925+00:00, run_end_date=2024-07-18 01:36:04.727606+00:00, run_duration=1.36468, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2673, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8660[0m
[[34m2024-07-18T07:06:05.391+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.581+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.620+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:05.630+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:05.705+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:05.783+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:05.804+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.720742+00:00, run_end_date=2024-07-18 01:36:05.190983+00:00, run_duration=1.47024, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2674, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.728171+00:00, queued_by_job_id=2569, pid=8661[0m
[[34m2024-07-18T07:06:05.811+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:05.831+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:05.913+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:06.123+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:06.179+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:06.403+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:06.507+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:07.056+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:07.057+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:06:07.057+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:07.072+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:07.072+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:07.076+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:07.084+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:07.085+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:07.116+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:04.872642+00:00, run_end_date=2024-07-18 01:36:06.209999+00:00, run_duration=1.33736, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2677, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:01.222603+00:00, queued_by_job_id=2569, pid=8690[0m
[[34m2024-07-18T07:06:07.117+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:04.892301+00:00, run_end_date=2024-07-18 01:36:05.880828+00:00, run_duration=0.988527, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2676, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8689[0m
[[34m2024-07-18T07:06:07.211+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:07.269+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:07.353+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:07.815+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:07.946+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:07.972+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:05.953911+00:00, run_end_date=2024-07-18 01:36:07.053633+00:00, run_duration=1.09972, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2678, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8762[0m
[[34m2024-07-18T07:06:08.099+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:08.455+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:08.704+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:08.728+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:08.833+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:08.912+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:08.940+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:09.006+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:09.054+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:09.097+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:09.236+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:09.242+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:09.419+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 259559), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2685', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 366852), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_investments.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 259559), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2685', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 366852), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_investments.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:06:09.484+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:09.484+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 8/16 running and queued tasks[0m
[[34m2024-07-18T07:06:09.485+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:09.503+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:09.476+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 307804), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2687', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 406621), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_mortgage_applications.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 307804), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2687', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 406621), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_mortgage_applications.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)[0m
[[34m2024-07-18T07:06:09.504+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:09.512+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:09.522+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:09.544+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.546+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.547+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:06:09.547+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.548+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.585+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.324189+00:00, run_end_date=2024-07-18 01:36:07.603679+00:00, run_duration=1.27949, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2679, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:01.222603+00:00, queued_by_job_id=2569, pid=8778[0m
[[34m2024-07-18T07:06:09.586+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:02.777300+00:00, run_end_date=2024-07-18 01:36:08.657186+00:00, run_duration=5.87989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2669, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8648[0m
[[34m2024-07-18T07:06:09.593+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:07.191033+00:00, run_end_date=2024-07-18 01:36:08.726342+00:00, run_duration=1.53531, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2682, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8791[0m
[[34m2024-07-18T07:06:09.595+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:07.945796+00:00, run_end_date=2024-07-18 01:36:09.069224+00:00, run_duration=1.12343, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2683, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:02.148278+00:00, queued_by_job_id=2569, pid=8807[0m
[[34m2024-07-18T07:06:09.596+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.368044+00:00, run_end_date=2024-07-18 01:36:07.570156+00:00, run_duration=1.20211, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2680, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.051812+00:00, queued_by_job_id=2569, pid=8779[0m
[[34m2024-07-18T07:06:09.689+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:09.775+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.775+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.776+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:09.788+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.725343+00:00, run_end_date=2024-07-18 01:36:09.147098+00:00, run_duration=2.42176, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2681, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.728171+00:00, queued_by_job_id=2569, pid=8780[0m
[[34m2024-07-18T07:06:09.789+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.752867+00:00, run_end_date=2024-07-18 01:34:07.026116+00:00, run_duration=1.27325, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2620, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=5015[0m
[[34m2024-07-18T07:06:09.790+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:09.817+0530[0m] {[34mtaskinstance.py:[0m2907} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:09.854+0530[0m] {[34mtaskinstance.py:[0m1206} INFO[0m - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013405, end_date=20240718T013609[0m
[[34m2024-07-18T07:06:09.872+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.100271+00:00, run_end_date=2024-07-18 01:34:07.314235+00:00, run_duration=1.21396, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2623, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=5022[0m
[[34m2024-07-18T07:06:09.873+0530[0m] {[34mtask_context_logger.py:[0m91} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:09.896+0530[0m] {[34mtaskinstance.py:[0m2907} ERROR[0m - Executor reports task instance <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?[0m
[[34m2024-07-18T07:06:09.926+0530[0m] {[34mtaskinstance.py:[0m1206} INFO[0m - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013406, end_date=20240718T013609[0m
[[34m2024-07-18T07:06:09.937+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:10.114+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:10.477+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:10.485+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:08.760318+00:00, run_end_date=2024-07-18 01:36:09.758830+00:00, run_duration=0.998512, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2684, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.099847+00:00, queued_by_job_id=2569, pid=8820[0m
[[34m2024-07-18T07:06:11.050+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:11.280+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:11.639+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:11.640+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:11.641+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:11.642+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:11.659+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.520261+00:00, run_end_date=2024-07-18 01:36:10.477191+00:00, run_duration=0.95693, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2686, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.051812+00:00, queued_by_job_id=2569, pid=8847[0m
[[34m2024-07-18T07:06:11.660+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.509535+00:00, run_end_date=2024-07-18 01:36:10.360096+00:00, run_duration=0.850561, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2688, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=8843[0m
[[34m2024-07-18T07:06:11.661+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.993537+00:00, run_end_date=2024-07-18 01:36:10.627997+00:00, run_duration=0.63446, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2690, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.340344+00:00, queued_by_job_id=2569, pid=8857[0m
[[34m2024-07-18T07:06:11.662+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:10.457577+00:00, run_end_date=2024-07-18 01:36:11.089313+00:00, run_duration=0.631736, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2691, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:07.062917+00:00, queued_by_job_id=2569, pid=8875[0m
[[34m2024-07-18T07:06:12.743+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:06:12.744+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:06:12.749+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:11.559944+00:00, run_end_date=2024-07-18 01:36:11.963884+00:00, run_duration=0.40394, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2692, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:09.495482+00:00, queued_by_job_id=2569, pid=8908[0m
[[34m2024-07-18T07:06:12.749+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.714492+00:00, run_end_date=2024-07-18 01:36:12.066989+00:00, run_duration=2.3525, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2689, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.340344+00:00, queued_by_job_id=2569, pid=8855[0m
[[34m2024-07-18T07:06:37.275+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:37.276+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:37.276+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:37.278+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:06:37.279+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:37.283+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:37.317+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:38.010+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:38.093+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:38.542+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:38.609+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:38.609+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:38.610+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:38.614+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:06:38.614+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:38.618+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:38.617+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:38.623+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:38.206230+00:00, run_end_date=2024-07-18 01:36:38.443430+00:00, run_duration=0.2372, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2693, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:36:37.276951+00:00, queued_by_job_id=2569, pid=9643[0m
[[34m2024-07-18T07:06:38.652+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:39.511+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:39.625+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:40.156+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:40.761+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:40.762+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:40.762+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:40.765+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:40.765+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:40.768+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:40.768+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:40.781+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:39.763844+00:00, run_end_date=2024-07-18 01:36:40.033992+00:00, run_duration=0.270148, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2694, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:38.610784+00:00, queued_by_job_id=2569, pid=9670[0m
[[34m2024-07-18T07:06:40.810+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:41.635+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:41.716+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:43.088+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:43.098+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:41.853110+00:00, run_end_date=2024-07-18 01:36:42.135030+00:00, run_duration=0.28192, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2695, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:40.763052+00:00, queued_by_job_id=2569, pid=9731[0m
[[34m2024-07-18T07:06:44.817+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:44.817+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:44.818+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:44.820+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:06:44.820+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:44.823+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:44.868+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:45.746+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:45.874+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:46.542+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:47.177+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:47.179+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:47.179+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:47.184+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:06:47.185+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:47.188+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:47.188+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:47.199+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:46.108015+00:00, run_end_date=2024-07-18 01:36:46.464711+00:00, run_duration=0.356696, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2696, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:36:44.818806+00:00, queued_by_job_id=2569, pid=9866[0m
[[34m2024-07-18T07:06:47.236+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:48.376+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:48.539+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:49.213+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:06:49.329+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:49.330+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:49.331+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:49.335+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:49.336+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:49.339+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:49.339+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:49.349+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:48.714588+00:00, run_end_date=2024-07-18 01:36:49.119319+00:00, run_duration=0.404731, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2697, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:47.181236+00:00, queued_by_job_id=2569, pid=9952[0m
[[34m2024-07-18T07:06:49.439+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:50.550+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:50.641+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:52.015+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:52.020+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:50.754826+00:00, run_end_date=2024-07-18 01:36:51.017787+00:00, run_duration=0.262961, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2698, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:49.333363+00:00, queued_by_job_id=2569, pid=10010[0m
[[34m2024-07-18T07:06:53.102+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:53.102+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:06:53.103+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>[0m
[[34m2024-07-18T07:06:53.105+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:06:53.105+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:53.109+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:06:53.152+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:06:53.954+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:06:54.029+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:06:55.017+0530[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun parent_dag @ 2024-07-18 01:28:18.110991+00:00: manual__2024-07-18T01:28:18.110991+00:00, state:running, queued_at: 2024-07-18 01:28:18.168776+00:00. externally triggered: True> successful[0m
[[34m2024-07-18T07:06:55.018+0530[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=parent_dag, execution_date=2024-07-18 01:28:18.110991+00:00, run_id=manual__2024-07-18T01:28:18.110991+00:00, run_start_date=2024-07-18 01:28:19.852875+00:00, run_end_date=2024-07-18 01:36:55.018329+00:00, run_duration=515.165454, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=ab6dc09708a4297d36001303949cf96b[0m
[[34m2024-07-18T07:06:55.039+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)[0m
[[34m2024-07-18T07:06:55.047+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:54.135749+00:00, run_end_date=2024-07-18 01:36:54.388961+00:00, run_duration=0.253212, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2699, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:53.103772+00:00, queued_by_job_id=2569, pid=10113[0m
[[34m2024-07-18T07:07:02.006+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 16 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:02.008+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.008+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 1/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.008+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 2/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.009+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 3/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.009+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 4/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.010+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 5/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.010+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 6/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.010+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 7/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.011+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 8/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.011+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 9/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.011+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 10/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.012+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 11/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.012+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.012+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.013+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.013+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.013+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:02.018+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.018+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.019+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.019+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.020+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.020+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.020+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.021+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.021+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.021+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.022+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.022+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.023+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.025+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.025+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.025+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.026+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.026+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.027+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.027+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.028+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.028+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.029+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.029+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.029+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.030+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.030+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.030+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.031+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.031+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.032+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:02.032+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.035+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.036+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.036+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.036+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.036+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.036+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.037+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.047+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.051+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.056+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.076+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.084+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.090+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.093+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.093+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.103+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:02.104+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.134+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.136+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.118+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.176+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.180+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.226+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.216+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.283+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.300+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.332+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.334+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.348+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.346+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.390+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.384+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:02.424+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:02.425+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.425+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:02.425+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.426+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:02.454+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.455+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:02.456+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:02.457+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:03.727+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:03.728+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:03.729+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:03.730+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:03.731+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:03.733+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:03.733+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:03.733+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:03.734+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:03.920+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:04.354+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:04.355+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:04.356+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:04.357+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:04.358+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:04.375+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:04.376+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:04.377+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:04.377+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:04.915+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:05.046+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:05.399+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:05.488+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:05.502+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:05.503+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:05.504+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:05.504+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:05.505+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:05.505+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:05.506+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:05.518+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:05.884+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:05.919+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:06.183+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:06.401+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:06.653+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:06.753+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:06.810+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:06.814+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:06.815+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:06.816+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:06.816+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:06.816+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:06.817+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:06.817+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 16/16 running and queued tasks[0m
[[34m2024-07-18T07:07:06.818+0530[0m] {[34mscheduler_job_runner.py:[0m487} INFO[0m - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16[0m
[[34m2024-07-18T07:07:06.983+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:07.240+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:07.846+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:07.978+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:08.279+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:08.280+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 12/16 running and queued tasks[0m
[[34m2024-07-18T07:07:08.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 13/16 running and queued tasks[0m
[[34m2024-07-18T07:07:08.281+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 14/16 running and queued tasks[0m
[[34m2024-07-18T07:07:08.282+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 15/16 running and queued tasks[0m
[[34m2024-07-18T07:07:08.293+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:08.304+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:08.309+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.310+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:08.312+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.313+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:08.314+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.322+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:08.323+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.327+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.329+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.336+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.343+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:07:08.352+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:08.352+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:08.353+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:08.374+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_atms_to_int_atms, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:04.706003+00:00, run_end_date=2024-07-18 01:37:06.661348+00:00, run_duration=1.95535, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2700, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10432[0m
[[34m2024-07-18T07:07:08.376+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_credit_scores_to_int_credit_scores, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:05.874016+00:00, run_end_date=2024-07-18 01:37:07.050685+00:00, run_duration=1.17667, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2703, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10441[0m
[[34m2024-07-18T07:07:08.377+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_loans_to_int_loans, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.085487+00:00, run_end_date=2024-07-18 01:37:07.526822+00:00, run_duration=1.44133, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2705, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10443[0m
[[34m2024-07-18T07:07:08.418+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:08.415+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:08.567+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:08.626+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:07:08.689+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:08.899+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:09.652+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.657+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.658+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.665+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.666+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.674+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:09.702+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cheques_to_int_cheques, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.080200+00:00, run_end_date=2024-07-18 01:37:07.773930+00:00, run_duration=1.69373, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2704, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10442[0m
[[34m2024-07-18T07:07:09.705+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_employees_to_int_employees, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.956016+00:00, run_end_date=2024-07-18 01:37:08.763879+00:00, run_duration=1.80786, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2702, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10456[0m
[[34m2024-07-18T07:07:09.713+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_fixed_deposits_to_int_fixed_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.871217+00:00, run_end_date=2024-07-18 01:37:09.109970+00:00, run_duration=2.23875, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2707, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10455[0m
[[34m2024-07-18T07:07:09.713+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_insurance_to_int_insurance, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.613618+00:00, run_end_date=2024-07-18 01:37:08.800749+00:00, run_duration=2.18713, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2701, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10454[0m
[[34m2024-07-18T07:07:09.714+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_investments_to_int_investments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.487888+00:00, run_end_date=2024-07-18 01:37:08.849120+00:00, run_duration=1.36123, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2708, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10470[0m
[[34m2024-07-18T07:07:09.718+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_online_banking_to_int_online_banking, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.410885+00:00, run_end_date=2024-07-18 01:37:08.149478+00:00, run_duration=1.73859, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2706, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10453[0m
[[34m2024-07-18T07:07:10.251+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:10.811+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:10.914+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:10.916+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:10.917+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:10.929+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_branches_to_int_branches, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.524333+00:00, run_end_date=2024-07-18 01:37:09.837521+00:00, run_duration=1.31319, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2713, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10522[0m
[[34m2024-07-18T07:07:10.930+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cards_to_int_cards, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.481424+00:00, run_end_date=2024-07-18 01:37:09.471809+00:00, run_duration=1.99039, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2709, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10465[0m
[[34m2024-07-18T07:07:10.931+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customers_to_int_customers, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.432508+00:00, run_end_date=2024-07-18 01:37:09.601775+00:00, run_duration=2.16927, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2710, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10468[0m
[[34m2024-07-18T07:07:11.132+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:11.260+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:12.028+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.028+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.029+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.029+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.029+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.030+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.030+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:12.039+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_accounts_to_int_accounts, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:09.364164+00:00, run_end_date=2024-07-18 01:37:10.776759+00:00, run_duration=1.4126, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2714, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10555[0m
[[34m2024-07-18T07:07:12.040+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_bill_payments_to_int_bill_payments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.062321+00:00, run_end_date=2024-07-18 01:37:11.111610+00:00, run_duration=3.04929, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2711, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10504[0m
[[34m2024-07-18T07:07:12.040+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customer_support_to_int_customer_support, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.664009+00:00, run_end_date=2024-07-18 01:37:10.753716+00:00, run_duration=2.08971, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10546[0m
[[34m2024-07-18T07:07:12.041+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_mortgage_applications_to_int_mortgage_applications, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:09.575067+00:00, run_end_date=2024-07-18 01:37:10.858836+00:00, run_duration=1.28377, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10556[0m
[[34m2024-07-18T07:07:12.042+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_recurring_deposits_to_int_recurring_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.130399+00:00, run_end_date=2024-07-18 01:37:11.773585+00:00, run_duration=0.643186, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2717, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10590[0m
[[34m2024-07-18T07:07:12.042+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_savings_goals_to_int_savings_goals, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.324667+00:00, run_end_date=2024-07-18 01:37:11.847116+00:00, run_duration=0.522449, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2718, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10599[0m
[[34m2024-07-18T07:07:12.043+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_transactions_to_int_transactions, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:10.477143+00:00, run_end_date=2024-07-18 01:37:11.327531+00:00, run_duration=0.850388, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2716, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10565[0m
[[34m2024-07-18T07:07:13.101+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:13.108+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_service_charges_to_int_service_charges, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.541359+00:00, run_end_date=2024-07-18 01:37:12.533880+00:00, run_duration=0.992521, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2719, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10600[0m
[[34m2024-07-18T07:07:45.412+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:45.413+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_prepare_data_today has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:07:45.413+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [scheduled]>[0m
[[34m2024-07-18T07:07:45.419+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_prepare_data_today', task_id='Prepare_data', run_id='manual__2024-07-18T01:37:44.827477+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:07:45.419+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_prepare_data_today', 'Prepare_data', 'manual__2024-07-18T01:37:44.827477+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_prepare_data_today.py'][0m
[[34m2024-07-18T07:07:45.422+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_prepare_data_today', 'Prepare_data', 'manual__2024-07-18T01:37:44.827477+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_prepare_data_today.py'][0m
[[34m2024-07-18T07:07:45.458+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/dag_prepare_data_today.py[0m
[[34m2024-07-18T07:07:45.559+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:07:52.337+0530[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun dag_prepare_data_today @ 2024-07-18 01:37:44.827477+00:00: manual__2024-07-18T01:37:44.827477+00:00, state:running, queued_at: 2024-07-18 01:37:44.848466+00:00. externally triggered: True> successful[0m
[[34m2024-07-18T07:07:52.338+0530[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=dag_prepare_data_today, execution_date=2024-07-18 01:37:44.827477+00:00, run_id=manual__2024-07-18T01:37:44.827477+00:00, run_start_date=2024-07-18 01:37:45.356063+00:00, run_end_date=2024-07-18 01:37:52.338169+00:00, run_duration=6.982106, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-18 01:37:44.827477+00:00, data_interval_end=2024-07-18 01:37:44.827477+00:00, dag_hash=83a5a88b23306d5e45e886e9fee1d340[0m
[[34m2024-07-18T07:07:52.362+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_prepare_data_today', task_id='Prepare_data', run_id='manual__2024-07-18T01:37:44.827477+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:07:52.374+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_prepare_data_today, task_id=Prepare_data, run_id=manual__2024-07-18T01:37:44.827477+00:00, map_index=-1, run_start_date=2024-07-18 01:37:45.676163+00:00, run_end_date=2024-07-18 01:37:52.045212+00:00, run_duration=6.36905, state=success, executor_state=success, try_number=1, max_tries=0, job_id=2720, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:45.415940+00:00, queued_by_job_id=2569, pid=11422[0m
[[34m2024-07-18T07:08:48.664+0530[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[2024-07-18T07:08:50.691+0530] {manager.py:524} INFO - DAG parent_dag is missing and will be deactivated.
[2024-07-18T07:08:50.700+0530] {manager.py:536} INFO - Deactivated 1 DAGs which are no longer present in file.
[2024-07-18T07:08:50.708+0530] {manager.py:540} INFO - Deleted DAG parent_dag in serialized_dag table
[[34m2024-07-18T07:11:29.327+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:29.329+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:29.330+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:29.336+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 60 and queue default[0m
[[34m2024-07-18T07:11:29.337+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:29.351+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:29.404+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:30.138+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:30.208+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:30.670+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:31.690+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:31.691+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:31.691+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:31.695+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 59 and queue default[0m
[[34m2024-07-18T07:11:31.696+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:31.700+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:31.699+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:31.704+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:30.307183+00:00, run_end_date=2024-07-18 01:41:30.546975+00:00, run_duration=0.239792, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2721, pool=default_pool, queue=default, priority_weight=60, operator=PythonOperator, queued_dttm=2024-07-18 01:41:29.331865+00:00, queued_by_job_id=2569, pid=18115[0m
[[34m2024-07-18T07:11:31.731+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:32.533+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:32.653+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:33.153+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:33.291+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:33.292+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:33.294+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:33.297+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 58 and queue default[0m
[[34m2024-07-18T07:11:33.297+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:33.301+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:33.301+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:33.307+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:32.772490+00:00, run_end_date=2024-07-18 01:41:33.052307+00:00, run_duration=0.279817, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2722, pool=default_pool, queue=default, priority_weight=59, operator=PythonOperator, queued_dttm=2024-07-18 01:41:31.692311+00:00, queued_by_job_id=2569, pid=18148[0m
[[34m2024-07-18T07:11:33.339+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:34.049+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:34.138+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:36.733+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:37.694+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:37.694+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:37.695+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:37.698+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 57 and queue default[0m
[[34m2024-07-18T07:11:37.699+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:37.702+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:37.702+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:37.707+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:34.304071+00:00, run_end_date=2024-07-18 01:41:36.629994+00:00, run_duration=2.32592, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2723, pool=default_pool, queue=default, priority_weight=58, operator=PythonOperator, queued_dttm=2024-07-18 01:41:33.295754+00:00, queued_by_job_id=2569, pid=18165[0m
[[34m2024-07-18T07:11:37.737+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:38.520+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:38.599+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:39.052+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:39.533+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:39.533+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:39.534+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:39.536+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 56 and queue default[0m
[[34m2024-07-18T07:11:39.536+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:39.539+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:39.539+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:39.547+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:38.697995+00:00, run_end_date=2024-07-18 01:41:38.938811+00:00, run_duration=0.240816, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2724, pool=default_pool, queue=default, priority_weight=57, operator=PythonOperator, queued_dttm=2024-07-18 01:41:37.695929+00:00, queued_by_job_id=2569, pid=18218[0m
[[34m2024-07-18T07:11:39.578+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:40.460+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:40.538+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:41.015+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:41.884+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:41.884+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:41.885+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:41.887+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 55 and queue default[0m
[[34m2024-07-18T07:11:41.887+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:41.889+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:41.889+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:41.898+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:40.654821+00:00, run_end_date=2024-07-18 01:41:40.918613+00:00, run_duration=0.263792, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2725, pool=default_pool, queue=default, priority_weight=56, operator=PythonOperator, queued_dttm=2024-07-18 01:41:39.534867+00:00, queued_by_job_id=2569, pid=18243[0m
[[34m2024-07-18T07:11:41.925+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:42.631+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:42.725+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:43.387+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:43.518+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:43.518+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:43.519+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:43.521+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 54 and queue default[0m
[[34m2024-07-18T07:11:43.521+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:43.525+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:43.524+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:43.533+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:42.846850+00:00, run_end_date=2024-07-18 01:41:43.283367+00:00, run_duration=0.436517, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2726, pool=default_pool, queue=default, priority_weight=55, operator=PythonOperator, queued_dttm=2024-07-18 01:41:41.885596+00:00, queued_by_job_id=2569, pid=18276[0m
[[34m2024-07-18T07:11:43.559+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:44.269+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:44.365+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:44.796+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:45.851+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:45.851+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:45.852+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:45.854+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 53 and queue default[0m
[[34m2024-07-18T07:11:45.855+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:45.859+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:45.858+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:45.865+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:44.464347+00:00, run_end_date=2024-07-18 01:41:44.699537+00:00, run_duration=0.23519, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2727, pool=default_pool, queue=default, priority_weight=54, operator=PythonOperator, queued_dttm=2024-07-18 01:41:43.519619+00:00, queued_by_job_id=2569, pid=18293[0m
[[34m2024-07-18T07:11:45.893+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:46.583+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:46.662+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:47.209+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:48.135+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:48.135+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:48.135+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:48.137+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 52 and queue default[0m
[[34m2024-07-18T07:11:48.138+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:48.142+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:48.141+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:48.149+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:46.782192+00:00, run_end_date=2024-07-18 01:41:47.087113+00:00, run_duration=0.304921, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2728, pool=default_pool, queue=default, priority_weight=53, operator=PythonOperator, queued_dttm=2024-07-18 01:41:45.853000+00:00, queued_by_job_id=2569, pid=18350[0m
[[34m2024-07-18T07:11:48.175+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:48.975+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:49.114+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:50.077+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:50.836+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:50.837+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:50.837+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:50.842+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 51 and queue default[0m
[[34m2024-07-18T07:11:50.842+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:50.846+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:50.846+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:50.851+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:49.251198+00:00, run_end_date=2024-07-18 01:41:49.997323+00:00, run_duration=0.746125, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2729, pool=default_pool, queue=default, priority_weight=52, operator=PythonOperator, queued_dttm=2024-07-18 01:41:48.136334+00:00, queued_by_job_id=2569, pid=18409[0m
[[34m2024-07-18T07:11:50.896+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:51.834+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:51.913+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:52.341+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:52.652+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:52.652+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:52.652+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:52.656+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 50 and queue default[0m
[[34m2024-07-18T07:11:52.656+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:52.660+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:52.660+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:52.664+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:52.009813+00:00, run_end_date=2024-07-18 01:41:52.271466+00:00, run_duration=0.261653, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2730, pool=default_pool, queue=default, priority_weight=51, operator=PythonOperator, queued_dttm=2024-07-18 01:41:50.838796+00:00, queued_by_job_id=2569, pid=18492[0m
[[34m2024-07-18T07:11:52.690+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:53.377+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:53.449+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:53.984+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:54.969+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:54.969+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:54.969+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:54.973+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 49 and queue default[0m
[[34m2024-07-18T07:11:54.974+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:54.978+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:54.978+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:54.982+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:53.550433+00:00, run_end_date=2024-07-18 01:41:53.914018+00:00, run_duration=0.363585, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2731, pool=default_pool, queue=default, priority_weight=50, operator=PythonOperator, queued_dttm=2024-07-18 01:41:52.653393+00:00, queued_by_job_id=2569, pid=18514[0m
[[34m2024-07-18T07:11:55.009+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:55.932+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:56.017+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:56.667+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:57.347+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:57.348+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:57.348+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:57.353+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 48 and queue default[0m
[[34m2024-07-18T07:11:57.357+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:57.363+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:57.367+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:57.384+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:56.182016+00:00, run_end_date=2024-07-18 01:41:56.511148+00:00, run_duration=0.329132, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2732, pool=default_pool, queue=default, priority_weight=49, operator=PythonOperator, queued_dttm=2024-07-18 01:41:54.970398+00:00, queued_by_job_id=2569, pid=18637[0m
[[34m2024-07-18T07:11:57.434+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:58.144+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:58.215+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:58.620+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:58.620+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:11:58.621+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:11:58.623+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 47 and queue default[0m
[[34m2024-07-18T07:11:58.625+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:58.628+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:11:58.618+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:11:58.668+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:11:58.763+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:11:58.776+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:58.315684+00:00, run_end_date=2024-07-18 01:41:58.533618+00:00, run_duration=0.217934, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2733, pool=default_pool, queue=default, priority_weight=48, operator=PythonOperator, queued_dttm=2024-07-18 01:41:57.349528+00:00, queued_by_job_id=2569, pid=18729[0m
[[34m2024-07-18T07:11:59.360+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:11:59.443+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:11:59.912+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:00.067+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:00.067+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:00.068+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:00.072+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 46 and queue default[0m
[[34m2024-07-18T07:12:00.073+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:00.075+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:00.075+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:00.079+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:59.544316+00:00, run_end_date=2024-07-18 01:41:59.784254+00:00, run_duration=0.239938, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2734, pool=default_pool, queue=default, priority_weight=47, operator=PythonOperator, queued_dttm=2024-07-18 01:41:58.621635+00:00, queued_by_job_id=2569, pid=18756[0m
[[34m2024-07-18T07:12:00.105+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:00.730+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:00.810+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:01.979+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:02.396+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:02.397+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:02.397+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:02.399+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 45 and queue default[0m
[[34m2024-07-18T07:12:02.400+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:02.404+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:02.403+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:02.410+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:00.924919+00:00, run_end_date=2024-07-18 01:42:01.892070+00:00, run_duration=0.967151, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2735, pool=default_pool, queue=default, priority_weight=46, operator=PythonOperator, queued_dttm=2024-07-18 01:42:00.068962+00:00, queued_by_job_id=2569, pid=18783[0m
[[34m2024-07-18T07:12:02.433+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:03.081+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:03.164+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:03.626+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:03.894+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:03.895+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:03.895+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:03.897+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 44 and queue default[0m
[[34m2024-07-18T07:12:03.897+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:03.903+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:03.901+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:03.912+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:03.264930+00:00, run_end_date=2024-07-18 01:42:03.504682+00:00, run_duration=0.239752, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2736, pool=default_pool, queue=default, priority_weight=45, operator=PythonOperator, queued_dttm=2024-07-18 01:42:02.398093+00:00, queued_by_job_id=2569, pid=18808[0m
[[34m2024-07-18T07:12:03.943+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:04.548+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:04.623+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:05.009+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:05.132+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:05.132+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:05.133+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:05.137+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 43 and queue default[0m
[[34m2024-07-18T07:12:05.137+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:05.141+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:05.141+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:05.147+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:04.720749+00:00, run_end_date=2024-07-18 01:42:04.945660+00:00, run_duration=0.224911, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2737, pool=default_pool, queue=default, priority_weight=44, operator=PythonOperator, queued_dttm=2024-07-18 01:42:03.895760+00:00, queued_by_job_id=2569, pid=18825[0m
[[34m2024-07-18T07:12:05.181+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:05.807+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:05.879+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:06.721+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:06.797+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:06.797+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:06.798+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:06.800+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 42 and queue default[0m
[[34m2024-07-18T07:12:06.800+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:06.804+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:06.803+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:06.812+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:06.000554+00:00, run_end_date=2024-07-18 01:42:06.639124+00:00, run_duration=0.63857, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2738, pool=default_pool, queue=default, priority_weight=43, operator=PythonOperator, queued_dttm=2024-07-18 01:42:05.133660+00:00, queued_by_job_id=2569, pid=18850[0m
[[34m2024-07-18T07:12:06.837+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:07.480+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:07.552+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:07.941+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:07.992+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:07.992+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:07.992+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:07.994+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 41 and queue default[0m
[[34m2024-07-18T07:12:07.995+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:07.998+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:07.997+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:08.004+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:07.649761+00:00, run_end_date=2024-07-18 01:42:07.861351+00:00, run_duration=0.21159, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2739, pool=default_pool, queue=default, priority_weight=42, operator=PythonOperator, queued_dttm=2024-07-18 01:42:06.798532+00:00, queued_by_job_id=2569, pid=18867[0m
[[34m2024-07-18T07:12:08.031+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:08.788+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:08.863+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:09.256+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:10.206+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:10.207+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:10.207+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:10.210+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 40 and queue default[0m
[[34m2024-07-18T07:12:10.210+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:10.213+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:10.213+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:10.221+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:08.964919+00:00, run_end_date=2024-07-18 01:42:09.195174+00:00, run_duration=0.230255, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2740, pool=default_pool, queue=default, priority_weight=41, operator=PythonOperator, queued_dttm=2024-07-18 01:42:07.993398+00:00, queued_by_job_id=2569, pid=18904[0m
[[34m2024-07-18T07:12:10.246+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:10.903+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:11.003+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:12.273+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:12.494+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:12.494+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:12.495+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:12.496+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 39 and queue default[0m
[[34m2024-07-18T07:12:12.497+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:12.499+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:12.499+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:12.507+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:11.104677+00:00, run_end_date=2024-07-18 01:42:12.208956+00:00, run_duration=1.10428, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2741, pool=default_pool, queue=default, priority_weight=40, operator=PythonOperator, queued_dttm=2024-07-18 01:42:10.208597+00:00, queued_by_job_id=2569, pid=18929[0m
[[34m2024-07-18T07:12:12.532+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:13.219+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:13.295+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:13.722+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:13.964+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:13.964+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:13.964+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:13.968+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 38 and queue default[0m
[[34m2024-07-18T07:12:13.969+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:13.973+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:13.973+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:13.977+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:13.394919+00:00, run_end_date=2024-07-18 01:42:13.628615+00:00, run_duration=0.233696, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2742, pool=default_pool, queue=default, priority_weight=39, operator=PythonOperator, queued_dttm=2024-07-18 01:42:12.495469+00:00, queued_by_job_id=2569, pid=18954[0m
[[34m2024-07-18T07:12:14.002+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:14.687+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:14.777+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:15.239+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:15.313+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:15.313+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:15.313+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:15.317+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 37 and queue default[0m
[[34m2024-07-18T07:12:15.318+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:15.321+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:15.321+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:15.325+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:14.882123+00:00, run_end_date=2024-07-18 01:42:15.125783+00:00, run_duration=0.24366, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2743, pool=default_pool, queue=default, priority_weight=38, operator=PythonOperator, queued_dttm=2024-07-18 01:42:13.965257+00:00, queued_by_job_id=2569, pid=18980[0m
[[34m2024-07-18T07:12:15.351+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:15.986+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:16.068+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:16.739+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:17.606+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:17.607+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:17.607+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:17.610+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 36 and queue default[0m
[[34m2024-07-18T07:12:17.611+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:17.613+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:17.613+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:17.624+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:16.181362+00:00, run_end_date=2024-07-18 01:42:16.641277+00:00, run_duration=0.459915, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2744, pool=default_pool, queue=default, priority_weight=37, operator=PythonOperator, queued_dttm=2024-07-18 01:42:15.314487+00:00, queued_by_job_id=2569, pid=19007[0m
[[34m2024-07-18T07:12:17.653+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:18.355+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:18.429+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:18.872+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:18.993+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:18.999+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:18.528839+00:00, run_end_date=2024-07-18 01:42:18.764889+00:00, run_duration=0.23605, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2745, pool=default_pool, queue=default, priority_weight=36, operator=PythonOperator, queued_dttm=2024-07-18 01:42:17.608593+00:00, queued_by_job_id=2569, pid=19046[0m
[[34m2024-07-18T07:12:19.323+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:19.324+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:19.324+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:19.326+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 35 and queue default[0m
[[34m2024-07-18T07:12:19.326+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:19.329+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:19.363+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:20.191+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:20.276+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:20.722+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:21.743+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:21.743+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:21.743+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:21.745+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 34 and queue default[0m
[[34m2024-07-18T07:12:21.746+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:21.750+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:21.750+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:21.756+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:20.381492+00:00, run_end_date=2024-07-18 01:42:20.625342+00:00, run_duration=0.24385, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2746, pool=default_pool, queue=default, priority_weight=35, operator=PythonOperator, queued_dttm=2024-07-18 01:42:19.324920+00:00, queued_by_job_id=2569, pid=19105[0m
[[34m2024-07-18T07:12:21.783+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:22.579+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:22.661+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:23.909+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:24.043+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:24.044+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:24.044+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:24.048+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 33 and queue default[0m
[[34m2024-07-18T07:12:24.049+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:24.052+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:24.052+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:24.057+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:22.771015+00:00, run_end_date=2024-07-18 01:42:23.772813+00:00, run_duration=1.0018, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2747, pool=default_pool, queue=default, priority_weight=34, operator=PythonOperator, queued_dttm=2024-07-18 01:42:21.744420+00:00, queued_by_job_id=2569, pid=19180[0m
[[34m2024-07-18T07:12:24.091+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:24.767+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:24.903+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:25.356+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:25.543+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:25.544+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:25.544+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:25.548+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 32 and queue default[0m
[[34m2024-07-18T07:12:25.549+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:25.552+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:25.552+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:25.558+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:25.020202+00:00, run_end_date=2024-07-18 01:42:25.274153+00:00, run_duration=0.253951, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2748, pool=default_pool, queue=default, priority_weight=33, operator=PythonOperator, queued_dttm=2024-07-18 01:42:24.045121+00:00, queued_by_job_id=2569, pid=19233[0m
[[34m2024-07-18T07:12:25.587+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:26.422+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:26.534+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:27.139+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:27.880+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:27.881+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:27.882+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:27.886+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 31 and queue default[0m
[[34m2024-07-18T07:12:27.886+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:27.890+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:27.889+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:27.895+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:26.692393+00:00, run_end_date=2024-07-18 01:42:27.005104+00:00, run_duration=0.312711, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2749, pool=default_pool, queue=default, priority_weight=32, operator=PythonOperator, queued_dttm=2024-07-18 01:42:25.544964+00:00, queued_by_job_id=2569, pid=19310[0m
[[34m2024-07-18T07:12:27.927+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:28.739+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:28.822+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:29.603+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:30.601+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:30.602+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:30.602+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:30.604+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 30 and queue default[0m
[[34m2024-07-18T07:12:30.604+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:30.607+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:30.607+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:30.618+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:28.940037+00:00, run_end_date=2024-07-18 01:42:29.537752+00:00, run_duration=0.597715, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2750, pool=default_pool, queue=default, priority_weight=31, operator=PythonOperator, queued_dttm=2024-07-18 01:42:27.883572+00:00, queued_by_job_id=2569, pid=19417[0m
[[34m2024-07-18T07:12:30.641+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:31.305+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:31.375+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:31.807+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:32.860+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:32.860+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:32.861+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:32.866+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 29 and queue default[0m
[[34m2024-07-18T07:12:32.867+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:32.870+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:32.870+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:32.874+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:31.477418+00:00, run_end_date=2024-07-18 01:42:31.735185+00:00, run_duration=0.257767, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2751, pool=default_pool, queue=default, priority_weight=30, operator=PythonOperator, queued_dttm=2024-07-18 01:42:30.603130+00:00, queued_by_job_id=2569, pid=19454[0m
[[34m2024-07-18T07:12:32.902+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:33.503+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:33.580+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:34.042+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:34.065+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:34.066+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:34.066+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:34.069+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 28 and queue default[0m
[[34m2024-07-18T07:12:34.069+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:34.071+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:34.105+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:34.142+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:34.148+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:33.699459+00:00, run_end_date=2024-07-18 01:42:33.940955+00:00, run_duration=0.241496, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2752, pool=default_pool, queue=default, priority_weight=29, operator=PythonOperator, queued_dttm=2024-07-18 01:42:32.863295+00:00, queued_by_job_id=2569, pid=19479[0m
[[34m2024-07-18T07:12:34.770+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:34.845+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:35.510+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:35.717+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:35.718+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:35.718+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:35.720+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 27 and queue default[0m
[[34m2024-07-18T07:12:35.721+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:35.723+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:35.723+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:35.730+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:34.947304+00:00, run_end_date=2024-07-18 01:42:35.444204+00:00, run_duration=0.4969, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2753, pool=default_pool, queue=default, priority_weight=28, operator=PythonOperator, queued_dttm=2024-07-18 01:42:34.066984+00:00, queued_by_job_id=2569, pid=19510[0m
[[34m2024-07-18T07:12:35.755+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:36.355+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:36.426+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:36.858+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:36.892+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:36.892+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:36.894+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:36.899+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 26 and queue default[0m
[[34m2024-07-18T07:12:36.899+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:36.903+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:36.902+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:36.908+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:36.532360+00:00, run_end_date=2024-07-18 01:42:36.765349+00:00, run_duration=0.232989, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2754, pool=default_pool, queue=default, priority_weight=27, operator=PythonOperator, queued_dttm=2024-07-18 01:42:35.719100+00:00, queued_by_job_id=2569, pid=19527[0m
[[34m2024-07-18T07:12:36.939+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:37.557+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:37.632+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:38.075+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:38.075+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:38.076+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:38.080+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 25 and queue default[0m
[[34m2024-07-18T07:12:38.081+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:38.083+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:38.079+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:38.118+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:38.161+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:38.168+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:37.741412+00:00, run_end_date=2024-07-18 01:42:38.000649+00:00, run_duration=0.259237, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2755, pool=default_pool, queue=default, priority_weight=26, operator=PythonOperator, queued_dttm=2024-07-18 01:42:36.895458+00:00, queued_by_job_id=2569, pid=19545[0m
[[34m2024-07-18T07:12:38.753+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:38.826+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:39.643+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:39.717+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:39.718+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:39.718+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:39.720+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 24 and queue default[0m
[[34m2024-07-18T07:12:39.720+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:39.724+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:39.723+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:39.731+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:38.934740+00:00, run_end_date=2024-07-18 01:42:39.547414+00:00, run_duration=0.612674, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2756, pool=default_pool, queue=default, priority_weight=25, operator=PythonOperator, queued_dttm=2024-07-18 01:42:38.076930+00:00, queued_by_job_id=2569, pid=19573[0m
[[34m2024-07-18T07:12:39.758+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:40.477+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:40.552+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:40.954+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:41.993+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:41.994+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:41.995+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:41.997+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 23 and queue default[0m
[[34m2024-07-18T07:12:41.998+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:42.001+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:42.000+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:42.005+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:40.663298+00:00, run_end_date=2024-07-18 01:42:40.892500+00:00, run_duration=0.229202, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2757, pool=default_pool, queue=default, priority_weight=24, operator=PythonOperator, queued_dttm=2024-07-18 01:42:39.718948+00:00, queued_by_job_id=2569, pid=19599[0m
[[34m2024-07-18T07:12:42.031+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:42.662+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:42.734+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:43.164+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:44.156+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:44.156+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:44.157+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:44.161+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 22 and queue default[0m
[[34m2024-07-18T07:12:44.161+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:44.165+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:44.164+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:44.169+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:42.834645+00:00, run_end_date=2024-07-18 01:42:43.071204+00:00, run_duration=0.236559, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2758, pool=default_pool, queue=default, priority_weight=23, operator=PythonOperator, queued_dttm=2024-07-18 01:42:41.996069+00:00, queued_by_job_id=2569, pid=19632[0m
[[34m2024-07-18T07:12:44.195+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:44.818+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:44.902+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:45.524+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:45.937+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:45.938+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:45.938+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:45.940+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 21 and queue default[0m
[[34m2024-07-18T07:12:45.941+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:45.946+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:45.945+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:45.951+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:44.995821+00:00, run_end_date=2024-07-18 01:42:45.451287+00:00, run_duration=0.455466, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2759, pool=default_pool, queue=default, priority_weight=22, operator=PythonOperator, queued_dttm=2024-07-18 01:42:44.157808+00:00, queued_by_job_id=2569, pid=19657[0m
[[34m2024-07-18T07:12:45.974+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:46.700+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:46.803+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:47.343+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:48.207+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:48.207+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:48.208+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:48.214+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 20 and queue default[0m
[[34m2024-07-18T07:12:48.215+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:48.221+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:48.225+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:48.236+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:46.917988+00:00, run_end_date=2024-07-18 01:42:47.201310+00:00, run_duration=0.283322, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2760, pool=default_pool, queue=default, priority_weight=21, operator=PythonOperator, queued_dttm=2024-07-18 01:42:45.939104+00:00, queued_by_job_id=2569, pid=19692[0m
[[34m2024-07-18T07:12:48.271+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:48.982+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:49.056+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:49.493+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:49.799+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:49.799+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:49.799+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:49.801+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 19 and queue default[0m
[[34m2024-07-18T07:12:49.802+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:49.804+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:49.804+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:49.813+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:49.156205+00:00, run_end_date=2024-07-18 01:42:49.403453+00:00, run_duration=0.247248, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2761, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:42:48.209009+00:00, queued_by_job_id=2569, pid=19731[0m
[[34m2024-07-18T07:12:49.836+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:50.469+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:50.541+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:51.643+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:52.036+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:52.036+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:52.036+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:52.038+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 18 and queue default[0m
[[34m2024-07-18T07:12:52.038+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:52.043+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:52.042+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:52.049+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:50.654214+00:00, run_end_date=2024-07-18 01:42:51.568331+00:00, run_duration=0.914117, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2762, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:42:49.800466+00:00, queued_by_job_id=2569, pid=19768[0m
[[34m2024-07-18T07:12:52.079+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:52.866+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:52.950+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:53.510+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:54.320+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:54.320+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:54.320+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:54.324+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 17 and queue default[0m
[[34m2024-07-18T07:12:54.325+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:54.328+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:54.328+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:54.333+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:53.088705+00:00, run_end_date=2024-07-18 01:42:53.435393+00:00, run_duration=0.346688, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2763, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:42:52.037101+00:00, queued_by_job_id=2569, pid=19850[0m
[[34m2024-07-18T07:12:54.360+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:54.985+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:55.067+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:55.454+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:56.106+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:56.107+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:56.108+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:56.113+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 16 and queue default[0m
[[34m2024-07-18T07:12:56.113+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:56.117+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:56.116+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:56.123+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:55.169149+00:00, run_end_date=2024-07-18 01:42:55.400220+00:00, run_duration=0.231071, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2764, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:42:54.321634+00:00, queued_by_job_id=2569, pid=19893[0m
[[34m2024-07-18T07:12:56.153+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:56.954+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:57.116+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:58.143+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:12:58.392+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:58.393+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:12:58.393+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:12:58.397+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 15 and queue default[0m
[[34m2024-07-18T07:12:58.397+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:58.400+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:12:58.400+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:12:58.406+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:57.308927+00:00, run_end_date=2024-07-18 01:42:58.036395+00:00, run_duration=0.727468, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2765, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:42:56.109691+00:00, queued_by_job_id=2569, pid=19986[0m
[[34m2024-07-18T07:12:58.437+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:12:59.275+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:12:59.380+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:12:59.865+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:00.131+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:00.131+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:00.131+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:00.133+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 14 and queue default[0m
[[34m2024-07-18T07:13:00.134+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:00.137+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:00.137+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:00.145+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:59.523860+00:00, run_end_date=2024-07-18 01:42:59.776709+00:00, run_duration=0.252849, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2766, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:42:58.394821+00:00, queued_by_job_id=2569, pid=20093[0m
[[34m2024-07-18T07:13:00.169+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:00.829+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:00.915+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:01.317+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:01.317+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:01.317+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:01.319+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 13 and queue default[0m
[[34m2024-07-18T07:13:01.320+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:01.323+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:01.357+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:01.351+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:01.396+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:01.401+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:01.019291+00:00, run_end_date=2024-07-18 01:43:01.259327+00:00, run_duration=0.240036, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2767, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:43:00.132420+00:00, queued_by_job_id=2569, pid=20132[0m
[[34m2024-07-18T07:13:01.963+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:02.039+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:02.969+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:03.344+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:03.345+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:03.346+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:03.352+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 12 and queue default[0m
[[34m2024-07-18T07:13:03.352+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:03.359+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:03.358+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:03.366+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:02.167558+00:00, run_end_date=2024-07-18 01:43:02.863931+00:00, run_duration=0.696373, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2768, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:43:01.318169+00:00, queued_by_job_id=2569, pid=20151[0m
[[34m2024-07-18T07:13:03.396+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:04.015+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:04.087+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:04.499+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:04.533+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:04.533+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:04.533+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:04.536+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 11 and queue default[0m
[[34m2024-07-18T07:13:04.536+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:04.541+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:04.540+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:04.546+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:04.189397+00:00, run_end_date=2024-07-18 01:43:04.413678+00:00, run_duration=0.224281, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2769, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:43:03.347864+00:00, queued_by_job_id=2569, pid=20176[0m
[[34m2024-07-18T07:13:04.573+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:05.207+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:05.318+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:05.797+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:06.415+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:06.415+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:06.415+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:06.417+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue default[0m
[[34m2024-07-18T07:13:06.418+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:06.422+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:06.422+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:06.430+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:05.461962+00:00, run_end_date=2024-07-18 01:43:05.713155+00:00, run_duration=0.251193, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2770, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:43:04.534413+00:00, queued_by_job_id=2569, pid=20193[0m
[[34m2024-07-18T07:13:06.457+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:07.176+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:07.249+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:07.959+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:08.232+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:08.233+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:08.233+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:08.235+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-18T07:13:08.235+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:08.240+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:08.239+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:08.245+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:07.352028+00:00, run_end_date=2024-07-18 01:43:07.890203+00:00, run_duration=0.538175, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2771, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:43:06.416368+00:00, queued_by_job_id=2569, pid=20218[0m
[[34m2024-07-18T07:13:08.272+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:08.932+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:09.008+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:09.460+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:10.368+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:10.369+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:10.371+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:10.375+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-18T07:13:10.375+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:10.378+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:10.378+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:10.383+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:09.130542+00:00, run_end_date=2024-07-18 01:43:09.395750+00:00, run_duration=0.265208, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2772, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:43:08.233949+00:00, queued_by_job_id=2569, pid=20244[0m
[[34m2024-07-18T07:13:10.411+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:11.184+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:11.263+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:11.726+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:12.614+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:12.614+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:12.614+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:12.616+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-18T07:13:12.617+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:12.623+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:12.622+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:12.631+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:11.383398+00:00, run_end_date=2024-07-18 01:43:11.645367+00:00, run_duration=0.261969, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2773, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:43:10.372365+00:00, queued_by_job_id=2569, pid=20281[0m
[[34m2024-07-18T07:13:12.660+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:13.298+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:13.381+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:14.147+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:14.543+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:14.544+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:14.544+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:14.546+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-18T07:13:14.546+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:14.550+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:14.549+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:14.559+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:13.481469+00:00, run_end_date=2024-07-18 01:43:14.048251+00:00, run_duration=0.566782, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2774, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:43:12.615473+00:00, queued_by_job_id=2569, pid=20306[0m
[[34m2024-07-18T07:13:14.587+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:15.322+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:15.406+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:15.902+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:16.563+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:16.564+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:16.564+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:16.566+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-18T07:13:16.567+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:16.572+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:16.572+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:16.578+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:15.527904+00:00, run_end_date=2024-07-18 01:43:15.784410+00:00, run_duration=0.256506, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2775, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:43:14.544989+00:00, queued_by_job_id=2569, pid=20332[0m
[[34m2024-07-18T07:13:16.605+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:17.279+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:17.364+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:17.848+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:18.813+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:18.813+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:18.813+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:18.815+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-18T07:13:18.816+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:18.820+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:18.820+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:18.826+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:17.493736+00:00, run_end_date=2024-07-18 01:43:17.758469+00:00, run_duration=0.264733, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2776, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:43:16.565047+00:00, queued_by_job_id=2569, pid=20367[0m
[[34m2024-07-18T07:13:18.853+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:19.586+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:19.664+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:20.722+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:21.632+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:21.632+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:21.633+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:21.638+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:13:21.639+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:21.647+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:21.654+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:21.656+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:19.771916+00:00, run_end_date=2024-07-18 01:43:20.626621+00:00, run_duration=0.854705, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2777, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:43:18.814402+00:00, queued_by_job_id=2569, pid=20406[0m
[[34m2024-07-18T07:13:21.731+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:22.553+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:22.642+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:23.187+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:23.373+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:23.373+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:23.374+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:23.376+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:13:23.377+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:23.380+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:23.379+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:23.390+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:22.775877+00:00, run_end_date=2024-07-18 01:43:23.116234+00:00, run_duration=0.340357, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2778, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:43:21.635442+00:00, queued_by_job_id=2569, pid=20483[0m
[[34m2024-07-18T07:13:23.424+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:24.268+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:24.372+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:24.924+0530[0m] {[34mlocal_executor.py:[0m139} ERROR[0m - Failed to execute task cannot pickle 'Connection' object.[0m
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object[0m
[[34m2024-07-18T07:13:25.644+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:25.644+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG parent_dag has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:13:25.645+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>[0m
[[34m2024-07-18T07:13:25.647+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:13:25.647+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:25.651+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:25.651+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py'][0m
[[34m2024-07-18T07:13:25.658+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:24.494174+00:00, run_end_date=2024-07-18 01:43:24.843886+00:00, run_duration=0.349712, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2779, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:43:23.375022+00:00, queued_by_job_id=2569, pid=20544[0m
[[34m2024-07-18T07:13:25.680+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py[0m
[[34m2024-07-18T07:13:26.265+0530[0m] {[34mbase.py:[0m84} INFO[0m - Using connection ID 'mysql_default' for task execution.[0m
[[34m2024-07-18T07:13:26.337+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:13:32.878+0530[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun parent_dag @ 2024-07-18 01:41:28.205554+00:00: manual__2024-07-18T01:41:28.205554+00:00, state:running, queued_at: 2024-07-18 01:41:28.266692+00:00. externally triggered: True> successful[0m
[[34m2024-07-18T07:13:32.878+0530[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=parent_dag, execution_date=2024-07-18 01:41:28.205554+00:00, run_id=manual__2024-07-18T01:41:28.205554+00:00, run_start_date=2024-07-18 01:41:29.237506+00:00, run_end_date=2024-07-18 01:43:32.878804+00:00, run_duration=123.641298, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=c2dc310f9c774fb70b8256555b5d12ec[0m
[[34m2024-07-18T07:13:32.904+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:13:32.907+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:26.441051+00:00, run_end_date=2024-07-18 01:43:32.523641+00:00, run_duration=6.08259, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2780, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:43:25.645820+00:00, queued_by_job_id=2569, pid=20583[0m
[[34m2024-07-18T07:13:48.733+0530[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-07-18T07:14:10.623+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:10.624+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:10.624+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:10.627+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 20 and queue default[0m
[[34m2024-07-18T07:14:10.627+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:10.631+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:10.661+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:11.278+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:13.416+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:13.416+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:13.416+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:13.419+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 19 and queue default[0m
[[34m2024-07-18T07:14:13.419+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:13.423+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:13.423+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:13.430+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_accounts_to_int_accounts, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:11.378724+00:00, run_end_date=2024-07-18 01:44:12.648310+00:00, run_duration=1.26959, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2781, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:44:10.625320+00:00, queued_by_job_id=2569, pid=21741[0m
[[34m2024-07-18T07:14:13.454+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:14.117+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:14.894+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:14.895+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:14.895+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:14.898+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 18 and queue default[0m
[[34m2024-07-18T07:14:14.899+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:14.901+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:14.901+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:14.908+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_atms_to_int_atms, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:14.220956+00:00, run_end_date=2024-07-18 01:44:14.654263+00:00, run_duration=0.433307, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2782, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:44:13.417618+00:00, queued_by_job_id=2569, pid=21787[0m
[[34m2024-07-18T07:14:14.934+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:15.574+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:16.338+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:16.339+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:16.339+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:16.342+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 17 and queue default[0m
[[34m2024-07-18T07:14:16.342+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:16.345+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:16.375+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:16.404+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:16.409+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_bill_payments_to_int_bill_payments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:15.679180+00:00, run_end_date=2024-07-18 01:44:16.268594+00:00, run_duration=0.589414, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2783, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:44:14.896708+00:00, queued_by_job_id=2569, pid=21804[0m
[[34m2024-07-18T07:14:16.927+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:17.452+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:17.452+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:17.452+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:17.454+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 16 and queue default[0m
[[34m2024-07-18T07:14:17.454+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:17.457+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:17.457+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:17.461+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_branches_to_int_branches, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:17.009416+00:00, run_end_date=2024-07-18 01:44:17.345336+00:00, run_duration=0.33592, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2784, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:44:16.340223+00:00, queued_by_job_id=2569, pid=21829[0m
[[34m2024-07-18T07:14:17.479+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:18.049+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:19.665+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:19.665+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:19.666+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:19.667+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 15 and queue default[0m
[[34m2024-07-18T07:14:19.668+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:19.672+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:19.672+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:19.678+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cards_to_int_cards, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:18.151796+00:00, run_end_date=2024-07-18 01:44:18.982151+00:00, run_duration=0.830355, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2785, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:44:17.453320+00:00, queued_by_job_id=2569, pid=21847[0m
[[34m2024-07-18T07:14:19.705+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:20.396+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:21.445+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:21.446+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:21.446+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:21.448+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 14 and queue default[0m
[[34m2024-07-18T07:14:21.448+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:21.452+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:21.451+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:21.460+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cheques_to_int_cheques, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:20.502755+00:00, run_end_date=2024-07-18 01:44:20.998538+00:00, run_duration=0.495783, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2786, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:44:19.666546+00:00, queued_by_job_id=2569, pid=21884[0m
[[34m2024-07-18T07:14:21.485+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:22.164+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:23.599+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:23.600+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:23.600+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:23.602+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 13 and queue default[0m
[[34m2024-07-18T07:14:23.603+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:23.610+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:23.610+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:23.614+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_credit_scores_to_int_credit_scores, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:22.258936+00:00, run_end_date=2024-07-18 01:44:23.010727+00:00, run_duration=0.751791, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2787, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:44:21.446961+00:00, queued_by_job_id=2569, pid=21909[0m
[[34m2024-07-18T07:14:23.647+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:24.389+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:26.065+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:26.065+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:26.066+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:26.073+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 12 and queue default[0m
[[34m2024-07-18T07:14:26.073+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:26.077+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:26.077+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:26.083+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customer_support_to_int_customer_support, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:24.491683+00:00, run_end_date=2024-07-18 01:44:24.997891+00:00, run_duration=0.506208, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2788, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:44:23.601066+00:00, queued_by_job_id=2569, pid=21958[0m
[[34m2024-07-18T07:14:26.114+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:26.983+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:28.740+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:28.740+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:28.740+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:28.747+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 11 and queue default[0m
[[34m2024-07-18T07:14:28.747+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:28.753+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:28.754+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:28.762+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customers_to_int_customers, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:27.079457+00:00, run_end_date=2024-07-18 01:44:27.817063+00:00, run_duration=0.737606, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2789, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:44:26.068120+00:00, queued_by_job_id=2569, pid=22051[0m
[[34m2024-07-18T07:14:28.803+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:29.694+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[2024-07-18T07:14:29.796+0530] {base.py:791} ERROR - Exception during reset or similar
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 763, in _finalize_fairy
    fairy._reset(pool, transaction_was_reset)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/pool/base.py", line 1038, in _reset
    pool._dialect.do_rollback(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 683, in do_rollback
    dbapi_connection.rollback()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 582, in rollback
    self._cmysql.rollback()
_mysql_connector.MySQLInterfaceError: Lost connection to MySQL server during query
[[34m2024-07-18T07:14:31.012+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:31.012+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:31.013+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:31.015+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 10 and queue default[0m
[[34m2024-07-18T07:14:31.016+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:31.021+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:31.021+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:31.027+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_employees_to_int_employees, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:29.862861+00:00, run_end_date=2024-07-18 01:44:30.725573+00:00, run_duration=0.862712, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2790, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:44:28.741430+00:00, queued_by_job_id=2569, pid=22122[0m
[[34m2024-07-18T07:14:31.063+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:31.911+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:32.778+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:32.778+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:32.779+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:32.784+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-18T07:14:32.785+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:32.791+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:32.838+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:32.893+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:32.905+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_fixed_deposits_to_int_fixed_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:32.016369+00:00, run_end_date=2024-07-18 01:44:32.649113+00:00, run_duration=0.632744, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2791, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:44:31.013886+00:00, queued_by_job_id=2569, pid=22224[0m
[[34m2024-07-18T07:14:33.815+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:35.042+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:35.042+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:35.043+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:35.045+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-18T07:14:35.046+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:35.049+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:35.049+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:35.057+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_insurance_to_int_insurance, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:33.954577+00:00, run_end_date=2024-07-18 01:44:34.868290+00:00, run_duration=0.913713, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2792, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:44:32.780244+00:00, queued_by_job_id=2569, pid=22303[0m
[[34m2024-07-18T07:14:35.091+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:35.811+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:36.719+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:36.720+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:36.720+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:36.722+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-18T07:14:36.722+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:36.725+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:36.725+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:36.731+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_investments_to_int_investments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:35.912254+00:00, run_end_date=2024-07-18 01:44:36.352798+00:00, run_duration=0.440544, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2793, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:44:35.043859+00:00, queued_by_job_id=2569, pid=22338[0m
[[34m2024-07-18T07:14:36.756+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:37.364+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:38.610+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:38.610+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:38.611+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:38.613+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-18T07:14:38.613+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:38.617+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:38.617+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:38.621+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_loans_to_int_loans, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:37.470553+00:00, run_end_date=2024-07-18 01:44:38.057718+00:00, run_duration=0.587165, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2794, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:44:36.721169+00:00, queued_by_job_id=2569, pid=22363[0m
[[34m2024-07-18T07:14:38.642+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:39.186+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:40.852+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:40.852+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:40.853+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:40.855+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-18T07:14:40.855+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:40.861+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:40.860+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:40.868+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_mortgage_applications_to_int_mortgage_applications, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:39.264191+00:00, run_end_date=2024-07-18 01:44:39.736951+00:00, run_duration=0.47276, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2795, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:44:38.611653+00:00, queued_by_job_id=2569, pid=22388[0m
[[34m2024-07-18T07:14:40.892+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:41.434+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:42.886+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:42.887+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:42.887+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:42.890+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-18T07:14:42.890+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:42.895+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:42.895+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:42.901+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_online_banking_to_int_online_banking, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:41.520558+00:00, run_end_date=2024-07-18 01:44:41.983612+00:00, run_duration=0.463054, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2796, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:44:40.853821+00:00, queued_by_job_id=2569, pid=22413[0m
[[34m2024-07-18T07:14:42.927+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:43.554+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:45.116+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:45.117+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:45.117+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:45.120+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:14:45.120+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:45.123+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:45.123+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:45.127+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_recurring_deposits_to_int_recurring_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:43.640474+00:00, run_end_date=2024-07-18 01:44:44.072862+00:00, run_duration=0.432388, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2797, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:44:42.888134+00:00, queued_by_job_id=2569, pid=22451[0m
[[34m2024-07-18T07:14:45.151+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:45.687+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:46.869+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:46.869+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:46.869+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:46.871+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:14:46.872+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:46.874+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:46.874+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:46.878+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_savings_goals_to_int_savings_goals, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:45.770921+00:00, run_end_date=2024-07-18 01:44:46.218692+00:00, run_duration=0.447771, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2798, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:44:45.118646+00:00, queued_by_job_id=2569, pid=22476[0m
[[34m2024-07-18T07:14:46.903+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:47.447+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:49.053+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:49.053+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG mysql_data_transformation has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:14:49.053+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>[0m
[[34m2024-07-18T07:14:49.055+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:14:49.056+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:49.058+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:49.058+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py'][0m
[[34m2024-07-18T07:14:49.064+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_service_charges_to_int_service_charges, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:47.525513+00:00, run_end_date=2024-07-18 01:44:48.107835+00:00, run_duration=0.582322, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2799, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:44:46.870402+00:00, queued_by_job_id=2569, pid=22502[0m
[[34m2024-07-18T07:14:49.087+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py[0m
[[34m2024-07-18T07:14:49.672+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:14:51.923+0530[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun mysql_data_transformation @ 2024-07-18 01:37:00.986102+00:00: manual__2024-07-18T01:37:00.986102+00:00, state:running, queued_at: 2024-07-18 01:44:10.030762+00:00. externally triggered: True> successful[0m
[[34m2024-07-18T07:14:51.923+0530[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=mysql_data_transformation, execution_date=2024-07-18 01:37:00.986102+00:00, run_id=manual__2024-07-18T01:37:00.986102+00:00, run_start_date=2024-07-18 01:44:10.558087+00:00, run_end_date=2024-07-18 01:44:51.923414+00:00, run_duration=41.365327, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=3e31518e1a895412bcceab372924eeb7[0m
[[34m2024-07-18T07:14:51.935+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)[0m
[[34m2024-07-18T07:14:51.938+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_transactions_to_int_transactions, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:49.750229+00:00, run_end_date=2024-07-18 01:44:51.786080+00:00, run_duration=2.03585, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2800, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:44:49.054557+00:00, queued_by_job_id=2569, pid=22527[0m
[[34m2024-07-18T07:15:09.780+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:09.781+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:09.781+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:09.783+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_accounts_to_dlt_accounts', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 20 and queue default[0m
[[34m2024-07-18T07:15:09.784+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_accounts_to_dlt_accounts', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:09.786+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_accounts_to_dlt_accounts', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:09.822+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:10.660+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:11.992+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:11.993+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:11.993+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:11.996+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_atms_to_dlt_atms', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 19 and queue default[0m
[[34m2024-07-18T07:15:11.996+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_atms_to_dlt_atms', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:12.000+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_accounts_to_dlt_accounts', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:11.999+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_atms_to_dlt_atms', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:12.005+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_accounts_to_dlt_accounts, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:10.750230+00:00, run_end_date=2024-07-18 01:45:11.842863+00:00, run_duration=1.09263, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2801, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:45:09.781912+00:00, queued_by_job_id=2569, pid=23005[0m
[[34m2024-07-18T07:15:12.032+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:12.720+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:13.316+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:13.316+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:13.317+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:13.319+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_bill_payments_to_dlt_bill_payments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 18 and queue default[0m
[[34m2024-07-18T07:15:13.319+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_bill_payments_to_dlt_bill_payments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:13.321+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_bill_payments_to_dlt_bill_payments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:13.354+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:13.386+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_atms_to_dlt_atms', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:13.393+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_atms_to_dlt_atms, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:12.857131+00:00, run_end_date=2024-07-18 01:45:13.276776+00:00, run_duration=0.419645, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2802, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:45:11.994366+00:00, queued_by_job_id=2569, pid=23031[0m
[[34m2024-07-18T07:15:14.038+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:15.320+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:15.320+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:15.321+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:15.326+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_branches_to_dlt_branches', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 17 and queue default[0m
[[34m2024-07-18T07:15:15.326+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_branches_to_dlt_branches', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:15.329+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_bill_payments_to_dlt_bill_payments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:15.329+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_branches_to_dlt_branches', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:15.335+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_bill_payments_to_dlt_bill_payments, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:14.177368+00:00, run_end_date=2024-07-18 01:45:14.748609+00:00, run_duration=0.571241, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2803, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:45:13.317590+00:00, queued_by_job_id=2569, pid=23066[0m
[[34m2024-07-18T07:15:15.358+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:15.897+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:16.460+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:16.460+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:16.462+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:16.466+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cards_to_dlt_cards', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 16 and queue default[0m
[[34m2024-07-18T07:15:16.466+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cards_to_dlt_cards', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:16.469+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_branches_to_dlt_branches', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:16.469+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cards_to_dlt_cards', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:16.478+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_branches_to_dlt_branches, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:15.998975+00:00, run_end_date=2024-07-18 01:45:16.329103+00:00, run_duration=0.330128, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2804, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:45:15.322136+00:00, queued_by_job_id=2569, pid=23085[0m
[[34m2024-07-18T07:15:16.508+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:17.197+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:18.354+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:18.355+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:18.355+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:18.357+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cheques_to_dlt_cheques', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 15 and queue default[0m
[[34m2024-07-18T07:15:18.357+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cheques_to_dlt_cheques', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:18.360+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cards_to_dlt_cards', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:18.360+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cheques_to_dlt_cheques', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:18.365+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_cards_to_dlt_cards, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:17.295694+00:00, run_end_date=2024-07-18 01:45:17.827466+00:00, run_duration=0.531772, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2805, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:45:16.463419+00:00, queued_by_job_id=2569, pid=23112[0m
[[34m2024-07-18T07:15:18.390+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:19.187+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:20.533+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:20.533+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:20.534+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:20.535+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_credit_scores_to_dlt_credit_scores', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 14 and queue default[0m
[[34m2024-07-18T07:15:20.536+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_credit_scores_to_dlt_credit_scores', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:20.541+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cheques_to_dlt_cheques', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:20.540+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_credit_scores_to_dlt_credit_scores', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:20.548+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_cheques_to_dlt_cheques, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:19.281816+00:00, run_end_date=2024-07-18 01:45:19.614938+00:00, run_duration=0.333122, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2806, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:45:18.355748+00:00, queued_by_job_id=2569, pid=23155[0m
[[34m2024-07-18T07:15:20.573+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:21.312+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:22.356+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:22.357+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:22.357+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:22.359+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customer_support_to_dlt_customer_support', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 13 and queue default[0m
[[34m2024-07-18T07:15:22.359+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customer_support_to_dlt_customer_support', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:22.362+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_credit_scores_to_dlt_credit_scores', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:22.362+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customer_support_to_dlt_customer_support', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:22.367+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_credit_scores_to_dlt_credit_scores, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:21.427173+00:00, run_end_date=2024-07-18 01:45:21.969613+00:00, run_duration=0.54244, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2807, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:45:20.534563+00:00, queued_by_job_id=2569, pid=23196[0m
[[34m2024-07-18T07:15:22.392+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:23.075+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:23.826+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:23.827+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:23.827+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:23.829+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customers_to_dlt_customers', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 12 and queue default[0m
[[34m2024-07-18T07:15:23.829+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customers_to_dlt_customers', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:23.833+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customer_support_to_dlt_customer_support', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:23.832+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customers_to_dlt_customers', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:23.838+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_customer_support_to_dlt_customer_support, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:23.164628+00:00, run_end_date=2024-07-18 01:45:23.523704+00:00, run_duration=0.359076, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2808, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:45:22.358004+00:00, queued_by_job_id=2569, pid=23232[0m
[[34m2024-07-18T07:15:23.859+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:24.334+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:25.346+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:25.350+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:25.350+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:25.353+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_employees_to_dlt_employees', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 11 and queue default[0m
[[34m2024-07-18T07:15:25.353+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_employees_to_dlt_employees', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:25.358+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customers_to_dlt_customers', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:25.362+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_employees_to_dlt_employees', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:25.369+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_customers_to_dlt_customers, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:24.397578+00:00, run_end_date=2024-07-18 01:45:24.946205+00:00, run_duration=0.548627, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2809, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:45:23.827910+00:00, queued_by_job_id=2569, pid=23256[0m
[[34m2024-07-18T07:15:25.413+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:25.964+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:26.495+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:26.496+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:26.496+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:26.498+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue default[0m
[[34m2024-07-18T07:15:26.498+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:26.501+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:26.531+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:26.553+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_employees_to_dlt_employees', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:26.556+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_employees_to_dlt_employees, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:26.038706+00:00, run_end_date=2024-07-18 01:45:26.440270+00:00, run_duration=0.401564, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2810, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:45:25.351530+00:00, queued_by_job_id=2569, pid=23297[0m
[[34m2024-07-18T07:15:27.048+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:28.515+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:28.516+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:28.516+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:28.519+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_insurance_to_dlt_insurance', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default[0m
[[34m2024-07-18T07:15:28.520+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_insurance_to_dlt_insurance', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:28.523+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:28.523+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_insurance_to_dlt_insurance', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:28.530+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:27.135265+00:00, run_end_date=2024-07-18 01:45:27.510808+00:00, run_duration=0.375543, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2811, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:45:26.496895+00:00, queued_by_job_id=2569, pid=23344[0m
[[34m2024-07-18T07:15:28.557+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:29.137+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:29.658+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:29.658+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:29.658+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:29.661+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_investments_to_dlt_investments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default[0m
[[34m2024-07-18T07:15:29.661+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_investments_to_dlt_investments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:29.666+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_insurance_to_dlt_insurance', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:29.666+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_investments_to_dlt_investments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:29.670+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_insurance_to_dlt_insurance, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:29.222042+00:00, run_end_date=2024-07-18 01:45:29.555703+00:00, run_duration=0.333661, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2812, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:45:28.517654+00:00, queued_by_job_id=2569, pid=23409[0m
[[34m2024-07-18T07:15:29.690+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:30.227+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:30.762+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:30.762+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:30.762+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:30.764+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_loans_to_dlt_loans', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default[0m
[[34m2024-07-18T07:15:30.765+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_loans_to_dlt_loans', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:30.768+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_loans_to_dlt_loans', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:30.798+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:30.850+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_investments_to_dlt_investments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:30.859+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_investments_to_dlt_investments, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:30.304172+00:00, run_end_date=2024-07-18 01:45:30.651369+00:00, run_duration=0.347197, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2813, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:45:29.659572+00:00, queued_by_job_id=2569, pid=23426[0m
[[34m2024-07-18T07:15:31.481+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:32.524+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:32.524+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:32.525+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:32.531+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2024-07-18T07:15:32.531+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:32.534+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_loans_to_dlt_loans', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:32.535+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:32.540+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_loans_to_dlt_loans, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:31.622634+00:00, run_end_date=2024-07-18 01:45:32.103593+00:00, run_duration=0.480959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2814, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:45:30.763462+00:00, queued_by_job_id=2569, pid=23475[0m
[[34m2024-07-18T07:15:32.581+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:33.455+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:34.334+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:34.335+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:34.335+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:34.341+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_online_banking_to_dlt_online_banking', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2024-07-18T07:15:34.342+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_online_banking_to_dlt_online_banking', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:34.345+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:34.345+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_online_banking_to_dlt_online_banking', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:34.354+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:33.640397+00:00, run_end_date=2024-07-18 01:45:34.050187+00:00, run_duration=0.40979, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2815, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:45:32.525491+00:00, queued_by_job_id=2569, pid=23572[0m
[[34m2024-07-18T07:15:34.381+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:35.052+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:36.583+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:36.584+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:36.584+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:36.589+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2024-07-18T07:15:36.590+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:36.603+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:36.610+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_online_banking_to_dlt_online_banking', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:36.637+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_online_banking_to_dlt_online_banking, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:35.168641+00:00, run_end_date=2024-07-18 01:45:35.607691+00:00, run_duration=0.43905, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2816, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:45:34.338046+00:00, queued_by_job_id=2569, pid=23657[0m
[[34m2024-07-18T07:15:36.676+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:37.399+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:38.833+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:38.834+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:38.834+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:38.838+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_savings_goals_to_dlt_savings_goals', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2024-07-18T07:15:38.839+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_savings_goals_to_dlt_savings_goals', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:38.842+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:38.841+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_savings_goals_to_dlt_savings_goals', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:38.846+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:37.517612+00:00, run_end_date=2024-07-18 01:45:37.895771+00:00, run_duration=0.378159, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2817, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:45:36.585446+00:00, queued_by_job_id=2569, pid=23696[0m
[[34m2024-07-18T07:15:38.875+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:39.560+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:41.031+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:41.031+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:41.032+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:41.033+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_service_charges_to_dlt_service_charges', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-07-18T07:15:41.034+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_service_charges_to_dlt_service_charges', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:41.037+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_savings_goals_to_dlt_savings_goals', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:41.037+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_service_charges_to_dlt_service_charges', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:41.042+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_savings_goals_to_dlt_savings_goals, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:39.642595+00:00, run_end_date=2024-07-18 01:45:40.081467+00:00, run_duration=0.438872, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2818, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:45:38.835720+00:00, queued_by_job_id=2569, pid=23721[0m
[[34m2024-07-18T07:15:41.064+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:41.542+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:42.172+0530[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:42.172+0530[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG dag_incremental_script has 0/16 running and queued tasks[0m
[[34m2024-07-18T07:15:42.173+0530[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>[0m
[[34m2024-07-18T07:15:42.176+0530[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_transactions_to_dlt_transactions', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-07-18T07:15:42.177+0530[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_transactions_to_dlt_transactions', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:42.181+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_service_charges_to_dlt_service_charges', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:42.180+0530[0m] {[34mlocal_executor.py:[0m90} INFO[0m - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_transactions_to_dlt_transactions', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py'][0m
[[34m2024-07-18T07:15:42.187+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_service_charges_to_dlt_service_charges, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:41.618096+00:00, run_end_date=2024-07-18 01:45:42.000352+00:00, run_duration=0.382256, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2819, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:45:41.032483+00:00, queued_by_job_id=2569, pid=23746[0m
[[34m2024-07-18T07:15:42.222+0530[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py[0m
[[34m2024-07-18T07:15:43.081+0530[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali[0m
[[34m2024-07-18T07:15:45.437+0530[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun dag_incremental_script @ 2024-07-18 01:45:08.918618+00:00: manual__2024-07-18T01:45:08.918618+00:00, state:running, queued_at: 2024-07-18 01:45:08.947679+00:00. externally triggered: True> successful[0m
[[34m2024-07-18T07:15:45.437+0530[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=dag_incremental_script, execution_date=2024-07-18 01:45:08.918618+00:00, run_id=manual__2024-07-18T01:45:08.918618+00:00, run_start_date=2024-07-18 01:45:09.732984+00:00, run_end_date=2024-07-18 01:45:45.437656+00:00, run_duration=35.704672, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=a2e952aa7ce10146e64886eb9de60f00[0m
[[34m2024-07-18T07:15:45.449+0530[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_transactions_to_dlt_transactions', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)[0m
[[34m2024-07-18T07:15:45.453+0530[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_transactions_to_dlt_transactions, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:43.207600+00:00, run_end_date=2024-07-18 01:45:44.467663+00:00, run_duration=1.26006, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2820, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:45:42.174008+00:00, queued_by_job_id=2569, pid=23843[0m
[[34m2024-07-18T07:18:48.804+0530[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
