2024-07-18 07:03:48,316 INFO - Task context logging is enabled
2024-07-18 07:03:48,318 INFO - Loaded executor: LocalExecutor
2024-07-18 07:03:48,364 INFO - Starting the scheduler
2024-07-18 07:03:48,365 INFO - Processing each file at most -1 times
2024-07-18 07:03:48,554 INFO - Launched DagFileProcessorManager with pid: 3891
2024-07-18 07:03:48,556 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-07-18 07:03:48,563 INFO - Configured default timezone UTC
2024-07-18 07:03:48,591 INFO - Marked 1 SchedulerJob instances as failed
2024-07-18 07:03:48,619 INFO - Reset the following 15 orphaned TaskInstances:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [running]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [running]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]>
2024-07-18 07:03:48,906 INFO - 16 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:48,907 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:03:48,908 INFO - DAG parent_dag has 1/16 running and queued tasks
2024-07-18 07:03:48,908 INFO - DAG parent_dag has 2/16 running and queued tasks
2024-07-18 07:03:48,909 INFO - DAG parent_dag has 3/16 running and queued tasks
2024-07-18 07:03:48,910 INFO - DAG parent_dag has 4/16 running and queued tasks
2024-07-18 07:03:48,911 INFO - DAG parent_dag has 5/16 running and queued tasks
2024-07-18 07:03:48,912 INFO - DAG parent_dag has 6/16 running and queued tasks
2024-07-18 07:03:48,912 INFO - DAG parent_dag has 7/16 running and queued tasks
2024-07-18 07:03:48,913 INFO - DAG parent_dag has 8/16 running and queued tasks
2024-07-18 07:03:48,913 INFO - DAG parent_dag has 9/16 running and queued tasks
2024-07-18 07:03:48,913 INFO - DAG parent_dag has 10/16 running and queued tasks
2024-07-18 07:03:48,914 INFO - DAG parent_dag has 11/16 running and queued tasks
2024-07-18 07:03:48,914 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:03:48,914 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:03:48,914 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:48,915 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:48,915 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:48,921 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,922 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,923 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,924 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,924 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,925 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,925 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,926 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,926 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,927 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,927 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,928 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,928 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,928 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,928 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,928 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,929 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,929 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,929 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,929 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,930 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,930 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:48,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,934 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,935 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,935 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,936 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,936 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,937 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,939 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,942 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,942 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,939 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,944 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,947 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,947 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,951 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,952 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:48,953 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:49,012 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,016 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,016 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,020 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,017 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,022 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,036 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,048 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,051 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,054 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,072 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,084 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,110 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,112 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,116 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,128 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:49,363 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:49,398 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:49,399 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:49,399 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:49,399 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:49,399 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:49,400 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:49,400 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:49,400 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:50,753 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:50,758 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:50,759 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:50,760 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:50,760 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:50,761 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:50,761 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:50,762 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:50,771 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:51,103 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,157 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,275 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,373 INFO - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,424 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,536 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,540 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,588 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,603 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,607 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,615 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,680 INFO - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,748 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,765 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,774 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:51,904 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,956 INFO - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,964 INFO - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,969 INFO - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:51,997 INFO - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,052 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,126 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:52,140 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:52,140 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:52,141 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:52,141 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:52,142 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:52,146 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:52,147 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:52,147 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:52,148 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:52,267 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,367 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:52,528 INFO - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,538 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:52,736 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,731 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:52,768 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:52,835 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:52,885 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:52,930 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:52,977 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:52,963 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,147 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:53,159 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:53,213 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,218 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,234 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,395 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,418 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,552 INFO - 12 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:53,506 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,552 INFO - DAG parent_dag has 5/16 running and queued tasks
2024-07-18 07:03:53,553 INFO - DAG parent_dag has 6/16 running and queued tasks
2024-07-18 07:03:53,553 INFO - DAG parent_dag has 7/16 running and queued tasks
2024-07-18 07:03:53,566 INFO - DAG parent_dag has 8/16 running and queued tasks
2024-07-18 07:03:53,566 INFO - DAG parent_dag has 9/16 running and queued tasks
2024-07-18 07:03:53,567 INFO - DAG parent_dag has 10/16 running and queued tasks
2024-07-18 07:03:53,570 INFO - DAG parent_dag has 11/16 running and queued tasks
2024-07-18 07:03:53,571 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:03:53,571 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:03:53,571 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:53,572 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:53,572 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:53,572 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:53,573 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:53,575 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,591 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:53,592 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,592 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:53,593 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,593 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:03:53,593 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,597 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,601 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,602 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,602 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,603 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,603 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,604 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,604 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,605 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,605 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,606 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,606 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,607 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,608 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:53,608 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,612 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,615 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,617 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,617 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,620 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,620 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,623 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,624 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,623 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,624 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,625 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,624 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,625 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,626 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,627 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,630 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,626 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,634 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,635 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:03:53,635 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,636 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:53,635 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:53,665 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.178349+00:00, run_end_date=2024-07-18 01:33:53.012331+00:00, run_duration=0.833982, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2573, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4137
2024-07-18 07:03:53,666 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.715452+00:00, run_end_date=2024-07-18 01:33:52.569335+00:00, run_duration=0.853883, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2571, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4113
2024-07-18 07:03:53,666 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.280484+00:00, run_end_date=2024-07-18 01:33:52.752804+00:00, run_duration=0.47232, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2576, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4141
2024-07-18 07:03:53,667 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.363237+00:00, run_end_date=2024-07-18 01:33:53.256591+00:00, run_duration=0.893354, state=success, executor_state=failed, try_number=2, max_tries=1, job_id=2578, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4148
2024-07-18 07:03:53,667 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.623242+00:00, run_end_date=2024-07-18 01:33:53.386218+00:00, run_duration=0.762976, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2580, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4159
2024-07-18 07:03:53,668 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.221443+00:00, run_end_date=2024-07-18 01:33:52.981402+00:00, run_duration=0.759959, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2575, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4138
2024-07-18 07:03:53,668 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.429495+00:00, run_end_date=2024-07-18 01:33:53.065000+00:00, run_duration=0.635505, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2577, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4156
2024-07-18 07:03:53,669 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.911441+00:00, run_end_date=2024-07-18 01:33:52.661656+00:00, run_duration=0.750215, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2572, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4126
2024-07-18 07:03:53,669 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:51.660445+00:00, run_end_date=2024-07-18 01:33:52.625014+00:00, run_duration=0.964569, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2570, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4119
2024-07-18 07:03:53,672 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,670 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.338197+00:00, run_end_date=2024-07-18 01:33:53.200699+00:00, run_duration=0.862502, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2574, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4147
2024-07-18 07:03:53,679 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:52.523519+00:00, run_end_date=2024-07-18 01:33:53.327690+00:00, run_duration=0.804171, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2579, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4158
2024-07-18 07:03:53,726 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,748 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,765 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,786 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,788 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,798 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,784 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,796 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,811 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,828 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:53,895 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:53,968 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:53,968 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:53,969 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:53,969 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:53,969 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:53,970 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:53,970 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:53,998 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:53,999 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:53,999 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:54,014 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:54,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:54,015 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:54,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:54,051 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:54,050 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:54,068 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:54,075 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.118931+00:00, run_end_date=2024-07-18 01:33:53.657028+00:00, run_duration=0.538097, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2582, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4170
2024-07-18 07:03:54,035 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:54,148 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:54,239 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:54,392 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:54,392 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:54,392 INFO - Not executing <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:54,392 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:54,393 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:54,393 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:54,393 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:54,393 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:54,393 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:54,414 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:54,433 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.052748+00:00, run_end_date=2024-07-18 01:33:53.812855+00:00, run_duration=0.760107, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2581, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4169
2024-07-18 07:03:54,547 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:54,569 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:54,657 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:55,533 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:55,558 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:55,649 INFO - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:55,650 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:03:55,650 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:55,651 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:55,651 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,652 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,652 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,653 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,653 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,654 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,654 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,655 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,655 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:55,660 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:55,661 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,662 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:55,663 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,663 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:55,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,673 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:55,674 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:55,675 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:03:55,679 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,683 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,683 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:55,685 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.360249+00:00, run_end_date=2024-07-18 01:33:54.435911+00:00, run_duration=1.07566, state=success, executor_state=failed, try_number=2, max_tries=1, job_id=2583, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4220
2024-07-18 07:03:55,686 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.398163+00:00, run_end_date=2024-07-18 01:33:54.402660+00:00, run_duration=1.0045, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2584, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4198
2024-07-18 07:03:55,687 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:53.397320+00:00, run_end_date=2024-07-18 01:33:54.371660+00:00, run_duration=0.97434, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2585, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:48.916394+00:00, queued_by_job_id=2569, pid=4199
2024-07-18 07:03:55,791 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:55,820 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:55,824 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:55,814 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:55,892 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:55,893 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,893 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,894 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,894 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,902 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,903 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,903 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:55,904 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:55,928 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:55,949 INFO - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,096 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,140 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,149 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,169 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,179 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,197 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,218 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,252 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,343 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,371 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,456 INFO - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,467 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,467 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,485 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,532 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,541 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,595 INFO - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,708 INFO - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:56,823 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:56,842 INFO - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:57,039 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,040 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:57,040 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,040 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,041 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,041 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,042 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,042 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,054 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,071 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:57,071 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,082 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,172 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,229 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:57,260 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,260 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:57,261 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,261 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,261 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,264 INFO - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:57,262 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,266 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,267 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,267 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,268 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,268 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,277 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:57,278 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,281 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,285 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,292 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.284446+00:00, run_end_date=2024-07-18 01:33:56.947047+00:00, run_duration=0.662601, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2586, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4453
2024-07-18 07:03:57,271 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,420 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:57,499 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,564 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,564 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:03:57,565 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:57,565 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:57,565 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,566 INFO - Not executing <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,566 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,575 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,575 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,577 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:57,584 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:57,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,585 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:57,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,585 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:57,586 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,604 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,620 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,624 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,628 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,629 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,603 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,647 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.533262+00:00, run_end_date=2024-07-18 01:33:57.297474+00:00, run_duration=0.764212, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2589, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4455
2024-07-18 07:03:57,648 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.395458+00:00, run_end_date=2024-07-18 01:33:57.030894+00:00, run_duration=0.635436, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2587, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4454
2024-07-18 07:03:57,628 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,699 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:57,696 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:57,682 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,796 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:57,888 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,888 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:57,889 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:57,889 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,889 INFO - Not executing <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,890 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,890 INFO - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,898 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,899 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,899 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:57,899 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:57,900 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:57,845 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,924 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:03:57,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,924 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:03:57,925 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,856 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:57,938 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:57,954 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,959 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,959 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,960 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:57,964 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:57,978 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.598704+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=1, job_id=2588, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4456
2024-07-18 07:03:57,979 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.780295+00:00, run_end_date=2024-07-18 01:33:57.394653+00:00, run_duration=0.614358, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2594, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4466
2024-07-18 07:03:57,979 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.720978+00:00, run_end_date=2024-07-18 01:33:57.435938+00:00, run_duration=0.71496, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2590, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:54.000110+00:00, queued_by_job_id=2569, pid=4459
2024-07-18 07:03:58,039 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,051 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:58,063 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:58,105 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:58,100 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,205 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,205 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:03:58,206 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:03:58,206 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:58,206 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,207 INFO - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,207 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,207 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,208 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,208 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,208 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,225 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:58,226 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,226 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:03:58,226 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,227 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:03:58,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,238 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,242 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,243 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,243 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,243 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,242 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,250 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,258 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:58,260 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.894438+00:00, run_end_date=2024-07-18 01:33:57.640639+00:00, run_duration=0.746201, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2593, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4482
2024-07-18 07:03:58,261 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.855847+00:00, run_end_date=2024-07-18 01:33:57.625575+00:00, run_duration=0.769728, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2591, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4480
2024-07-18 07:03:58,261 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.866844+00:00, run_end_date=2024-07-18 01:33:57.876966+00:00, run_duration=1.01012, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2595, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4481
2024-07-18 07:03:58,262 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.828746+00:00, run_end_date=2024-07-18 01:33:57.813133+00:00, run_duration=0.984387, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2592, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4472
2024-07-18 07:03:58,300 INFO - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:58,286 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:58,328 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,344 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,367 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,484 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,484 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:58,484 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,485 INFO - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,485 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,485 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,486 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,486 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,486 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,486 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,487 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,492 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:03:58,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,497 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,505 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:56.981430+00:00, run_end_date=2024-07-18 01:33:58.085032+00:00, run_duration=1.1036, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2596, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:54.000110+00:00, queued_by_job_id=2569, pid=4484
2024-07-18 07:03:58,515 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,479 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:58,632 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,633 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:03:58,633 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,633 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,634 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,634 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,634 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,635 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,635 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,643 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:03:58,644 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,647 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:03:58,685 WARNING - Failing (1) jobs without heartbeat after 2024-07-18 01:28:58.661441+00:00
2024-07-18 07:03:58,686 ERROR - Detected zombie job: {'full_filepath': '//home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py', 'processor_subdir': '/home/kali/Desktop/projects/git/bank_data_processing/dags', 'msg': "{'DAG Id': 'parent_dag', 'Task Id': 'raw_load_bill_payments.tuncate_table', 'Run Id': 'manual__2024-07-18T01:28:18.110991+00:00', 'Hostname': 'kali'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fde483e4490>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2024-07-18 07:03:58,691 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:58,671 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:58,692 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,707 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:03:58,904 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:03:58,904 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,904 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,905 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,905 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,905 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,905 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,906 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:03:58,906 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:03:58,908 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,908 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:03:58,913 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:57.330601+00:00, run_end_date=2024-07-18 01:33:58.305743+00:00, run_duration=0.975142, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2597, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4500
2024-07-18 07:03:58,913 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:57.772257+00:00, run_end_date=2024-07-18 01:33:58.543220+00:00, run_duration=0.770963, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2598, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:53.574262+00:00, queued_by_job_id=2569, pid=4540
2024-07-18 07:03:59,013 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:03:59,227 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:03:59,492 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:03:59,707 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:00,055 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,062 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,100 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,089 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:00,192 INFO - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:00,193 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:04:00,194 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:04:00,195 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:00,195 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,210 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,211 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,211 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,211 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,212 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,212 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,212 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:00,227 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:00,227 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,228 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:00,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,228 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:00,229 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,230 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,243 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,252 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,254 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,258 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:00,259 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:00,259 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:00,274 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:58.751210+00:00, run_end_date=2024-07-18 01:33:59.455792+00:00, run_duration=0.704582, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2600, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4605
2024-07-18 07:04:00,275 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:59.022597+00:00, run_end_date=2024-07-18 01:33:59.888286+00:00, run_duration=0.865689, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2601, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4631
2024-07-18 07:04:00,275 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:58.488991+00:00, run_end_date=2024-07-18 01:33:59.319389+00:00, run_duration=0.830398, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2599, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:55.657232+00:00, queued_by_job_id=2569, pid=4603
2024-07-18 07:04:00,312 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,317 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,387 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,379 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:00,391 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:00,428 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:00,444 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,464 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,476 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:00,477 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:00,477 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,478 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,478 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,482 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,483 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,483 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,484 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,484 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,484 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:00,492 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:00,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,503 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:00,560 INFO - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,603 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,539 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:00,635 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:00,673 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:00,679 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,679 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,680 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,680 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,680 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,680 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,680 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:00,681 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:00,780 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,791 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:00,867 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,914 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:00,983 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:01,188 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:01,216 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:01,233 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:01,278 INFO - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:01,459 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:01,737 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:01,829 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:01,830 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:01,830 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:01,831 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:01,831 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:01,832 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:01,832 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:01,832 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:01,833 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:01,852 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:01,853 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:01,859 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:01,867 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:01,881 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:33:59.551010+00:00, run_end_date=2024-07-18 01:34:00.347025+00:00, run_duration=0.796015, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2602, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.055542+00:00, queued_by_job_id=2569, pid=4687
2024-07-18 07:04:01,935 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:01,964 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:02,045 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:02,000 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:02,130 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:02,240 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,240 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:04:02,241 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:02,241 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,241 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,242 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,242 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,243 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,244 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,251 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:02,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,253 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:02,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,260 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:02,260 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,262 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,276 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.949711+00:00, run_end_date=2024-07-18 01:34:01.780446+00:00, run_duration=0.830735, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2605, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4756
2024-07-18 07:04:02,356 INFO - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:02,386 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:02,359 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:02,415 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:02,452 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:02,659 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET last_scheduling_decision=%(last_scheduling_decision)s, updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'last_scheduling_decision': datetime.datetime(2024, 7, 18, 1, 34, 1, 750070), 'updated_at': datetime.datetime(2024, 7, 18, 1, 34, 1, 777636), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET last_scheduling_decision=%(last_scheduling_decision)s, updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'last_scheduling_decision': datetime.datetime(2024, 7, 18, 1, 34, 1, 750070), 'updated_at': datetime.datetime(2024, 7, 18, 1, 34, 1, 777636), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:04:02,744 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,744 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:02,745 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,745 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,745 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,746 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,746 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,746 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,747 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,755 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:02,756 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,762 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:02,763 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:02,770 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,780 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.870962+00:00, run_end_date=2024-07-18 01:34:01.912204+00:00, run_duration=1.04124, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2604, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.274781+00:00, queued_by_job_id=2569, pid=4755
2024-07-18 07:04:02,780 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.258272+00:00, run_end_date=2024-07-18 01:34:02.151095+00:00, run_duration=0.892823, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2608, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4759
2024-07-18 07:04:02,752 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'updated_at': datetime.datetime(2024, 7, 18, 1, 33, 58, 456968), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE dag_run SET updated_at=%(updated_at)s WHERE dag_run.id = %(dag_run_id)s]
[parameters: {'updated_at': datetime.datetime(2024, 7, 18, 1, 33, 58, 456968), 'dag_run_id': 1312}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:04:02,867 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:02,955 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:02,972 INFO - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,973 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:04:02,973 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:04:02,973 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:04:02,974 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:04:02,974 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:02,984 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:02,985 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,985 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:02,986 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,989 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,995 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:02,999 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,000 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,012 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=None
2024-07-18 07:04:03,012 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:04:02,995 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:03,033 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:04:03,088 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:03,106 INFO - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=, end_date=20240718T013403
2024-07-18 07:04:03,127 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:03,184 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=None
2024-07-18 07:04:03,129 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:04:03,185 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:04:03,210 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:04:03,241 INFO - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=, end_date=20240718T013403
2024-07-18 07:04:03,517 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:03,659 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:03,719 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:03,847 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:03,889 INFO - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:03,921 INFO - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:03,926 INFO - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:03,926 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:04:03,927 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:04:03,927 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:04:03,927 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:04:03,936 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:03,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,936 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:03,937 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,937 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:04:03,937 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,940 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,943 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,946 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:04:03,948 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,948 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,948 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,949 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,949 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:03,968 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.619264+00:00, run_end_date=2024-07-18 01:34:03.308959+00:00, run_duration=1.6897, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.901182+00:00, queued_by_job_id=2569, pid=4776
2024-07-18 07:04:03,968 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.636648+00:00, run_end_date=2024-07-18 01:34:02.894218+00:00, run_duration=2.25757, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2603, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4746
2024-07-18 07:04:03,969 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.601360+00:00, run_end_date=2024-07-18 01:34:02.858226+00:00, run_duration=1.25687, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2611, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.576453+00:00, queued_by_job_id=2569, pid=4773
2024-07-18 07:04:03,969 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.571884+00:00, run_end_date=2024-07-18 01:34:02.857335+00:00, run_duration=1.28545, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2610, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4769
2024-07-18 07:04:03,970 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.545275+00:00, run_end_date=None, run_duration=None, state=running, executor_state=failed, try_number=1, max_tries=1, job_id=2609, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.209294+00:00, queued_by_job_id=2569, pid=4765
2024-07-18 07:04:04,020 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:04,076 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:04,096 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:04:04,572 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:04,903 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:04,915 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:05,276 INFO - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:05,300 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,373 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:05,395 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.033834+00:00, run_end_date=2024-07-18 01:34:04.294343+00:00, run_duration=3.26051, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2606, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.487932+00:00, queued_by_job_id=2569, pid=4757
2024-07-18 07:04:05,627 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,671 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:05,684 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,700 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,814 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,822 INFO - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:05,857 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:04:05,876 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:05,934 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:06,057 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:06,064 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:04:06,625 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:06,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:06,641 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:02.203657+00:00, run_end_date=2024-07-18 01:34:05.269942+00:00, run_duration=3.06628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2613, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:58.636129+00:00, queued_by_job_id=2569, pid=4816
2024-07-18 07:04:06,642 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.076042+00:00, run_end_date=2024-07-18 01:34:05.621482+00:00, run_duration=1.54544, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2616, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:01.834022+00:00, queued_by_job_id=2569, pid=4935
2024-07-18 07:04:07,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,773 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,773 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:07,779 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:00.977032+00:00, run_end_date=2024-07-18 01:34:07.467875+00:00, run_duration=6.49084, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2607, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:33:57.901182+00:00, queued_by_job_id=2569, pid=4758
2024-07-18 07:04:07,779 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.178537+00:00, run_end_date=2024-07-18 01:34:06.993625+00:00, run_duration=2.81509, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2617, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.214285+00:00, queued_by_job_id=2569, pid=4943
2024-07-18 07:04:07,779 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:04.273797+00:00, run_end_date=2024-07-18 01:34:06.343563+00:00, run_duration=2.06977, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2618, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:00.485829+00:00, queued_by_job_id=2569, pid=4951
2024-07-18 07:04:07,780 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.342433+00:00, run_end_date=2024-07-18 01:34:06.606533+00:00, run_duration=1.2641, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2619, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.245463+00:00, queued_by_job_id=2569, pid=5006
2024-07-18 07:04:07,780 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.752867+00:00, run_end_date=2024-07-18 01:34:07.026116+00:00, run_duration=1.27325, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2620, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.245463+00:00, queued_by_job_id=2569, pid=5015
2024-07-18 07:04:07,780 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.059850+00:00, run_end_date=2024-07-18 01:34:07.409916+00:00, run_duration=1.35007, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2622, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.748200+00:00, queued_by_job_id=2569, pid=5021
2024-07-18 07:04:07,781 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.100271+00:00, run_end_date=2024-07-18 01:34:07.314235+00:00, run_duration=1.21396, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2623, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.975676+00:00, queued_by_job_id=2569, pid=5022
2024-07-18 07:04:07,781 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.913053+00:00, run_end_date=2024-07-18 01:34:07.137610+00:00, run_duration=1.22456, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2621, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:02.975676+00:00, queued_by_job_id=2569, pid=5018
2024-07-18 07:04:07,781 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.357740+00:00, run_end_date=2024-07-18 01:34:07.458216+00:00, run_duration=1.10048, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2626, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5040
2024-07-18 07:04:08,796 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:08,803 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.294182+00:00, run_end_date=2024-07-18 01:34:07.663677+00:00, run_duration=1.3695, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2624, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5039
2024-07-18 07:04:08,825 WARNING - Failing (1) jobs without heartbeat after 2024-07-18 01:29:08.819813+00:00
2024-07-18 07:04:08,826 ERROR - Detected zombie job: {'full_filepath': '//home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py', 'processor_subdir': '/home/kali/Desktop/projects/git/bank_data_processing/dags', 'msg': "{'DAG Id': 'parent_dag', 'Task Id': 'raw_load_service_charges.tuncate_table', 'Run Id': 'manual__2024-07-18T01:28:18.110991+00:00', 'Hostname': 'kali'}", 'simple_task_instance': <airflow.models.taskinstance.SimpleTaskInstance object at 0x7fde4587dc50>, 'is_failure_callback': True} (See https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html#zombie-undead-tasks)
2024-07-18 07:04:12,339 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:04:12,342 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.225213+00:00, run_end_date=2024-07-18 01:34:11.234802+00:00, run_duration=5.00959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2625, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:34:03.928710+00:00, queued_by_job_id=2569, pid=5026
2024-07-18 07:05:27,597 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:27,598 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:27,598 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:27,601 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:27,601 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:27,604 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:27,637 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:28,247 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:28,325 INFO - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:28,771 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:29,506 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:29,507 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:29,507 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:29,509 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:29,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:29,514 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:29,513 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:29,520 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:28.438019+00:00, run_end_date=2024-07-18 01:35:28.707653+00:00, run_duration=0.269634, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2627, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:27.599412+00:00, queued_by_job_id=2569, pid=7494
2024-07-18 07:05:29,544 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:30,266 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:30,376 INFO - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:30,802 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:31,572 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:31,572 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:31,573 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:31,575 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:05:31,575 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:31,581 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:31,580 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:31,588 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:30.508168+00:00, run_end_date=2024-07-18 01:35:30.741804+00:00, run_duration=0.233636, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2628, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:29.507864+00:00, queued_by_job_id=2569, pid=7531
2024-07-18 07:05:31,623 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:32,375 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:32,453 INFO - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:33,852 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:33,856 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:32.574242+00:00, run_end_date=2024-07-18 01:35:33.088071+00:00, run_duration=0.513829, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2629, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:31.573588+00:00, queued_by_job_id=2569, pid=7592
2024-07-18 07:05:38,889 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:38,889 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:38,889 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:38,892 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:38,892 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:38,897 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:38,935 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:39,737 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:39,811 INFO - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:40,429 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:40,640 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:40,641 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:40,641 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:40,646 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:40,647 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:40,650 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:05:40,650 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:40,654 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:39.954491+00:00, run_end_date=2024-07-18 01:35:40.331535+00:00, run_duration=0.377044, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2630, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:38.890322+00:00, queued_by_job_id=2569, pid=7808
2024-07-18 07:05:40,687 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:41,820 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:41,958 INFO - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:42,582 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:42,919 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:42,919 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:42,919 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:42,922 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:05:42,923 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:42,928 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:05:42,927 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:42,937 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:42.160060+00:00, run_end_date=2024-07-18 01:35:42.487688+00:00, run_duration=0.327628, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2631, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:40.642643+00:00, queued_by_job_id=2569, pid=7879
2024-07-18 07:05:42,964 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:43,763 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:43,851 INFO - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:44,144 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 35, 44, 25148), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 3, 'job_id': '2632', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 35, 44, 114673), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_atms.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 35, 44, 25148), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 3, 'job_id': '2632', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 35, 44, 114673), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_atms.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:05:45,280 INFO - 16 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:45,281 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:05:45,281 INFO - DAG parent_dag has 1/16 running and queued tasks
2024-07-18 07:05:45,281 INFO - DAG parent_dag has 2/16 running and queued tasks
2024-07-18 07:05:45,281 INFO - DAG parent_dag has 3/16 running and queued tasks
2024-07-18 07:05:45,282 INFO - DAG parent_dag has 4/16 running and queued tasks
2024-07-18 07:05:45,282 INFO - DAG parent_dag has 5/16 running and queued tasks
2024-07-18 07:05:45,282 INFO - DAG parent_dag has 6/16 running and queued tasks
2024-07-18 07:05:45,282 INFO - DAG parent_dag has 7/16 running and queued tasks
2024-07-18 07:05:45,282 INFO - DAG parent_dag has 8/16 running and queued tasks
2024-07-18 07:05:45,283 INFO - DAG parent_dag has 9/16 running and queued tasks
2024-07-18 07:05:45,283 INFO - DAG parent_dag has 10/16 running and queued tasks
2024-07-18 07:05:45,283 INFO - DAG parent_dag has 11/16 running and queued tasks
2024-07-18 07:05:45,283 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:05:45,283 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:45,284 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:45,284 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:45,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:45,288 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,288 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,288 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,289 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,289 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,289 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,290 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,290 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,290 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,290 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,291 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,291 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,293 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,293 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,294 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,294 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,295 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,295 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,296 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,296 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,297 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,297 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,298 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,299 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,299 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,299 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,300 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,300 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:45,300 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,303 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,304 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,304 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,304 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,304 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,305 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,304 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,310 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,319 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,325 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,328 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,330 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,342 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,350 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,355 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,359 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:05:45,346 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:45,369 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,373 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,375 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,372 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,409 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:32.574242+00:00, run_end_date=2024-07-18 01:35:33.088071+00:00, run_duration=0.513829, state=None, executor_state=failed, try_number=3, max_tries=3, job_id=2629, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:42.920839+00:00, queued_by_job_id=2569, pid=7592
2024-07-18 07:05:45,424 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,436 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,434 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,448 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,448 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,466 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,465 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,496 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,521 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,533 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,533 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,569 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:45,965 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:45,965 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:45,965 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:45,966 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:45,966 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:45,967 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:45,967 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:45,968 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:45,968 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:46,337 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:46,599 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:47,531 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:47,533 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:47,535 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:47,535 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:47,536 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:47,537 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:47,537 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:47,538 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:47,538 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:47,541 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:47,838 INFO - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:48,282 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:48,379 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:48,587 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:48,598 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:48,723 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:48,781 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:48,806 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:48,825 INFO - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,054 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:49,055 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:49,056 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,057 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,058 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,074 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,076 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,078 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,091 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,091 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,092 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:49,090 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:49,109 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:49,114 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:49,120 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:49,130 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:05:49,140 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,172 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:47.055549+00:00, run_end_date=2024-07-18 01:35:48.071075+00:00, run_duration=1.01553, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2633, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8125
2024-07-18 07:05:49,318 INFO - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,346 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:49,348 INFO - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,359 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:49,437 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:49,585 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:49,585 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,586 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,603 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,603 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,604 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,605 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,605 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:49,606 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:49,616 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,679 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:49,787 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,835 INFO - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:49,868 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:49,901 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,013 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:50,140 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:50,231 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:50,249 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,289 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:50,271 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:50,454 INFO - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,487 INFO - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,595 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,865 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:50,887 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:50,951 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:50,952 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:05:50,952 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:50,953 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:50,953 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:50,954 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:50,954 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:50,955 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:50,955 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:50,957 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:50,966 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:50,967 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,967 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:50,968 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,968 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:05:50,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,969 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:50,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,985 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,990 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:50,991 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:50,988 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,986 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:50,992 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,023 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:48.443695+00:00, run_end_date=2024-07-18 01:35:50.018314+00:00, run_duration=1.57462, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2634, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8136
2024-07-18 07:05:51,024 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.593939+00:00, run_end_date=2024-07-18 01:35:50.653568+00:00, run_duration=1.05963, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2637, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8161
2024-07-18 07:05:51,092 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,032 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,114 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,122 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,117 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,144 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,334 INFO - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:51,335 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:51,336 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:51,336 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:51,336 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:51,337 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:51,337 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:51,338 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:51,393 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:51,394 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:51,395 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:51,396 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:51,397 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:51,413 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:51,414 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,415 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:51,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,417 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:51,417 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,431 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,447 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,451 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:51,347 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,457 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1)
2024-07-18 07:05:51,457 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:51,373 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,533 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.481339+00:00, run_end_date=2024-07-18 01:35:50.785677+00:00, run_duration=1.30434, state=success, executor_state=failed, try_number=4, max_tries=4, job_id=2636, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8160
2024-07-18 07:05:51,536 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.696465+00:00, run_end_date=2024-07-18 01:35:50.842026+00:00, run_duration=1.14556, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2638, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8162
2024-07-18 07:05:51,516 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,596 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,680 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,691 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:51,813 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:51,949 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:52,321 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:52,322 INFO - DAG parent_dag has 11/16 running and queued tasks
2024-07-18 07:05:52,330 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:05:52,331 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:52,331 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:52,332 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:52,363 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,367 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,368 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,368 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,369 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,369 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,319 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:52,370 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,404 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,405 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,410 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,415 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,417 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,417 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,418 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,420 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,420 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,434 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.112396+00:00, run_end_date=2024-07-18 01:35:51.005846+00:00, run_duration=0.89345, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2641, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8175
2024-07-18 07:05:52,435 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.322648+00:00, run_end_date=2024-07-18 01:35:51.634011+00:00, run_duration=1.31136, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2642, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8178
2024-07-18 07:05:52,436 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.369401+00:00, run_end_date=2024-07-18 01:35:50.961514+00:00, run_duration=1.59211, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2635, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8152
2024-07-18 07:05:52,436 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.134000+00:00, run_end_date=2024-07-18 01:35:51.392605+00:00, run_duration=1.25861, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2643, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8176
2024-07-18 07:05:52,437 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:49.841897+00:00, run_end_date=2024-07-18 01:35:51.009356+00:00, run_duration=1.16746, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2639, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8172
2024-07-18 07:05:52,435 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:52,535 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,536 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,483 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:52,500 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:52,552 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,645 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,695 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:52,696 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:52,697 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:52,697 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,698 INFO - Not executing <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,700 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,702 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,703 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,704 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,704 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,705 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,706 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:52,714 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,715 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:52,716 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,723 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,727 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:52,732 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,733 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:05:52,733 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,734 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:52,758 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.675893+00:00, run_end_date=2024-07-18 01:35:52.185215+00:00, run_duration=1.50932, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2644, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8180
2024-07-18 07:05:52,761 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.857828+00:00, run_end_date=2024-07-18 01:35:52.146348+00:00, run_duration=1.28852, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2645, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8181
2024-07-18 07:05:52,764 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.976925+00:00, run_end_date=2024-07-18 01:35:52.240966+00:00, run_duration=1.26404, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2646, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8191
2024-07-18 07:05:52,771 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.510842+00:00, run_end_date=2024-07-18 01:35:51.999120+00:00, run_duration=1.48828, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2640, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8179
2024-07-18 07:05:52,898 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,937 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:52,963 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:52,965 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,970 INFO - Not executing <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,971 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,971 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,972 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,972 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,973 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:52,974 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:52,980 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:53,203 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:53,312 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:53,408 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:53,498 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:53,615 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:53,627 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:53,748 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:54,139 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:54,129 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:54,209 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:54,210 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:54,211 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:54,211 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,212 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,212 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,213 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,213 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,214 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,219 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,220 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,221 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:54,229 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:54,230 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:54,231 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:54,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:54,237 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:54,240 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:54,243 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:54,244 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:54,255 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:51.554350+00:00, run_end_date=2024-07-18 01:35:52.969696+00:00, run_duration=1.41535, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2648, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8235
2024-07-18 07:05:54,258 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:50.997576+00:00, run_end_date=2024-07-18 01:35:52.885925+00:00, run_duration=1.88835, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2647, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:45.285238+00:00, queued_by_job_id=2569, pid=8195
2024-07-18 07:05:54,364 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:54,355 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:54,382 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:54,484 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:54,558 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:54,603 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:54,604 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,604 INFO - Not executing <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,604 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,605 INFO - Not executing <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,605 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,606 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,606 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:54,611 INFO - Not executing <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:54,830 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:55,123 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:55,186 INFO - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:55,353 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:55,451 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:55,538 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:55,543 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:55,667 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:55,759 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:55,869 INFO - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:55,904 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:56,028 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:56,096 INFO - 7 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:56,103 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:05:56,104 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:56,104 INFO - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:56,104 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:56,111 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:56,111 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,112 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,112 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,112 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,113 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,114 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,131 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:56,137 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:56,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,149 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:56,149 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,150 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:56,150 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,151 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:56,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,165 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,175 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,178 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,178 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,206 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:56,206 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:56,207 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:56,212 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:56,253 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:53.926797+00:00, run_end_date=2024-07-18 01:35:54.959595+00:00, run_duration=1.0328, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2649, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8314
2024-07-18 07:05:56,262 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.072107+00:00, run_end_date=2024-07-18 01:35:55.316484+00:00, run_duration=1.24438, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2650, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:49.094268+00:00, queued_by_job_id=2569, pid=8325
2024-07-18 07:05:56,263 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.555721+00:00, run_end_date=2024-07-18 01:35:55.753273+00:00, run_duration=1.19755, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2651, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8341
2024-07-18 07:05:56,268 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:56,306 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:56,368 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:56,291 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:56,373 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:56,393 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:56,406 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:56,541 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:56,546 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:56,548 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,549 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,549 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,550 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,550 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,551 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,551 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,561 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,563 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:56,571 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:56,573 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,583 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:56,610 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:56,610 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:56,641 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.975805+00:00, run_end_date=2024-07-18 01:35:56.126223+00:00, run_duration=1.15042, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2653, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8361
2024-07-18 07:05:56,650 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:54.864954+00:00, run_end_date=2024-07-18 01:35:55.986038+00:00, run_duration=1.12108, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2652, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8352
2024-07-18 07:05:56,797 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:56,823 INFO - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:56,852 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:56,855 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,858 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,866 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,867 INFO - Not executing <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,867 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,867 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:56,867 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:56,868 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:57,185 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:57,293 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:57,468 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:57,692 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:57,916 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:57,997 INFO - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:58,083 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:58,173 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:58,172 INFO - 8 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:58,176 INFO - DAG parent_dag has 11/16 running and queued tasks
2024-07-18 07:05:58,177 INFO - DAG parent_dag has 12/16 running and queued tasks
2024-07-18 07:05:58,177 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:05:58,178 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:05:58,183 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:05:58,184 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,184 INFO - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,185 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,186 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,191 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,192 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,193 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:58,213 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:58,214 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,215 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:05:58,216 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,216 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:05:58,217 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,217 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:05:58,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,219 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:05:58,219 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,229 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,237 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,246 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,247 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,251 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:58,252 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:58,253 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:58,255 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:05:58,281 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:55.609463+00:00, run_end_date=2024-07-18 01:35:56.890268+00:00, run_duration=1.2808, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2655, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8382
2024-07-18 07:05:58,282 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.307397+00:00, run_end_date=2024-07-18 01:35:57.577590+00:00, run_duration=1.27019, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2656, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.710848+00:00, queued_by_job_id=2569, pid=8396
2024-07-18 07:05:58,282 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:55.737761+00:00, run_end_date=2024-07-18 01:35:56.983140+00:00, run_duration=1.24538, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2654, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8383
2024-07-18 07:05:58,334 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:58,299 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:58,360 INFO - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:58,369 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:58,395 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:58,427 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:58,470 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:58,464 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:58,503 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:05:58,624 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:05:58,625 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,646 INFO - Not executing <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,647 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,647 INFO - Not executing <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,648 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,648 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,648 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:05:58,649 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:05:58,683 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=4, map_index=-1)
2024-07-18 07:05:58,684 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:05:58,708 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:58,726 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.868757+00:00, run_end_date=2024-07-18 01:35:57.864558+00:00, run_duration=0.995801, state=success, executor_state=failed, try_number=4, max_tries=4, job_id=2657, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:51.411166+00:00, queued_by_job_id=2569, pid=8436
2024-07-18 07:05:58,751 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:56.925419+00:00, run_end_date=2024-07-18 01:35:58.102473+00:00, run_duration=1.17705, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2659, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:35:50.959759+00:00, queued_by_job_id=2569, pid=8434
2024-07-18 07:05:58,894 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:58,944 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:05:58,977 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:59,111 INFO - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:05:59,321 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:05:59,627 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:00,100 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:00,101 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:06:00,101 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:00,102 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:00,111 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,112 INFO - Not executing <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,112 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,113 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,113 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,122 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,123 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:00,138 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:06:00,139 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,140 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:00,141 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,171 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:00,172 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,145 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:00,193 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,198 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,198 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,206 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:00,207 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:00,255 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:57.123101+00:00, run_end_date=2024-07-18 01:35:58.553070+00:00, run_duration=1.42997, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2658, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.710848+00:00, queued_by_job_id=2569, pid=8455
2024-07-18 07:06:00,256 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:57.454807+00:00, run_end_date=2024-07-18 01:35:58.649420+00:00, run_duration=1.19461, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2660, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8457
2024-07-18 07:06:00,289 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:00,401 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:00,419 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:00,613 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:00,680 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:00,681 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:00,682 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:00,691 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,695 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,696 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,696 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,697 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:00,698 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:00,627 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:00,726 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:00,738 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:00,755 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,757 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:00,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,784 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:00,789 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,801 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:00,837 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:58.648030+00:00, run_end_date=2024-07-18 01:35:59.911863+00:00, run_duration=1.26383, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2661, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8509
2024-07-18 07:06:00,868 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:00,878 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:00,826 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:00,914 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:00,927 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:01,058 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:01,073 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:01,208 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:01,209 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:01,209 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:01,210 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,210 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,220 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,220 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,220 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,220 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,221 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,221 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,221 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:01,243 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:01,244 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:01,244 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:01,245 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:01,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:01,257 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:01,266 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:01,266 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:01,267 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:01,267 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:01,268 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:01,295 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:58.999001+00:00, run_end_date=2024-07-18 01:36:00.554336+00:00, run_duration=1.55534, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2663, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:54.226033+00:00, queued_by_job_id=2569, pid=8526
2024-07-18 07:06:01,296 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.450707+00:00, run_end_date=2024-07-18 01:36:00.392758+00:00, run_duration=0.942051, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2664, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:54.226033+00:00, queued_by_job_id=2569, pid=8530
2024-07-18 07:06:01,296 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.784327+00:00, run_end_date=2024-07-18 01:36:00.655189+00:00, run_duration=0.870862, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2665, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8531
2024-07-18 07:06:01,297 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:35:59.120316+00:00, run_end_date=2024-07-18 01:36:00.406986+00:00, run_duration=1.28667, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2662, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:52.354557+00:00, queued_by_job_id=2569, pid=8529
2024-07-18 07:06:01,336 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:01,460 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:01,518 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:01,522 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,524 INFO - Not executing <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,524 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,525 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,525 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,525 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,526 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:01,526 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:01,629 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:01,903 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:01,908 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:01,895 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:02,037 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:02,116 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:02,117 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:02,117 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,118 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,131 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,132 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,133 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,133 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,134 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,134 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,147 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:02,175 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:02,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:02,189 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:02,203 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:02,218 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:02,224 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:00.174439+00:00, run_end_date=2024-07-18 01:36:01.586077+00:00, run_duration=1.41164, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2666, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.564963+00:00, queued_by_job_id=2569, pid=8559
2024-07-18 07:06:02,241 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:02,263 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:02,323 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:02,356 INFO - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:02,409 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:02,638 INFO - 4 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:02,638 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,639 INFO - Not executing <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,639 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,640 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,641 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,642 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,659 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:02,659 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:02,875 INFO - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:03,050 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:03,059 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:03,024 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:03,226 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:03,330 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:03,531 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:03,625 INFO - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:04,023 INFO - 6 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:04,026 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:04,027 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:04,028 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,028 INFO - Not executing <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,029 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,029 INFO - Not executing <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,030 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,039 INFO - Not executing <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,040 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,041 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,042 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:04,063 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:04,064 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,065 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:04,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,076 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,089 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:04,087 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,090 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:04,131 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:01.364596+00:00, run_end_date=2024-07-18 01:36:02.692225+00:00, run_duration=1.32763, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2667, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8605
2024-07-18 07:06:04,132 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:01.630815+00:00, run_end_date=2024-07-18 01:36:03.018463+00:00, run_duration=1.38765, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2668, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8630
2024-07-18 07:06:04,215 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:04,327 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:04,330 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:04,313 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:04,376 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:04,470 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:04,552 INFO - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:04,584 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:04,774 INFO - 5 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:04,774 INFO - DAG parent_dag has 13/16 running and queued tasks
2024-07-18 07:06:04,775 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:04,775 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:04,776 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,776 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,776 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:04,777 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:04,777 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:04,809 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:04,810 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,811 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:04,811 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,811 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:04,812 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,828 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,829 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,835 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:04,838 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:04,865 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:02.914064+00:00, run_end_date=2024-07-18 01:36:04.201233+00:00, run_duration=1.28717, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2670, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8654
2024-07-18 07:06:04,793 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 4, 429302), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2675', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 4, 698659), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_branches.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 4, 429302), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2675', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 4, 698659), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_branches.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:06:05,002 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:05,073 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,092 INFO - 3 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:05,093 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:05,094 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:05,094 INFO - Not executing <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:05,095 INFO - DAG parent_dag has 16/16 running and queued tasks
2024-07-18 07:06:05,095 INFO - Not executing <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]> since the number of tasks running or queued from DAG parent_dag is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:06:05,096 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:05,104 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:05,105 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,068 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,074 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,109 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:05,111 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:05,112 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:05,111 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,126 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:01.619264+00:00, run_end_date=2024-07-18 01:34:03.308959+00:00, run_duration=1.6897, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2612, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=4776
2024-07-18 07:06:05,127 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:05,138 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:05,161 INFO - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013401, end_date=20240718T013605
2024-07-18 07:06:05,184 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.104349+00:00, run_end_date=2024-07-18 01:36:04.632059+00:00, run_duration=1.52771, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2672, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8658
2024-07-18 07:06:05,185 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.084483+00:00, run_end_date=2024-07-18 01:36:04.324532+00:00, run_duration=1.24005, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2671, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:56.132204+00:00, queued_by_job_id=2569, pid=8659
2024-07-18 07:06:05,324 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:05,334 INFO - 2 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:05,335 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:05,336 INFO - DAG parent_dag has 15/16 running and queued tasks
2024-07-18 07:06:05,337 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:05,348 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:05,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,350 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:05,354 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,373 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:05,374 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,381 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:05,405 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.362925+00:00, run_end_date=2024-07-18 01:36:04.727606+00:00, run_duration=1.36468, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2673, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8660
2024-07-18 07:06:05,391 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,581 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,620 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:05,630 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:05,705 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:05,783 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:05,804 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:03.720742+00:00, run_end_date=2024-07-18 01:36:05.190983+00:00, run_duration=1.47024, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2674, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.728171+00:00, queued_by_job_id=2569, pid=8661
2024-07-18 07:06:05,811 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:05,831 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:05,913 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:06,123 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:06,179 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:06,403 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:06,507 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:07,056 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:07,057 INFO - DAG parent_dag has 14/16 running and queued tasks
2024-07-18 07:06:07,057 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:07,072 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:07,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:07,076 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:07,084 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:07,085 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:07,116 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:04.872642+00:00, run_end_date=2024-07-18 01:36:06.209999+00:00, run_duration=1.33736, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2677, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:01.222603+00:00, queued_by_job_id=2569, pid=8690
2024-07-18 07:06:07,117 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:04.892301+00:00, run_end_date=2024-07-18 01:36:05.880828+00:00, run_duration=0.988527, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2676, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:35:58.194360+00:00, queued_by_job_id=2569, pid=8689
2024-07-18 07:06:07,211 INFO - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:07,269 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:07,353 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:07,815 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:07,946 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:07,972 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:05.953911+00:00, run_end_date=2024-07-18 01:36:07.053633+00:00, run_duration=1.09972, state=success, executor_state=failed, try_number=2, max_tries=2, job_id=2678, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8762
2024-07-18 07:06:08,099 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:08,455 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:08,704 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:08,728 INFO - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:08,833 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:08,912 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:08,940 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:09,006 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:09,054 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:09,097 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:09,236 INFO - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:09,242 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:09,484 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:09,484 INFO - DAG parent_dag has 8/16 running and queued tasks
2024-07-18 07:06:09,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:09,503 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:09,504 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:09,512 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:09,419 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 259559), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2685', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 366852), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_investments.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 259559), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2685', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 366852), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_investments.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:06:09,476 ERROR - Failed to execute task (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 307804), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2687', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 406621), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_mortgage_applications.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85).
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 705, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.InternalError: 1213 (40001): Deadlock found when trying to get lock; try restarting transaction

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 152, in _execute
    if not self.task_instance.check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2349, in check_and_change_state_before_execution
    return TaskInstance._check_and_change_state_before_execution(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 2321, in _check_and_change_state_before_execution
    session.commit()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1001, in _emit_update_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/cursor_cext.py", line 357, in execute
    result = self._connection.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 106, in wrapper
    result = method(cnx, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/mysql/connector/connection_cext.py", line 713, in cmd_query
    raise get_mysql_exception(
sqlalchemy.exc.InternalError: (mysql.connector.errors.InternalError) 1213 (40001): Deadlock found when trying to get lock; try restarting transaction
[SQL: UPDATE task_instance SET start_date=%(start_date)s, end_date=%(end_date)s, state=%(state)s, try_number=%(try_number)s, job_id=%(job_id)s, pid=%(pid)s, updated_at=%(updated_at)s WHERE task_instance.dag_id = %(task_instance_dag_id)s AND task_instance.task_id = %(task_instance_task_id)s AND task_instance.run_id = %(task_instance_run_id)s AND task_instance.map_index = %(task_instance_map_index)s]
[parameters: {'start_date': datetime.datetime(2024, 7, 18, 1, 36, 9, 307804), 'end_date': None, 'state': <TaskInstanceState.RUNNING: 'running'>, 'try_number': 2, 'job_id': '2687', 'pid': None, 'updated_at': datetime.datetime(2024, 7, 18, 1, 36, 9, 406621), 'task_instance_dag_id': 'parent_dag', 'task_instance_task_id': 'raw_load_mortgage_applications.insert_table', 'task_instance_run_id': 'manual__2024-07-18T01:28:18.110991+00:00', 'task_instance_map_index': -1}]
(Background on this error at: https://sqlalche.me/e/14/2j85)
2024-07-18 07:06:09,522 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:09,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,546 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,547 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:06:09,547 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,585 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.324189+00:00, run_end_date=2024-07-18 01:36:07.603679+00:00, run_duration=1.27949, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2679, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:01.222603+00:00, queued_by_job_id=2569, pid=8778
2024-07-18 07:06:09,586 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:02.777300+00:00, run_end_date=2024-07-18 01:36:08.657186+00:00, run_duration=5.87989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2669, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8648
2024-07-18 07:06:09,593 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:07.191033+00:00, run_end_date=2024-07-18 01:36:08.726342+00:00, run_duration=1.53531, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2682, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.125720+00:00, queued_by_job_id=2569, pid=8791
2024-07-18 07:06:09,595 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:07.945796+00:00, run_end_date=2024-07-18 01:36:09.069224+00:00, run_duration=1.12343, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2683, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:02.148278+00:00, queued_by_job_id=2569, pid=8807
2024-07-18 07:06:09,596 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.368044+00:00, run_end_date=2024-07-18 01:36:07.570156+00:00, run_duration=1.20211, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2680, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.051812+00:00, queued_by_job_id=2569, pid=8779
2024-07-18 07:06:09,689 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:09,775 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,775 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,776 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:09,788 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:06.725343+00:00, run_end_date=2024-07-18 01:36:09.147098+00:00, run_duration=2.42176, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2681, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:00.728171+00:00, queued_by_job_id=2569, pid=8780
2024-07-18 07:06:09,789 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:05.752867+00:00, run_end_date=2024-07-18 01:34:07.026116+00:00, run_duration=1.27325, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2620, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=5015
2024-07-18 07:06:09,790 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:09,817 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:09,854 INFO - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013405, end_date=20240718T013609
2024-07-18 07:06:09,872 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:34:06.100271+00:00, run_end_date=2024-07-18 01:34:07.314235+00:00, run_duration=1.21396, state=queued, executor_state=failed, try_number=2, max_tries=2, job_id=2623, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=5022
2024-07-18 07:06:09,873 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:09,896 ERROR - Executor reports task instance <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
2024-07-18 07:06:09,926 INFO - Marking task as UP_FOR_RETRY. dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, execution_date=20240718T012818, start_date=20240718T013406, end_date=20240718T013609
2024-07-18 07:06:09,937 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:10,114 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:10,477 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:10,485 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:08.760318+00:00, run_end_date=2024-07-18 01:36:09.758830+00:00, run_duration=0.998512, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2684, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.099847+00:00, queued_by_job_id=2569, pid=8820
2024-07-18 07:06:11,050 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:11,280 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:11,639 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:11,640 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:11,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:11,642 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:11,659 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.520261+00:00, run_end_date=2024-07-18 01:36:10.477191+00:00, run_duration=0.95693, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2686, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.051812+00:00, queued_by_job_id=2569, pid=8847
2024-07-18 07:06:11,660 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.509535+00:00, run_end_date=2024-07-18 01:36:10.360096+00:00, run_duration=0.850561, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2688, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:04.788821+00:00, queued_by_job_id=2569, pid=8843
2024-07-18 07:06:11,661 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.993537+00:00, run_end_date=2024-07-18 01:36:10.627997+00:00, run_duration=0.63446, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2690, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.340344+00:00, queued_by_job_id=2569, pid=8857
2024-07-18 07:06:11,662 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:10.457577+00:00, run_end_date=2024-07-18 01:36:11.089313+00:00, run_duration=0.631736, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2691, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:07.062917+00:00, queued_by_job_id=2569, pid=8875
2024-07-18 07:06:12,743 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=2, map_index=-1)
2024-07-18 07:06:12,744 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=1, map_index=-1)
2024-07-18 07:06:12,749 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:11.559944+00:00, run_end_date=2024-07-18 01:36:11.963884+00:00, run_duration=0.40394, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2692, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:09.495482+00:00, queued_by_job_id=2569, pid=8908
2024-07-18 07:06:12,749 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:09.714492+00:00, run_end_date=2024-07-18 01:36:12.066989+00:00, run_duration=2.3525, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2689, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:05.340344+00:00, queued_by_job_id=2569, pid=8855
2024-07-18 07:06:37,275 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:37,276 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:37,276 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:37,278 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:06:37,279 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:37,283 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:37,317 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:38,010 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:38,093 INFO - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:38,542 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:38,609 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:38,609 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:38,610 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:38,614 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:06:38,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:38,618 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:38,617 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:38,623 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:38.206230+00:00, run_end_date=2024-07-18 01:36:38.443430+00:00, run_duration=0.2372, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2693, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:36:37.276951+00:00, queued_by_job_id=2569, pid=9643
2024-07-18 07:06:38,652 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:39,511 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:39,625 INFO - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:40,156 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:40,761 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:40,762 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:40,762 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:40,765 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:40,765 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:40,768 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:40,768 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:40,781 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:39.763844+00:00, run_end_date=2024-07-18 01:36:40.033992+00:00, run_duration=0.270148, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2694, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:38.610784+00:00, queued_by_job_id=2569, pid=9670
2024-07-18 07:06:40,810 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:41,635 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:41,716 INFO - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:43,088 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:43,098 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:41.853110+00:00, run_end_date=2024-07-18 01:36:42.135030+00:00, run_duration=0.28192, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2695, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:40.763052+00:00, queued_by_job_id=2569, pid=9731
2024-07-18 07:06:44,817 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:44,817 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:44,818 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:44,820 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:06:44,820 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:44,823 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:44,868 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:45,746 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:45,874 INFO - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:46,542 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:47,177 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:47,179 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:47,179 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:47,184 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:06:47,185 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:47,188 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:47,188 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:47,199 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:46.108015+00:00, run_end_date=2024-07-18 01:36:46.464711+00:00, run_duration=0.356696, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2696, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:36:44.818806+00:00, queued_by_job_id=2569, pid=9866
2024-07-18 07:06:47,236 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:48,376 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:48,539 INFO - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:49,213 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:06:49,329 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:49,330 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:49,331 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:49,335 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:49,336 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:49,339 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:49,339 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:49,349 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:48.714588+00:00, run_end_date=2024-07-18 01:36:49.119319+00:00, run_duration=0.404731, state=success, executor_state=failed, try_number=3, max_tries=3, job_id=2697, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:36:47.181236+00:00, queued_by_job_id=2569, pid=9952
2024-07-18 07:06:49,439 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:50,550 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:50,641 INFO - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:52,015 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:52,020 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:50.754826+00:00, run_end_date=2024-07-18 01:36:51.017787+00:00, run_duration=0.262961, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2698, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:49.333363+00:00, queued_by_job_id=2569, pid=10010
2024-07-18 07:06:53,102 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:53,102 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:06:53,103 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [scheduled]>
2024-07-18 07:06:53,105 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:06:53,105 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:53,109 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:28:18.110991+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:06:53,152 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:06:53,954 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:06:54,029 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:28:18.110991+00:00 [queued]> on host kali
2024-07-18 07:06:55,017 INFO - Marking run <DagRun parent_dag @ 2024-07-18 01:28:18.110991+00:00: manual__2024-07-18T01:28:18.110991+00:00, state:running, queued_at: 2024-07-18 01:28:18.168776+00:00. externally triggered: True> successful
2024-07-18 07:06:55,018 INFO - DagRun Finished: dag_id=parent_dag, execution_date=2024-07-18 01:28:18.110991+00:00, run_id=manual__2024-07-18T01:28:18.110991+00:00, run_start_date=2024-07-18 01:28:19.852875+00:00, run_end_date=2024-07-18 01:36:55.018329+00:00, run_duration=515.165454, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=ab6dc09708a4297d36001303949cf96b
2024-07-18 07:06:55,039 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:28:18.110991+00:00', try_number=3, map_index=-1)
2024-07-18 07:06:55,047 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:28:18.110991+00:00, map_index=-1, run_start_date=2024-07-18 01:36:54.135749+00:00, run_end_date=2024-07-18 01:36:54.388961+00:00, run_duration=0.253212, state=success, executor_state=success, try_number=3, max_tries=3, job_id=2699, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:36:53.103772+00:00, queued_by_job_id=2569, pid=10113
2024-07-18 07:07:02,006 INFO - 16 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:02,008 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:07:02,008 INFO - DAG mysql_data_transformation has 1/16 running and queued tasks
2024-07-18 07:07:02,008 INFO - DAG mysql_data_transformation has 2/16 running and queued tasks
2024-07-18 07:07:02,009 INFO - DAG mysql_data_transformation has 3/16 running and queued tasks
2024-07-18 07:07:02,009 INFO - DAG mysql_data_transformation has 4/16 running and queued tasks
2024-07-18 07:07:02,010 INFO - DAG mysql_data_transformation has 5/16 running and queued tasks
2024-07-18 07:07:02,010 INFO - DAG mysql_data_transformation has 6/16 running and queued tasks
2024-07-18 07:07:02,010 INFO - DAG mysql_data_transformation has 7/16 running and queued tasks
2024-07-18 07:07:02,011 INFO - DAG mysql_data_transformation has 8/16 running and queued tasks
2024-07-18 07:07:02,011 INFO - DAG mysql_data_transformation has 9/16 running and queued tasks
2024-07-18 07:07:02,011 INFO - DAG mysql_data_transformation has 10/16 running and queued tasks
2024-07-18 07:07:02,012 INFO - DAG mysql_data_transformation has 11/16 running and queued tasks
2024-07-18 07:07:02,012 INFO - DAG mysql_data_transformation has 12/16 running and queued tasks
2024-07-18 07:07:02,012 INFO - DAG mysql_data_transformation has 13/16 running and queued tasks
2024-07-18 07:07:02,013 INFO - DAG mysql_data_transformation has 14/16 running and queued tasks
2024-07-18 07:07:02,013 INFO - DAG mysql_data_transformation has 15/16 running and queued tasks
2024-07-18 07:07:02,013 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:02,018 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,018 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,019 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,019 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,020 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,020 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,021 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,022 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,023 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,025 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,025 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,025 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,026 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,027 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,028 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,028 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,029 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,029 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,029 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,030 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,030 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,030 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,031 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,031 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,032 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:02,032 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,035 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,036 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,036 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,036 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,036 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,036 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,037 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,047 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,051 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,056 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,076 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,084 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,090 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,093 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,093 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,103 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:02,104 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,134 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,136 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,118 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,176 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,180 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,226 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,216 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,300 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,283 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,332 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,334 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,348 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,346 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,390 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,384 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:02,424 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:02,425 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:02,425 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:02,425 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:02,426 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:02,454 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:02,455 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:02,456 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:02,457 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:03,727 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:03,728 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:03,729 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:03,730 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:03,731 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:03,733 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:03,733 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:03,733 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:03,734 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:03,920 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:04,354 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:04,355 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:04,356 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:04,357 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:04,358 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:04,375 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:04,376 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:04,377 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:04,377 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:04,915 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:05,046 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:05,399 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:05,488 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:05,502 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:05,503 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:05,504 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:05,504 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:05,505 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:05,505 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:05,506 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:05,518 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:05,884 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:05,919 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:06,183 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:06,401 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:06,653 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:06,753 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:06,810 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:06,814 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:06,815 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:06,816 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:06,816 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:06,816 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:06,817 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:06,817 INFO - DAG mysql_data_transformation has 16/16 running and queued tasks
2024-07-18 07:07:06,818 INFO - Not executing <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]> since the number of tasks running or queued from DAG mysql_data_transformation is >= to the DAG's max_active_tasks limit of 16
2024-07-18 07:07:06,983 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:07,240 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:07,846 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:07,978 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:08,279 INFO - 4 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:08,280 INFO - DAG mysql_data_transformation has 12/16 running and queued tasks
2024-07-18 07:07:08,281 INFO - DAG mysql_data_transformation has 13/16 running and queued tasks
2024-07-18 07:07:08,281 INFO - DAG mysql_data_transformation has 14/16 running and queued tasks
2024-07-18 07:07:08,282 INFO - DAG mysql_data_transformation has 15/16 running and queued tasks
2024-07-18 07:07:08,293 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:07:08,304 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:08,309 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,310 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:08,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,313 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:08,314 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,322 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:08,323 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,327 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,329 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,336 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,343 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:07:08,352 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:08,352 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:08,353 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:08,374 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_atms_to_int_atms, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:04.706003+00:00, run_end_date=2024-07-18 01:37:06.661348+00:00, run_duration=1.95535, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2700, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10432
2024-07-18 07:07:08,376 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_credit_scores_to_int_credit_scores, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:05.874016+00:00, run_end_date=2024-07-18 01:37:07.050685+00:00, run_duration=1.17667, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2703, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10441
2024-07-18 07:07:08,377 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_loans_to_int_loans, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.085487+00:00, run_end_date=2024-07-18 01:37:07.526822+00:00, run_duration=1.44133, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2705, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10443
2024-07-18 07:07:08,418 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:08,415 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:08,567 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:08,626 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:07:08,689 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:08,899 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:09,652 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,657 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,658 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,665 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,666 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,674 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:09,702 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cheques_to_int_cheques, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.080200+00:00, run_end_date=2024-07-18 01:37:07.773930+00:00, run_duration=1.69373, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2704, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10442
2024-07-18 07:07:09,705 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_employees_to_int_employees, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.956016+00:00, run_end_date=2024-07-18 01:37:08.763879+00:00, run_duration=1.80786, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2702, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10456
2024-07-18 07:07:09,713 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_fixed_deposits_to_int_fixed_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.871217+00:00, run_end_date=2024-07-18 01:37:09.109970+00:00, run_duration=2.23875, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2707, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10455
2024-07-18 07:07:09,713 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_insurance_to_int_insurance, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.613618+00:00, run_end_date=2024-07-18 01:37:08.800749+00:00, run_duration=2.18713, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2701, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10454
2024-07-18 07:07:09,714 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_investments_to_int_investments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.487888+00:00, run_end_date=2024-07-18 01:37:08.849120+00:00, run_duration=1.36123, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2708, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10470
2024-07-18 07:07:09,718 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_online_banking_to_int_online_banking, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:06.410885+00:00, run_end_date=2024-07-18 01:37:08.149478+00:00, run_duration=1.73859, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2706, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10453
2024-07-18 07:07:10,251 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:10,811 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:10,914 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:10,916 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:10,917 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:10,929 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_branches_to_int_branches, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.524333+00:00, run_end_date=2024-07-18 01:37:09.837521+00:00, run_duration=1.31319, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2713, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10522
2024-07-18 07:07:10,930 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cards_to_int_cards, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.481424+00:00, run_end_date=2024-07-18 01:37:09.471809+00:00, run_duration=1.99039, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2709, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10465
2024-07-18 07:07:10,931 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customers_to_int_customers, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:07.432508+00:00, run_end_date=2024-07-18 01:37:09.601775+00:00, run_duration=2.16927, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2710, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10468
2024-07-18 07:07:11,132 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:11,260 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:07:12,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,029 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,029 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,029 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:12,039 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_accounts_to_int_accounts, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:09.364164+00:00, run_end_date=2024-07-18 01:37:10.776759+00:00, run_duration=1.4126, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2714, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10555
2024-07-18 07:07:12,040 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_bill_payments_to_int_bill_payments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.062321+00:00, run_end_date=2024-07-18 01:37:11.111610+00:00, run_duration=3.04929, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2711, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10504
2024-07-18 07:07:12,040 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customer_support_to_int_customer_support, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:08.664009+00:00, run_end_date=2024-07-18 01:37:10.753716+00:00, run_duration=2.08971, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10546
2024-07-18 07:07:12,041 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_mortgage_applications_to_int_mortgage_applications, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:09.575067+00:00, run_end_date=2024-07-18 01:37:10.858836+00:00, run_duration=1.28377, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:02.014739+00:00, queued_by_job_id=2569, pid=10556
2024-07-18 07:07:12,042 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_recurring_deposits_to_int_recurring_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.130399+00:00, run_end_date=2024-07-18 01:37:11.773585+00:00, run_duration=0.643186, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2717, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10590
2024-07-18 07:07:12,042 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_savings_goals_to_int_savings_goals, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.324667+00:00, run_end_date=2024-07-18 01:37:11.847116+00:00, run_duration=0.522449, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2718, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10599
2024-07-18 07:07:12,043 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_transactions_to_int_transactions, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:10.477143+00:00, run_end_date=2024-07-18 01:37:11.327531+00:00, run_duration=0.850388, state=up_for_retry, executor_state=success, try_number=1, max_tries=1, job_id=2716, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10565
2024-07-18 07:07:13,101 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:13,108 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_service_charges_to_int_service_charges, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:37:11.541359+00:00, run_end_date=2024-07-18 01:37:12.533880+00:00, run_duration=0.992521, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2719, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:08.295109+00:00, queued_by_job_id=2569, pid=10600
2024-07-18 07:07:45,412 INFO - 1 tasks up for execution:
	<TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [scheduled]>
2024-07-18 07:07:45,413 INFO - DAG dag_prepare_data_today has 0/16 running and queued tasks
2024-07-18 07:07:45,413 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [scheduled]>
2024-07-18 07:07:45,419 INFO - Sending TaskInstanceKey(dag_id='dag_prepare_data_today', task_id='Prepare_data', run_id='manual__2024-07-18T01:37:44.827477+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:07:45,419 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_prepare_data_today', 'Prepare_data', 'manual__2024-07-18T01:37:44.827477+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_prepare_data_today.py']
2024-07-18 07:07:45,422 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_prepare_data_today', 'Prepare_data', 'manual__2024-07-18T01:37:44.827477+00:00', '--local', '--subdir', 'DAGS_FOLDER/dag_prepare_data_today.py']
2024-07-18 07:07:45,458 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/dag_prepare_data_today.py
2024-07-18 07:07:45,559 INFO - Running <TaskInstance: dag_prepare_data_today.Prepare_data manual__2024-07-18T01:37:44.827477+00:00 [queued]> on host kali
2024-07-18 07:07:52,337 INFO - Marking run <DagRun dag_prepare_data_today @ 2024-07-18 01:37:44.827477+00:00: manual__2024-07-18T01:37:44.827477+00:00, state:running, queued_at: 2024-07-18 01:37:44.848466+00:00. externally triggered: True> successful
2024-07-18 07:07:52,338 INFO - DagRun Finished: dag_id=dag_prepare_data_today, execution_date=2024-07-18 01:37:44.827477+00:00, run_id=manual__2024-07-18T01:37:44.827477+00:00, run_start_date=2024-07-18 01:37:45.356063+00:00, run_end_date=2024-07-18 01:37:52.338169+00:00, run_duration=6.982106, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-18 01:37:44.827477+00:00, data_interval_end=2024-07-18 01:37:44.827477+00:00, dag_hash=83a5a88b23306d5e45e886e9fee1d340
2024-07-18 07:07:52,362 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_prepare_data_today', task_id='Prepare_data', run_id='manual__2024-07-18T01:37:44.827477+00:00', try_number=1, map_index=-1)
2024-07-18 07:07:52,374 INFO - TaskInstance Finished: dag_id=dag_prepare_data_today, task_id=Prepare_data, run_id=manual__2024-07-18T01:37:44.827477+00:00, map_index=-1, run_start_date=2024-07-18 01:37:45.676163+00:00, run_end_date=2024-07-18 01:37:52.045212+00:00, run_duration=6.36905, state=success, executor_state=success, try_number=1, max_tries=0, job_id=2720, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:37:45.415940+00:00, queued_by_job_id=2569, pid=11422
2024-07-18 07:08:48,664 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-07-18 07:11:29,327 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:29,329 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:29,330 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:29,336 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 60 and queue default
2024-07-18 07:11:29,337 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:29,351 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:29,404 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:30,138 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:30,208 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:30,670 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:31,690 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:31,691 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:31,691 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:31,695 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 59 and queue default
2024-07-18 07:11:31,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:31,700 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:31,699 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:31,704 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:30.307183+00:00, run_end_date=2024-07-18 01:41:30.546975+00:00, run_duration=0.239792, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2721, pool=default_pool, queue=default, priority_weight=60, operator=PythonOperator, queued_dttm=2024-07-18 01:41:29.331865+00:00, queued_by_job_id=2569, pid=18115
2024-07-18 07:11:31,731 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:32,533 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:32,653 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:33,153 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:33,291 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:33,292 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:33,294 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:33,297 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 58 and queue default
2024-07-18 07:11:33,297 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:33,301 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:33,301 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_accounts.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:33,307 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:32.772490+00:00, run_end_date=2024-07-18 01:41:33.052307+00:00, run_duration=0.279817, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2722, pool=default_pool, queue=default, priority_weight=59, operator=PythonOperator, queued_dttm=2024-07-18 01:41:31.692311+00:00, queued_by_job_id=2569, pid=18148
2024-07-18 07:11:33,339 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:34,049 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:34,138 INFO - Running <TaskInstance: parent_dag.raw_load_accounts.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:36,733 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:37,694 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:37,694 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:37,695 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:37,698 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 57 and queue default
2024-07-18 07:11:37,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:37,702 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_accounts.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:37,702 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:37,707 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_accounts.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:34.304071+00:00, run_end_date=2024-07-18 01:41:36.629994+00:00, run_duration=2.32592, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2723, pool=default_pool, queue=default, priority_weight=58, operator=PythonOperator, queued_dttm=2024-07-18 01:41:33.295754+00:00, queued_by_job_id=2569, pid=18165
2024-07-18 07:11:37,737 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:38,520 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:38,599 INFO - Running <TaskInstance: parent_dag.raw_load_atms.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:39,052 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:39,533 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:39,533 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:39,534 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:39,536 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 56 and queue default
2024-07-18 07:11:39,536 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:39,539 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:39,539 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:39,547 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:38.697995+00:00, run_end_date=2024-07-18 01:41:38.938811+00:00, run_duration=0.240816, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2724, pool=default_pool, queue=default, priority_weight=57, operator=PythonOperator, queued_dttm=2024-07-18 01:41:37.695929+00:00, queued_by_job_id=2569, pid=18218
2024-07-18 07:11:39,578 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:40,460 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:40,538 INFO - Running <TaskInstance: parent_dag.raw_load_atms.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:41,015 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:41,884 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:41,884 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:41,885 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:41,887 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 55 and queue default
2024-07-18 07:11:41,887 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:41,889 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:41,889 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_atms.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:41,898 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:40.654821+00:00, run_end_date=2024-07-18 01:41:40.918613+00:00, run_duration=0.263792, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2725, pool=default_pool, queue=default, priority_weight=56, operator=PythonOperator, queued_dttm=2024-07-18 01:41:39.534867+00:00, queued_by_job_id=2569, pid=18243
2024-07-18 07:11:41,925 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:42,631 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:42,725 INFO - Running <TaskInstance: parent_dag.raw_load_atms.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:43,387 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:43,518 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:43,518 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:43,519 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:43,521 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 54 and queue default
2024-07-18 07:11:43,521 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:43,525 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_atms.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:43,524 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:43,533 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_atms.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:42.846850+00:00, run_end_date=2024-07-18 01:41:43.283367+00:00, run_duration=0.436517, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2726, pool=default_pool, queue=default, priority_weight=55, operator=PythonOperator, queued_dttm=2024-07-18 01:41:41.885596+00:00, queued_by_job_id=2569, pid=18276
2024-07-18 07:11:43,559 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:44,269 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:44,365 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:44,796 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:45,851 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:45,851 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:45,852 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:45,854 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 53 and queue default
2024-07-18 07:11:45,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:45,859 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:45,858 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:45,865 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:44.464347+00:00, run_end_date=2024-07-18 01:41:44.699537+00:00, run_duration=0.23519, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2727, pool=default_pool, queue=default, priority_weight=54, operator=PythonOperator, queued_dttm=2024-07-18 01:41:43.519619+00:00, queued_by_job_id=2569, pid=18293
2024-07-18 07:11:45,893 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:46,583 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:46,662 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:47,209 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:48,135 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:48,135 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:48,135 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:48,137 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 52 and queue default
2024-07-18 07:11:48,138 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:48,142 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:48,141 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_bill_payments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:48,149 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:46.782192+00:00, run_end_date=2024-07-18 01:41:47.087113+00:00, run_duration=0.304921, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2728, pool=default_pool, queue=default, priority_weight=53, operator=PythonOperator, queued_dttm=2024-07-18 01:41:45.853000+00:00, queued_by_job_id=2569, pid=18350
2024-07-18 07:11:48,175 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:48,975 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:49,114 INFO - Running <TaskInstance: parent_dag.raw_load_bill_payments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:50,077 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:50,836 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:50,837 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:50,837 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:50,842 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 51 and queue default
2024-07-18 07:11:50,842 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:50,846 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_bill_payments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:50,846 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:50,851 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_bill_payments.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:49.251198+00:00, run_end_date=2024-07-18 01:41:49.997323+00:00, run_duration=0.746125, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2729, pool=default_pool, queue=default, priority_weight=52, operator=PythonOperator, queued_dttm=2024-07-18 01:41:48.136334+00:00, queued_by_job_id=2569, pid=18409
2024-07-18 07:11:50,896 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:51,834 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:51,913 INFO - Running <TaskInstance: parent_dag.raw_load_branches.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:52,341 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:52,652 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:52,652 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:52,652 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:52,656 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 50 and queue default
2024-07-18 07:11:52,656 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:52,660 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:52,660 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:52,664 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:52.009813+00:00, run_end_date=2024-07-18 01:41:52.271466+00:00, run_duration=0.261653, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2730, pool=default_pool, queue=default, priority_weight=51, operator=PythonOperator, queued_dttm=2024-07-18 01:41:50.838796+00:00, queued_by_job_id=2569, pid=18492
2024-07-18 07:11:52,690 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:53,377 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:53,449 INFO - Running <TaskInstance: parent_dag.raw_load_branches.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:53,984 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:54,969 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:54,969 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:54,969 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:54,973 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 49 and queue default
2024-07-18 07:11:54,974 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:54,978 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:54,978 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_branches.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:54,982 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:53.550433+00:00, run_end_date=2024-07-18 01:41:53.914018+00:00, run_duration=0.363585, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2731, pool=default_pool, queue=default, priority_weight=50, operator=PythonOperator, queued_dttm=2024-07-18 01:41:52.653393+00:00, queued_by_job_id=2569, pid=18514
2024-07-18 07:11:55,009 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:55,932 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:56,017 INFO - Running <TaskInstance: parent_dag.raw_load_branches.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:56,667 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:57,347 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:57,348 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:57,348 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:57,353 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 48 and queue default
2024-07-18 07:11:57,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:57,363 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:57,367 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_branches.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:57,384 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_branches.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:56.182016+00:00, run_end_date=2024-07-18 01:41:56.511148+00:00, run_duration=0.329132, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2732, pool=default_pool, queue=default, priority_weight=49, operator=PythonOperator, queued_dttm=2024-07-18 01:41:54.970398+00:00, queued_by_job_id=2569, pid=18637
2024-07-18 07:11:57,434 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:58,144 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:58,215 INFO - Running <TaskInstance: parent_dag.raw_load_cards.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:58,620 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:58,620 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:11:58,621 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:11:58,623 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 47 and queue default
2024-07-18 07:11:58,625 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:58,628 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:11:58,618 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:11:58,668 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:11:58,763 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:11:58,776 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:58.315684+00:00, run_end_date=2024-07-18 01:41:58.533618+00:00, run_duration=0.217934, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2733, pool=default_pool, queue=default, priority_weight=48, operator=PythonOperator, queued_dttm=2024-07-18 01:41:57.349528+00:00, queued_by_job_id=2569, pid=18729
2024-07-18 07:11:59,360 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:11:59,443 INFO - Running <TaskInstance: parent_dag.raw_load_cards.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:11:59,912 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:00,067 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:00,067 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:00,068 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:00,072 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 46 and queue default
2024-07-18 07:12:00,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:00,075 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:00,075 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cards.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:00,079 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:41:59.544316+00:00, run_end_date=2024-07-18 01:41:59.784254+00:00, run_duration=0.239938, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2734, pool=default_pool, queue=default, priority_weight=47, operator=PythonOperator, queued_dttm=2024-07-18 01:41:58.621635+00:00, queued_by_job_id=2569, pid=18756
2024-07-18 07:12:00,105 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:00,730 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:00,810 INFO - Running <TaskInstance: parent_dag.raw_load_cards.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:01,979 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:02,396 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:02,397 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:02,397 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:02,399 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 45 and queue default
2024-07-18 07:12:02,400 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:02,404 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cards.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:02,403 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:02,410 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cards.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:00.924919+00:00, run_end_date=2024-07-18 01:42:01.892070+00:00, run_duration=0.967151, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2735, pool=default_pool, queue=default, priority_weight=46, operator=PythonOperator, queued_dttm=2024-07-18 01:42:00.068962+00:00, queued_by_job_id=2569, pid=18783
2024-07-18 07:12:02,433 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:03,081 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:03,164 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:03,626 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:03,894 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:03,895 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:03,895 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:03,897 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 44 and queue default
2024-07-18 07:12:03,897 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:03,903 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:03,901 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:03,912 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:03.264930+00:00, run_end_date=2024-07-18 01:42:03.504682+00:00, run_duration=0.239752, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2736, pool=default_pool, queue=default, priority_weight=45, operator=PythonOperator, queued_dttm=2024-07-18 01:42:02.398093+00:00, queued_by_job_id=2569, pid=18808
2024-07-18 07:12:03,943 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:04,548 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:04,623 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:05,009 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:05,132 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:05,132 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:05,133 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:05,137 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 43 and queue default
2024-07-18 07:12:05,137 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:05,141 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:05,141 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_cheques.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:05,147 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:04.720749+00:00, run_end_date=2024-07-18 01:42:04.945660+00:00, run_duration=0.224911, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2737, pool=default_pool, queue=default, priority_weight=44, operator=PythonOperator, queued_dttm=2024-07-18 01:42:03.895760+00:00, queued_by_job_id=2569, pid=18825
2024-07-18 07:12:05,181 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:05,807 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:05,879 INFO - Running <TaskInstance: parent_dag.raw_load_cheques.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:06,721 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:06,797 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:06,797 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:06,798 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:06,800 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 42 and queue default
2024-07-18 07:12:06,800 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:06,804 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_cheques.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:06,803 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:06,812 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_cheques.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:06.000554+00:00, run_end_date=2024-07-18 01:42:06.639124+00:00, run_duration=0.63857, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2738, pool=default_pool, queue=default, priority_weight=43, operator=PythonOperator, queued_dttm=2024-07-18 01:42:05.133660+00:00, queued_by_job_id=2569, pid=18850
2024-07-18 07:12:06,837 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:07,480 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:07,552 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:07,941 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:07,992 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:07,992 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:07,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:07,994 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 41 and queue default
2024-07-18 07:12:07,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:07,998 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:07,997 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:08,004 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:07.649761+00:00, run_end_date=2024-07-18 01:42:07.861351+00:00, run_duration=0.21159, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2739, pool=default_pool, queue=default, priority_weight=42, operator=PythonOperator, queued_dttm=2024-07-18 01:42:06.798532+00:00, queued_by_job_id=2569, pid=18867
2024-07-18 07:12:08,031 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:08,788 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:08,863 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:09,256 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:10,206 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:10,207 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:10,207 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:10,210 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 40 and queue default
2024-07-18 07:12:10,210 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:10,213 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:10,213 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_credit_scores.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:10,221 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:08.964919+00:00, run_end_date=2024-07-18 01:42:09.195174+00:00, run_duration=0.230255, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2740, pool=default_pool, queue=default, priority_weight=41, operator=PythonOperator, queued_dttm=2024-07-18 01:42:07.993398+00:00, queued_by_job_id=2569, pid=18904
2024-07-18 07:12:10,246 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:10,903 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:11,003 INFO - Running <TaskInstance: parent_dag.raw_load_credit_scores.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:12,273 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:12,494 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:12,494 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:12,495 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:12,496 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 39 and queue default
2024-07-18 07:12:12,497 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:12,499 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_credit_scores.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:12,499 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:12,507 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_credit_scores.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:11.104677+00:00, run_end_date=2024-07-18 01:42:12.208956+00:00, run_duration=1.10428, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2741, pool=default_pool, queue=default, priority_weight=40, operator=PythonOperator, queued_dttm=2024-07-18 01:42:10.208597+00:00, queued_by_job_id=2569, pid=18929
2024-07-18 07:12:12,532 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:13,219 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:13,295 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:13,722 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:13,964 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:13,964 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:13,964 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:13,968 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 38 and queue default
2024-07-18 07:12:13,969 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:13,973 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:13,973 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:13,977 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:13.394919+00:00, run_end_date=2024-07-18 01:42:13.628615+00:00, run_duration=0.233696, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2742, pool=default_pool, queue=default, priority_weight=39, operator=PythonOperator, queued_dttm=2024-07-18 01:42:12.495469+00:00, queued_by_job_id=2569, pid=18954
2024-07-18 07:12:14,002 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:14,687 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:14,777 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:15,239 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:15,313 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:15,313 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:15,313 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:15,317 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 37 and queue default
2024-07-18 07:12:15,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:15,321 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:15,321 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customer_support.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:15,325 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:14.882123+00:00, run_end_date=2024-07-18 01:42:15.125783+00:00, run_duration=0.24366, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2743, pool=default_pool, queue=default, priority_weight=38, operator=PythonOperator, queued_dttm=2024-07-18 01:42:13.965257+00:00, queued_by_job_id=2569, pid=18980
2024-07-18 07:12:15,351 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:15,986 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:16,068 INFO - Running <TaskInstance: parent_dag.raw_load_customer_support.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:16,739 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:17,606 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:17,607 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:17,607 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:17,610 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 36 and queue default
2024-07-18 07:12:17,611 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:17,613 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customer_support.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:17,613 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:17,624 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customer_support.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:16.181362+00:00, run_end_date=2024-07-18 01:42:16.641277+00:00, run_duration=0.459915, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2744, pool=default_pool, queue=default, priority_weight=37, operator=PythonOperator, queued_dttm=2024-07-18 01:42:15.314487+00:00, queued_by_job_id=2569, pid=19007
2024-07-18 07:12:17,653 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:18,355 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:18,429 INFO - Running <TaskInstance: parent_dag.raw_load_customers.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:18,872 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:18,993 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:18,999 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:18.528839+00:00, run_end_date=2024-07-18 01:42:18.764889+00:00, run_duration=0.23605, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2745, pool=default_pool, queue=default, priority_weight=36, operator=PythonOperator, queued_dttm=2024-07-18 01:42:17.608593+00:00, queued_by_job_id=2569, pid=19046
2024-07-18 07:12:19,323 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:19,324 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:19,324 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:19,326 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 35 and queue default
2024-07-18 07:12:19,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:19,329 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:19,363 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:20,191 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:20,276 INFO - Running <TaskInstance: parent_dag.raw_load_customers.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:20,722 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:21,743 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:21,743 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:21,743 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:21,745 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 34 and queue default
2024-07-18 07:12:21,746 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:21,750 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:21,750 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_customers.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:21,756 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:20.381492+00:00, run_end_date=2024-07-18 01:42:20.625342+00:00, run_duration=0.24385, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2746, pool=default_pool, queue=default, priority_weight=35, operator=PythonOperator, queued_dttm=2024-07-18 01:42:19.324920+00:00, queued_by_job_id=2569, pid=19105
2024-07-18 07:12:21,783 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:22,579 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:22,661 INFO - Running <TaskInstance: parent_dag.raw_load_customers.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:23,909 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:24,043 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:24,044 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:24,044 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:24,048 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 33 and queue default
2024-07-18 07:12:24,049 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:24,052 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_customers.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:24,052 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:24,057 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_customers.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:22.771015+00:00, run_end_date=2024-07-18 01:42:23.772813+00:00, run_duration=1.0018, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2747, pool=default_pool, queue=default, priority_weight=34, operator=PythonOperator, queued_dttm=2024-07-18 01:42:21.744420+00:00, queued_by_job_id=2569, pid=19180
2024-07-18 07:12:24,091 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:24,767 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:24,903 INFO - Running <TaskInstance: parent_dag.raw_load_employees.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:25,356 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:25,543 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:25,544 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:25,544 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:25,548 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 32 and queue default
2024-07-18 07:12:25,549 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:25,552 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:25,552 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:25,558 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:25.020202+00:00, run_end_date=2024-07-18 01:42:25.274153+00:00, run_duration=0.253951, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2748, pool=default_pool, queue=default, priority_weight=33, operator=PythonOperator, queued_dttm=2024-07-18 01:42:24.045121+00:00, queued_by_job_id=2569, pid=19233
2024-07-18 07:12:25,587 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:26,422 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:26,534 INFO - Running <TaskInstance: parent_dag.raw_load_employees.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:27,139 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:27,880 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:27,881 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:27,882 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:27,886 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 31 and queue default
2024-07-18 07:12:27,886 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:27,890 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:27,889 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_employees.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:27,895 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:26.692393+00:00, run_end_date=2024-07-18 01:42:27.005104+00:00, run_duration=0.312711, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2749, pool=default_pool, queue=default, priority_weight=32, operator=PythonOperator, queued_dttm=2024-07-18 01:42:25.544964+00:00, queued_by_job_id=2569, pid=19310
2024-07-18 07:12:27,927 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:28,739 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:28,822 INFO - Running <TaskInstance: parent_dag.raw_load_employees.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:29,603 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:30,601 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:30,602 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:30,602 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:30,604 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 30 and queue default
2024-07-18 07:12:30,604 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:30,607 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_employees.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:30,607 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:30,618 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_employees.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:28.940037+00:00, run_end_date=2024-07-18 01:42:29.537752+00:00, run_duration=0.597715, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2750, pool=default_pool, queue=default, priority_weight=31, operator=PythonOperator, queued_dttm=2024-07-18 01:42:27.883572+00:00, queued_by_job_id=2569, pid=19417
2024-07-18 07:12:30,641 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:31,305 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:31,375 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:31,807 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:32,860 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:32,860 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:32,861 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:32,866 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 29 and queue default
2024-07-18 07:12:32,867 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:32,870 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:32,870 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:32,874 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:31.477418+00:00, run_end_date=2024-07-18 01:42:31.735185+00:00, run_duration=0.257767, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2751, pool=default_pool, queue=default, priority_weight=30, operator=PythonOperator, queued_dttm=2024-07-18 01:42:30.603130+00:00, queued_by_job_id=2569, pid=19454
2024-07-18 07:12:32,902 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:33,503 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:33,580 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:34,042 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:34,065 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:34,066 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:34,066 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:34,069 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 28 and queue default
2024-07-18 07:12:34,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:34,071 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_fixed_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:34,105 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:34,142 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:34,148 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:33.699459+00:00, run_end_date=2024-07-18 01:42:33.940955+00:00, run_duration=0.241496, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2752, pool=default_pool, queue=default, priority_weight=29, operator=PythonOperator, queued_dttm=2024-07-18 01:42:32.863295+00:00, queued_by_job_id=2569, pid=19479
2024-07-18 07:12:34,770 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:34,845 INFO - Running <TaskInstance: parent_dag.raw_load_fixed_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:35,510 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:35,717 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:35,718 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:35,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:35,720 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 27 and queue default
2024-07-18 07:12:35,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:35,723 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_fixed_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:35,723 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:35,730 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_fixed_deposits.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:34.947304+00:00, run_end_date=2024-07-18 01:42:35.444204+00:00, run_duration=0.4969, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2753, pool=default_pool, queue=default, priority_weight=28, operator=PythonOperator, queued_dttm=2024-07-18 01:42:34.066984+00:00, queued_by_job_id=2569, pid=19510
2024-07-18 07:12:35,755 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:36,355 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:36,426 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:36,858 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:36,892 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:36,892 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:36,894 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:36,899 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 26 and queue default
2024-07-18 07:12:36,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:36,903 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:36,902 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:36,908 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:36.532360+00:00, run_end_date=2024-07-18 01:42:36.765349+00:00, run_duration=0.232989, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2754, pool=default_pool, queue=default, priority_weight=27, operator=PythonOperator, queued_dttm=2024-07-18 01:42:35.719100+00:00, queued_by_job_id=2569, pid=19527
2024-07-18 07:12:36,939 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:37,557 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:37,632 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:38,075 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:38,075 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:38,076 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:38,080 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 25 and queue default
2024-07-18 07:12:38,081 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:38,083 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_insurance.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:38,079 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:38,118 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:38,161 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:38,168 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:37.741412+00:00, run_end_date=2024-07-18 01:42:38.000649+00:00, run_duration=0.259237, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2755, pool=default_pool, queue=default, priority_weight=26, operator=PythonOperator, queued_dttm=2024-07-18 01:42:36.895458+00:00, queued_by_job_id=2569, pid=19545
2024-07-18 07:12:38,753 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:38,826 INFO - Running <TaskInstance: parent_dag.raw_load_insurance.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:39,643 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:39,717 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:39,718 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:39,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:39,720 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 24 and queue default
2024-07-18 07:12:39,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:39,724 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_insurance.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:39,723 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:39,731 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_insurance.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:38.934740+00:00, run_end_date=2024-07-18 01:42:39.547414+00:00, run_duration=0.612674, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2756, pool=default_pool, queue=default, priority_weight=25, operator=PythonOperator, queued_dttm=2024-07-18 01:42:38.076930+00:00, queued_by_job_id=2569, pid=19573
2024-07-18 07:12:39,758 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:40,477 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:40,552 INFO - Running <TaskInstance: parent_dag.raw_load_investments.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:40,954 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:41,993 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:41,994 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:41,995 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:41,997 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 23 and queue default
2024-07-18 07:12:41,998 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:42,001 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:42,000 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:42,005 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:40.663298+00:00, run_end_date=2024-07-18 01:42:40.892500+00:00, run_duration=0.229202, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2757, pool=default_pool, queue=default, priority_weight=24, operator=PythonOperator, queued_dttm=2024-07-18 01:42:39.718948+00:00, queued_by_job_id=2569, pid=19599
2024-07-18 07:12:42,031 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:42,662 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:42,734 INFO - Running <TaskInstance: parent_dag.raw_load_investments.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:43,164 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:44,156 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:44,156 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:44,157 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:44,161 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 22 and queue default
2024-07-18 07:12:44,161 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:44,165 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:44,164 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_investments.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:44,169 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:42.834645+00:00, run_end_date=2024-07-18 01:42:43.071204+00:00, run_duration=0.236559, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2758, pool=default_pool, queue=default, priority_weight=23, operator=PythonOperator, queued_dttm=2024-07-18 01:42:41.996069+00:00, queued_by_job_id=2569, pid=19632
2024-07-18 07:12:44,195 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:44,818 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:44,902 INFO - Running <TaskInstance: parent_dag.raw_load_investments.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:45,524 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:45,937 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:45,938 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:45,938 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:45,940 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 21 and queue default
2024-07-18 07:12:45,941 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:45,946 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_investments.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:45,945 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:45,951 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_investments.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:44.995821+00:00, run_end_date=2024-07-18 01:42:45.451287+00:00, run_duration=0.455466, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2759, pool=default_pool, queue=default, priority_weight=22, operator=PythonOperator, queued_dttm=2024-07-18 01:42:44.157808+00:00, queued_by_job_id=2569, pid=19657
2024-07-18 07:12:45,974 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:46,700 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:46,803 INFO - Running <TaskInstance: parent_dag.raw_load_loans.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:47,343 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:48,207 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:48,207 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:48,208 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:48,214 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 20 and queue default
2024-07-18 07:12:48,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:48,221 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:48,225 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:48,236 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:46.917988+00:00, run_end_date=2024-07-18 01:42:47.201310+00:00, run_duration=0.283322, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2760, pool=default_pool, queue=default, priority_weight=21, operator=PythonOperator, queued_dttm=2024-07-18 01:42:45.939104+00:00, queued_by_job_id=2569, pid=19692
2024-07-18 07:12:48,271 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:48,982 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:49,056 INFO - Running <TaskInstance: parent_dag.raw_load_loans.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:49,493 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:49,799 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:49,799 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:49,799 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:49,801 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 19 and queue default
2024-07-18 07:12:49,802 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:49,804 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:49,804 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_loans.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:49,813 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:49.156205+00:00, run_end_date=2024-07-18 01:42:49.403453+00:00, run_duration=0.247248, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2761, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:42:48.209009+00:00, queued_by_job_id=2569, pid=19731
2024-07-18 07:12:49,836 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:50,469 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:50,541 INFO - Running <TaskInstance: parent_dag.raw_load_loans.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:51,643 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:52,036 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:52,036 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:52,036 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:52,038 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 18 and queue default
2024-07-18 07:12:52,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:52,043 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_loans.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:52,042 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:52,049 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_loans.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:50.654214+00:00, run_end_date=2024-07-18 01:42:51.568331+00:00, run_duration=0.914117, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2762, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:42:49.800466+00:00, queued_by_job_id=2569, pid=19768
2024-07-18 07:12:52,079 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:52,866 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:52,950 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:53,510 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:54,320 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:54,320 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:54,320 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:54,324 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 17 and queue default
2024-07-18 07:12:54,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:54,328 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:54,328 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:54,333 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:53.088705+00:00, run_end_date=2024-07-18 01:42:53.435393+00:00, run_duration=0.346688, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2763, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:42:52.037101+00:00, queued_by_job_id=2569, pid=19850
2024-07-18 07:12:54,360 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:54,985 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:55,067 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:55,454 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:56,106 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:56,107 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:56,108 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:56,113 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 16 and queue default
2024-07-18 07:12:56,113 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:56,117 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:56,116 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_mortgage_applications.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:56,123 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:55.169149+00:00, run_end_date=2024-07-18 01:42:55.400220+00:00, run_duration=0.231071, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2764, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:42:54.321634+00:00, queued_by_job_id=2569, pid=19893
2024-07-18 07:12:56,153 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:56,954 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:57,116 INFO - Running <TaskInstance: parent_dag.raw_load_mortgage_applications.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:58,143 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:12:58,392 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:58,393 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:12:58,393 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:12:58,397 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 15 and queue default
2024-07-18 07:12:58,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:58,400 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_mortgage_applications.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:12:58,400 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:12:58,406 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_mortgage_applications.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:57.308927+00:00, run_end_date=2024-07-18 01:42:58.036395+00:00, run_duration=0.727468, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2765, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:42:56.109691+00:00, queued_by_job_id=2569, pid=19986
2024-07-18 07:12:58,437 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:12:59,275 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:12:59,380 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:12:59,865 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:00,131 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:00,131 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:00,131 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:00,133 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 14 and queue default
2024-07-18 07:13:00,134 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:00,137 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:00,137 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:00,145 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:42:59.523860+00:00, run_end_date=2024-07-18 01:42:59.776709+00:00, run_duration=0.252849, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2766, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:42:58.394821+00:00, queued_by_job_id=2569, pid=20093
2024-07-18 07:13:00,169 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:00,829 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:00,915 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:01,317 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:01,317 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:01,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:01,319 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 13 and queue default
2024-07-18 07:13:01,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:01,323 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_online_banking.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:01,357 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:01,351 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:01,396 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:01,401 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:01.019291+00:00, run_end_date=2024-07-18 01:43:01.259327+00:00, run_duration=0.240036, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2767, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:43:00.132420+00:00, queued_by_job_id=2569, pid=20132
2024-07-18 07:13:01,963 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:02,039 INFO - Running <TaskInstance: parent_dag.raw_load_online_banking.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:02,969 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:03,344 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:03,345 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:03,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:03,352 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 12 and queue default
2024-07-18 07:13:03,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:03,359 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_online_banking.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:03,358 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:03,366 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_online_banking.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:02.167558+00:00, run_end_date=2024-07-18 01:43:02.863931+00:00, run_duration=0.696373, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2768, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:43:01.318169+00:00, queued_by_job_id=2569, pid=20151
2024-07-18 07:13:03,396 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:04,015 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:04,087 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:04,499 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:04,533 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:04,533 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:04,533 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:04,536 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 11 and queue default
2024-07-18 07:13:04,536 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:04,541 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:04,540 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:04,546 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:04.189397+00:00, run_end_date=2024-07-18 01:43:04.413678+00:00, run_duration=0.224281, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2769, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:43:03.347864+00:00, queued_by_job_id=2569, pid=20176
2024-07-18 07:13:04,573 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:05,207 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:05,318 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:05,797 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:06,415 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:06,415 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:06,415 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:06,417 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue default
2024-07-18 07:13:06,418 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:06,422 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:06,422 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_recurring_deposits.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:06,430 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:05.461962+00:00, run_end_date=2024-07-18 01:43:05.713155+00:00, run_duration=0.251193, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2770, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:43:04.534413+00:00, queued_by_job_id=2569, pid=20193
2024-07-18 07:13:06,457 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:07,176 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:07,249 INFO - Running <TaskInstance: parent_dag.raw_load_recurring_deposits.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:07,959 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:08,232 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:08,233 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:08,233 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:08,235 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default
2024-07-18 07:13:08,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:08,240 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_recurring_deposits.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:08,239 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:08,245 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_recurring_deposits.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:07.352028+00:00, run_end_date=2024-07-18 01:43:07.890203+00:00, run_duration=0.538175, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2771, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:43:06.416368+00:00, queued_by_job_id=2569, pid=20218
2024-07-18 07:13:08,272 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:08,932 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:09,008 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:09,460 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:10,368 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:10,369 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:10,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:10,375 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-07-18 07:13:10,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:10,378 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:10,378 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:10,383 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:09.130542+00:00, run_end_date=2024-07-18 01:43:09.395750+00:00, run_duration=0.265208, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2772, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:43:08.233949+00:00, queued_by_job_id=2569, pid=20244
2024-07-18 07:13:10,411 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:11,184 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:11,263 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:11,726 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:12,614 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:12,614 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:12,614 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:12,616 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-07-18 07:13:12,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:12,623 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:12,622 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_savings_goals.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:12,631 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:11.383398+00:00, run_end_date=2024-07-18 01:43:11.645367+00:00, run_duration=0.261969, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2773, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:43:10.372365+00:00, queued_by_job_id=2569, pid=20281
2024-07-18 07:13:12,660 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:13,298 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:13,381 INFO - Running <TaskInstance: parent_dag.raw_load_savings_goals.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:14,147 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:14,543 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:14,544 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:14,544 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:14,546 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-07-18 07:13:14,546 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:14,550 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_savings_goals.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:14,549 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:14,559 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_savings_goals.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:13.481469+00:00, run_end_date=2024-07-18 01:43:14.048251+00:00, run_duration=0.566782, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2774, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:43:12.615473+00:00, queued_by_job_id=2569, pid=20306
2024-07-18 07:13:14,587 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:15,322 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:15,406 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:15,902 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:16,563 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:16,564 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:16,564 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:16,566 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2024-07-18 07:13:16,567 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:16,572 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:16,572 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:16,578 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:15.527904+00:00, run_end_date=2024-07-18 01:43:15.784410+00:00, run_duration=0.256506, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2775, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:43:14.544989+00:00, queued_by_job_id=2569, pid=20332
2024-07-18 07:13:16,605 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:17,279 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:17,364 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:17,848 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:18,813 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:18,813 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:18,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:18,815 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2024-07-18 07:13:18,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:18,820 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:18,820 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_service_charges.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:18,826 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:17.493736+00:00, run_end_date=2024-07-18 01:43:17.758469+00:00, run_duration=0.264733, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2776, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:43:16.565047+00:00, queued_by_job_id=2569, pid=20367
2024-07-18 07:13:18,853 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:19,586 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:19,664 INFO - Running <TaskInstance: parent_dag.raw_load_service_charges.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:20,722 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:21,632 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:21,632 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:21,633 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:21,638 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:13:21,639 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:21,647 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_service_charges.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:21,654 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.create_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:21,656 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_service_charges.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:19.771916+00:00, run_end_date=2024-07-18 01:43:20.626621+00:00, run_duration=0.854705, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2777, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:43:18.814402+00:00, queued_by_job_id=2569, pid=20406
2024-07-18 07:13:21,731 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:22,553 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:22,642 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.create_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:23,187 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:23,373 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:23,373 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:23,374 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:23,376 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:13:23,377 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:23,380 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.create_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:23,379 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.tuncate_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:23,390 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.create_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:22.775877+00:00, run_end_date=2024-07-18 01:43:23.116234+00:00, run_duration=0.340357, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2778, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:43:21.635442+00:00, queued_by_job_id=2569, pid=20483
2024-07-18 07:13:23,424 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:24,268 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:24,372 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.tuncate_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:24,924 ERROR - Failed to execute task cannot pickle 'Connection' object.
Traceback (most recent call last):
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/executors/local_executor.py", line 135, in _execute_work_in_fork
    args.func(args)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 441, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 219, in _run_task_by_selected_method
    return _run_task_by_local_task_job(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/cli/commands/task_command.py", line 281, in _run_task_by_local_task_job
    ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
          ^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 201, in _execute
    self.handle_task_exit(return_code)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/jobs/local_task_job_runner.py", line 244, in handle_task_exit
    self.task_instance.schedule_downstream_tasks(max_tis_per_query=self.job.max_tis_per_query)
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3523, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 3473, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2550, in partial_subset
    dag.task_dict = {
                    ^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2551, in <dictcomp>
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/dag.py", line 2548, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 153, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/kali/Desktop/projects/git/bank_data_processing/myenv/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 1307, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 146, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/copy.py", line 161, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle 'Connection' object
2024-07-18 07:13:25,644 INFO - 1 tasks up for execution:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:25,644 INFO - DAG parent_dag has 0/16 running and queued tasks
2024-07-18 07:13:25,645 INFO - Setting the following tasks to queued state:
	<TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [scheduled]>
2024-07-18 07:13:25,647 INFO - Sending TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:13:25,647 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:25,651 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.tuncate_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:25,651 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'parent_dag', 'raw_load_transactions.insert_table', 'manual__2024-07-18T01:41:28.205554+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/raw_models/dag_parent.py']
2024-07-18 07:13:25,658 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.tuncate_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:24.494174+00:00, run_end_date=2024-07-18 01:43:24.843886+00:00, run_duration=0.349712, state=success, executor_state=failed, try_number=1, max_tries=1, job_id=2779, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:43:23.375022+00:00, queued_by_job_id=2569, pid=20544
2024-07-18 07:13:25,680 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/raw_models/dag_parent.py
2024-07-18 07:13:26,265 INFO - Using connection ID 'mysql_default' for task execution.
2024-07-18 07:13:26,337 INFO - Running <TaskInstance: parent_dag.raw_load_transactions.insert_table manual__2024-07-18T01:41:28.205554+00:00 [queued]> on host kali
2024-07-18 07:13:32,878 INFO - Marking run <DagRun parent_dag @ 2024-07-18 01:41:28.205554+00:00: manual__2024-07-18T01:41:28.205554+00:00, state:running, queued_at: 2024-07-18 01:41:28.266692+00:00. externally triggered: True> successful
2024-07-18 07:13:32,878 INFO - DagRun Finished: dag_id=parent_dag, execution_date=2024-07-18 01:41:28.205554+00:00, run_id=manual__2024-07-18T01:41:28.205554+00:00, run_start_date=2024-07-18 01:41:29.237506+00:00, run_end_date=2024-07-18 01:43:32.878804+00:00, run_duration=123.641298, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=c2dc310f9c774fb70b8256555b5d12ec
2024-07-18 07:13:32,904 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='parent_dag', task_id='raw_load_transactions.insert_table', run_id='manual__2024-07-18T01:41:28.205554+00:00', try_number=1, map_index=-1)
2024-07-18 07:13:32,907 INFO - TaskInstance Finished: dag_id=parent_dag, task_id=raw_load_transactions.insert_table, run_id=manual__2024-07-18T01:41:28.205554+00:00, map_index=-1, run_start_date=2024-07-18 01:43:26.441051+00:00, run_end_date=2024-07-18 01:43:32.523641+00:00, run_duration=6.08259, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2780, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:43:25.645820+00:00, queued_by_job_id=2569, pid=20583
2024-07-18 07:13:48,733 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-07-18 07:14:10,623 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:10,624 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:10,624 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:10,627 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 20 and queue default
2024-07-18 07:14:10,627 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:10,631 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_accounts_to_int_accounts', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:10,661 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:11,278 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_accounts_to_int_accounts manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:13,416 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:13,416 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:13,416 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:13,419 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 19 and queue default
2024-07-18 07:14:13,419 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:13,423 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_accounts_to_int_accounts', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:13,423 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_atms_to_int_atms', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:13,430 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_accounts_to_int_accounts, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:11.378724+00:00, run_end_date=2024-07-18 01:44:12.648310+00:00, run_duration=1.26959, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2781, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:44:10.625320+00:00, queued_by_job_id=2569, pid=21741
2024-07-18 07:14:13,454 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:14,117 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_atms_to_int_atms manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:14,894 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:14,895 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:14,895 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:14,898 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 18 and queue default
2024-07-18 07:14:14,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:14,901 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_atms_to_int_atms', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:14,901 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_bill_payments_to_int_bill_payments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:14,908 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_atms_to_int_atms, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:14.220956+00:00, run_end_date=2024-07-18 01:44:14.654263+00:00, run_duration=0.433307, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2782, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:44:13.417618+00:00, queued_by_job_id=2569, pid=21787
2024-07-18 07:14:14,934 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:15,574 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_bill_payments_to_int_bill_payments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:16,338 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:16,339 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:16,339 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:16,342 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 17 and queue default
2024-07-18 07:14:16,342 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:16,345 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_branches_to_int_branches', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:16,375 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:16,404 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_bill_payments_to_int_bill_payments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:16,409 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_bill_payments_to_int_bill_payments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:15.679180+00:00, run_end_date=2024-07-18 01:44:16.268594+00:00, run_duration=0.589414, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2783, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:44:14.896708+00:00, queued_by_job_id=2569, pid=21804
2024-07-18 07:14:16,927 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_branches_to_int_branches manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:17,452 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:17,452 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:17,452 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:17,454 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 16 and queue default
2024-07-18 07:14:17,454 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:17,457 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_branches_to_int_branches', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:17,457 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cards_to_int_cards', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:17,461 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_branches_to_int_branches, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:17.009416+00:00, run_end_date=2024-07-18 01:44:17.345336+00:00, run_duration=0.33592, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2784, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:44:16.340223+00:00, queued_by_job_id=2569, pid=21829
2024-07-18 07:14:17,479 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:18,049 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_cards_to_int_cards manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:19,665 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:19,665 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:19,666 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:19,667 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 15 and queue default
2024-07-18 07:14:19,668 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:19,672 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cards_to_int_cards', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:19,672 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_cheques_to_int_cheques', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:19,678 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cards_to_int_cards, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:18.151796+00:00, run_end_date=2024-07-18 01:44:18.982151+00:00, run_duration=0.830355, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2785, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:44:17.453320+00:00, queued_by_job_id=2569, pid=21847
2024-07-18 07:14:19,705 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:20,396 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_cheques_to_int_cheques manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:21,445 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:21,446 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:21,446 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:21,448 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 14 and queue default
2024-07-18 07:14:21,448 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:21,452 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_cheques_to_int_cheques', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:21,451 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_credit_scores_to_int_credit_scores', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:21,460 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_cheques_to_int_cheques, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:20.502755+00:00, run_end_date=2024-07-18 01:44:20.998538+00:00, run_duration=0.495783, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2786, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:44:19.666546+00:00, queued_by_job_id=2569, pid=21884
2024-07-18 07:14:21,485 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:22,164 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_credit_scores_to_int_credit_scores manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:23,599 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:23,600 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:23,600 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:23,602 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 13 and queue default
2024-07-18 07:14:23,603 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:23,610 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_credit_scores_to_int_credit_scores', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:23,610 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customer_support_to_int_customer_support', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:23,614 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_credit_scores_to_int_credit_scores, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:22.258936+00:00, run_end_date=2024-07-18 01:44:23.010727+00:00, run_duration=0.751791, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2787, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:44:21.446961+00:00, queued_by_job_id=2569, pid=21909
2024-07-18 07:14:23,647 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:24,389 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_customer_support_to_int_customer_support manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:26,065 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:26,065 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:26,066 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:26,073 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 12 and queue default
2024-07-18 07:14:26,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:26,077 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customer_support_to_int_customer_support', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:26,077 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_customers_to_int_customers', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:26,083 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customer_support_to_int_customer_support, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:24.491683+00:00, run_end_date=2024-07-18 01:44:24.997891+00:00, run_duration=0.506208, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2788, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:44:23.601066+00:00, queued_by_job_id=2569, pid=21958
2024-07-18 07:14:26,114 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:26,983 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_customers_to_int_customers manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:28,740 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:28,740 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:28,740 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:28,747 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 11 and queue default
2024-07-18 07:14:28,747 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:28,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_customers_to_int_customers', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:28,754 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_employees_to_int_employees', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:28,762 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_customers_to_int_customers, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:27.079457+00:00, run_end_date=2024-07-18 01:44:27.817063+00:00, run_duration=0.737606, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2789, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:44:26.068120+00:00, queued_by_job_id=2569, pid=22051
2024-07-18 07:14:28,803 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:29,694 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_employees_to_int_employees manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:31,012 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:31,012 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:31,013 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:31,015 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 10 and queue default
2024-07-18 07:14:31,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:31,021 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_employees_to_int_employees', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:31,021 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_fixed_deposits_to_int_fixed_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:31,027 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_employees_to_int_employees, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:29.862861+00:00, run_end_date=2024-07-18 01:44:30.725573+00:00, run_duration=0.862712, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2790, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:44:28.741430+00:00, queued_by_job_id=2569, pid=22122
2024-07-18 07:14:31,063 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:31,911 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_fixed_deposits_to_int_fixed_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:32,778 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:32,778 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:32,779 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:32,784 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 9 and queue default
2024-07-18 07:14:32,785 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:32,791 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_insurance_to_int_insurance', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:32,838 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:32,893 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_fixed_deposits_to_int_fixed_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:32,905 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_fixed_deposits_to_int_fixed_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:32.016369+00:00, run_end_date=2024-07-18 01:44:32.649113+00:00, run_duration=0.632744, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2791, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:44:31.013886+00:00, queued_by_job_id=2569, pid=22224
2024-07-18 07:14:33,815 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_insurance_to_int_insurance manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:35,042 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:35,042 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:35,043 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:35,045 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 8 and queue default
2024-07-18 07:14:35,046 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:35,049 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_insurance_to_int_insurance', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:35,049 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_investments_to_int_investments', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:35,057 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_insurance_to_int_insurance, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:33.954577+00:00, run_end_date=2024-07-18 01:44:34.868290+00:00, run_duration=0.913713, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2792, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:44:32.780244+00:00, queued_by_job_id=2569, pid=22303
2024-07-18 07:14:35,091 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:35,811 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_investments_to_int_investments manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:36,719 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:36,720 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:36,720 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:36,722 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 7 and queue default
2024-07-18 07:14:36,722 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:36,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_investments_to_int_investments', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:36,725 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_loans_to_int_loans', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:36,731 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_investments_to_int_investments, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:35.912254+00:00, run_end_date=2024-07-18 01:44:36.352798+00:00, run_duration=0.440544, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2793, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:44:35.043859+00:00, queued_by_job_id=2569, pid=22338
2024-07-18 07:14:36,756 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:37,364 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_loans_to_int_loans manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:38,610 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:38,610 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:38,611 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:38,613 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 6 and queue default
2024-07-18 07:14:38,613 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:38,617 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_loans_to_int_loans', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:38,617 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_mortgage_applications_to_int_mortgage_applications', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:38,621 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_loans_to_int_loans, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:37.470553+00:00, run_end_date=2024-07-18 01:44:38.057718+00:00, run_duration=0.587165, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2794, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:44:36.721169+00:00, queued_by_job_id=2569, pid=22363
2024-07-18 07:14:38,642 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:39,186 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_mortgage_applications_to_int_mortgage_applications manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:40,852 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:40,852 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:40,853 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:40,855 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 5 and queue default
2024-07-18 07:14:40,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:40,861 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_mortgage_applications_to_int_mortgage_applications', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:40,860 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_online_banking_to_int_online_banking', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:40,868 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_mortgage_applications_to_int_mortgage_applications, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:39.264191+00:00, run_end_date=2024-07-18 01:44:39.736951+00:00, run_duration=0.47276, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2795, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:44:38.611653+00:00, queued_by_job_id=2569, pid=22388
2024-07-18 07:14:40,892 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:41,434 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_online_banking_to_int_online_banking manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:42,886 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:42,887 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:42,887 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:42,890 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 4 and queue default
2024-07-18 07:14:42,890 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:42,895 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_online_banking_to_int_online_banking', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:42,895 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_recurring_deposits_to_int_recurring_deposits', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:42,901 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_online_banking_to_int_online_banking, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:41.520558+00:00, run_end_date=2024-07-18 01:44:41.983612+00:00, run_duration=0.463054, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2796, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:44:40.853821+00:00, queued_by_job_id=2569, pid=22413
2024-07-18 07:14:42,927 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:43,554 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_recurring_deposits_to_int_recurring_deposits manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:45,116 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:45,117 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:45,117 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:45,120 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:14:45,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:45,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_recurring_deposits_to_int_recurring_deposits', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:45,123 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_savings_goals_to_int_savings_goals', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:45,127 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_recurring_deposits_to_int_recurring_deposits, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:43.640474+00:00, run_end_date=2024-07-18 01:44:44.072862+00:00, run_duration=0.432388, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2797, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:44:42.888134+00:00, queued_by_job_id=2569, pid=22451
2024-07-18 07:14:45,151 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:45,687 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_savings_goals_to_int_savings_goals manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:46,869 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:46,869 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:46,869 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:46,871 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:14:46,872 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:46,874 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_savings_goals_to_int_savings_goals', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:46,874 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_service_charges_to_int_service_charges', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:46,878 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_savings_goals_to_int_savings_goals, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:45.770921+00:00, run_end_date=2024-07-18 01:44:46.218692+00:00, run_duration=0.447771, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2798, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:44:45.118646+00:00, queued_by_job_id=2569, pid=22476
2024-07-18 07:14:46,903 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:47,447 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_service_charges_to_int_service_charges manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:49,053 INFO - 1 tasks up for execution:
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:49,053 INFO - DAG mysql_data_transformation has 0/16 running and queued tasks
2024-07-18 07:14:49,053 INFO - Setting the following tasks to queued state:
	<TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [scheduled]>
2024-07-18 07:14:49,055 INFO - Sending TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:14:49,056 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:49,058 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_service_charges_to_int_service_charges', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:49,058 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'mysql_data_transformation', 'transform_and_load_transactions_to_int_transactions', 'manual__2024-07-18T01:37:00.986102+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/int_models/cleaning_script.py']
2024-07-18 07:14:49,064 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_service_charges_to_int_service_charges, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:47.525513+00:00, run_end_date=2024-07-18 01:44:48.107835+00:00, run_duration=0.582322, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2799, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:44:46.870402+00:00, queued_by_job_id=2569, pid=22502
2024-07-18 07:14:49,087 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/int_models/cleaning_script.py
2024-07-18 07:14:49,672 INFO - Running <TaskInstance: mysql_data_transformation.transform_and_load_transactions_to_int_transactions manual__2024-07-18T01:37:00.986102+00:00 [queued]> on host kali
2024-07-18 07:14:51,923 INFO - Marking run <DagRun mysql_data_transformation @ 2024-07-18 01:37:00.986102+00:00: manual__2024-07-18T01:37:00.986102+00:00, state:running, queued_at: 2024-07-18 01:44:10.030762+00:00. externally triggered: True> successful
2024-07-18 07:14:51,923 INFO - DagRun Finished: dag_id=mysql_data_transformation, execution_date=2024-07-18 01:37:00.986102+00:00, run_id=manual__2024-07-18T01:37:00.986102+00:00, run_start_date=2024-07-18 01:44:10.558087+00:00, run_end_date=2024-07-18 01:44:51.923414+00:00, run_duration=41.365327, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=3e31518e1a895412bcceab372924eeb7
2024-07-18 07:14:51,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='mysql_data_transformation', task_id='transform_and_load_transactions_to_int_transactions', run_id='manual__2024-07-18T01:37:00.986102+00:00', try_number=2, map_index=-1)
2024-07-18 07:14:51,938 INFO - TaskInstance Finished: dag_id=mysql_data_transformation, task_id=transform_and_load_transactions_to_int_transactions, run_id=manual__2024-07-18T01:37:00.986102+00:00, map_index=-1, run_start_date=2024-07-18 01:44:49.750229+00:00, run_end_date=2024-07-18 01:44:51.786080+00:00, run_duration=2.03585, state=success, executor_state=success, try_number=2, max_tries=2, job_id=2800, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:44:49.054557+00:00, queued_by_job_id=2569, pid=22527
2024-07-18 07:15:09,780 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:09,781 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:09,781 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:09,783 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_accounts_to_dlt_accounts', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 20 and queue default
2024-07-18 07:15:09,784 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_accounts_to_dlt_accounts', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:09,786 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_accounts_to_dlt_accounts', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:09,822 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:10,660 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_accounts_to_dlt_accounts manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:11,992 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:11,993 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:11,993 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:11,996 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_atms_to_dlt_atms', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 19 and queue default
2024-07-18 07:15:11,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_atms_to_dlt_atms', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:12,000 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_accounts_to_dlt_accounts', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:11,999 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_atms_to_dlt_atms', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:12,005 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_accounts_to_dlt_accounts, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:10.750230+00:00, run_end_date=2024-07-18 01:45:11.842863+00:00, run_duration=1.09263, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2801, pool=default_pool, queue=default, priority_weight=20, operator=PythonOperator, queued_dttm=2024-07-18 01:45:09.781912+00:00, queued_by_job_id=2569, pid=23005
2024-07-18 07:15:12,032 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:12,720 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_atms_to_dlt_atms manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:13,316 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:13,316 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:13,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:13,319 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_bill_payments_to_dlt_bill_payments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 18 and queue default
2024-07-18 07:15:13,319 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_bill_payments_to_dlt_bill_payments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:13,321 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_bill_payments_to_dlt_bill_payments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:13,354 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:13,386 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_atms_to_dlt_atms', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:13,393 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_atms_to_dlt_atms, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:12.857131+00:00, run_end_date=2024-07-18 01:45:13.276776+00:00, run_duration=0.419645, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2802, pool=default_pool, queue=default, priority_weight=19, operator=PythonOperator, queued_dttm=2024-07-18 01:45:11.994366+00:00, queued_by_job_id=2569, pid=23031
2024-07-18 07:15:14,038 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_bill_payments_to_dlt_bill_payments manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:15,320 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:15,320 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:15,321 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:15,326 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_branches_to_dlt_branches', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 17 and queue default
2024-07-18 07:15:15,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_branches_to_dlt_branches', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:15,329 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_bill_payments_to_dlt_bill_payments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:15,329 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_branches_to_dlt_branches', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:15,335 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_bill_payments_to_dlt_bill_payments, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:14.177368+00:00, run_end_date=2024-07-18 01:45:14.748609+00:00, run_duration=0.571241, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2803, pool=default_pool, queue=default, priority_weight=18, operator=PythonOperator, queued_dttm=2024-07-18 01:45:13.317590+00:00, queued_by_job_id=2569, pid=23066
2024-07-18 07:15:15,358 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:15,897 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_branches_to_dlt_branches manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:16,460 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:16,460 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:16,462 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:16,466 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cards_to_dlt_cards', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 16 and queue default
2024-07-18 07:15:16,466 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cards_to_dlt_cards', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:16,469 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_branches_to_dlt_branches', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:16,469 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cards_to_dlt_cards', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:16,478 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_branches_to_dlt_branches, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:15.998975+00:00, run_end_date=2024-07-18 01:45:16.329103+00:00, run_duration=0.330128, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2804, pool=default_pool, queue=default, priority_weight=17, operator=PythonOperator, queued_dttm=2024-07-18 01:45:15.322136+00:00, queued_by_job_id=2569, pid=23085
2024-07-18 07:15:16,508 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:17,197 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_cards_to_dlt_cards manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:18,354 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:18,355 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:18,355 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:18,357 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cheques_to_dlt_cheques', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 15 and queue default
2024-07-18 07:15:18,357 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cheques_to_dlt_cheques', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:18,360 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cards_to_dlt_cards', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:18,360 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_cheques_to_dlt_cheques', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:18,365 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_cards_to_dlt_cards, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:17.295694+00:00, run_end_date=2024-07-18 01:45:17.827466+00:00, run_duration=0.531772, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2805, pool=default_pool, queue=default, priority_weight=16, operator=PythonOperator, queued_dttm=2024-07-18 01:45:16.463419+00:00, queued_by_job_id=2569, pid=23112
2024-07-18 07:15:18,390 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:19,187 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_cheques_to_dlt_cheques manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:20,533 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:20,533 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:20,534 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:20,535 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_credit_scores_to_dlt_credit_scores', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 14 and queue default
2024-07-18 07:15:20,536 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_credit_scores_to_dlt_credit_scores', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:20,541 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_cheques_to_dlt_cheques', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:20,540 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_credit_scores_to_dlt_credit_scores', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:20,548 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_cheques_to_dlt_cheques, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:19.281816+00:00, run_end_date=2024-07-18 01:45:19.614938+00:00, run_duration=0.333122, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2806, pool=default_pool, queue=default, priority_weight=15, operator=PythonOperator, queued_dttm=2024-07-18 01:45:18.355748+00:00, queued_by_job_id=2569, pid=23155
2024-07-18 07:15:20,573 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:21,312 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_credit_scores_to_dlt_credit_scores manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:22,356 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:22,357 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:22,357 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:22,359 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customer_support_to_dlt_customer_support', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 13 and queue default
2024-07-18 07:15:22,359 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customer_support_to_dlt_customer_support', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:22,362 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_credit_scores_to_dlt_credit_scores', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:22,362 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customer_support_to_dlt_customer_support', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:22,367 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_credit_scores_to_dlt_credit_scores, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:21.427173+00:00, run_end_date=2024-07-18 01:45:21.969613+00:00, run_duration=0.54244, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2807, pool=default_pool, queue=default, priority_weight=14, operator=PythonOperator, queued_dttm=2024-07-18 01:45:20.534563+00:00, queued_by_job_id=2569, pid=23196
2024-07-18 07:15:22,392 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:23,075 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_customer_support_to_dlt_customer_support manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:23,826 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:23,827 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:23,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:23,829 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customers_to_dlt_customers', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 12 and queue default
2024-07-18 07:15:23,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customers_to_dlt_customers', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:23,833 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customer_support_to_dlt_customer_support', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:23,832 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_customers_to_dlt_customers', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:23,838 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_customer_support_to_dlt_customer_support, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:23.164628+00:00, run_end_date=2024-07-18 01:45:23.523704+00:00, run_duration=0.359076, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2808, pool=default_pool, queue=default, priority_weight=13, operator=PythonOperator, queued_dttm=2024-07-18 01:45:22.358004+00:00, queued_by_job_id=2569, pid=23232
2024-07-18 07:15:23,859 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:24,334 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_customers_to_dlt_customers manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:25,346 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:25,350 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:25,350 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:25,353 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_employees_to_dlt_employees', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 11 and queue default
2024-07-18 07:15:25,353 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_employees_to_dlt_employees', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:25,358 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_customers_to_dlt_customers', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:25,369 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_customers_to_dlt_customers, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:24.397578+00:00, run_end_date=2024-07-18 01:45:24.946205+00:00, run_duration=0.548627, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2809, pool=default_pool, queue=default, priority_weight=12, operator=PythonOperator, queued_dttm=2024-07-18 01:45:23.827910+00:00, queued_by_job_id=2569, pid=23256
2024-07-18 07:15:25,362 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_employees_to_dlt_employees', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:25,413 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:25,964 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_employees_to_dlt_employees manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:26,495 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:26,496 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:26,496 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:26,498 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 10 and queue default
2024-07-18 07:15:26,498 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:26,501 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:26,531 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:26,553 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_employees_to_dlt_employees', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:26,556 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_employees_to_dlt_employees, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:26.038706+00:00, run_end_date=2024-07-18 01:45:26.440270+00:00, run_duration=0.401564, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2810, pool=default_pool, queue=default, priority_weight=11, operator=PythonOperator, queued_dttm=2024-07-18 01:45:25.351530+00:00, queued_by_job_id=2569, pid=23297
2024-07-18 07:15:27,048 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:28,515 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:28,516 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:28,516 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:28,519 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_insurance_to_dlt_insurance', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 9 and queue default
2024-07-18 07:15:28,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_insurance_to_dlt_insurance', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:28,523 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:28,523 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_insurance_to_dlt_insurance', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:28,530 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_fixed_deposits_to_dlt_fixed_deposits, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:27.135265+00:00, run_end_date=2024-07-18 01:45:27.510808+00:00, run_duration=0.375543, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2811, pool=default_pool, queue=default, priority_weight=10, operator=PythonOperator, queued_dttm=2024-07-18 01:45:26.496895+00:00, queued_by_job_id=2569, pid=23344
2024-07-18 07:15:28,557 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:29,137 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_insurance_to_dlt_insurance manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:29,658 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:29,658 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:29,658 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:29,661 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_investments_to_dlt_investments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 8 and queue default
2024-07-18 07:15:29,661 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_investments_to_dlt_investments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:29,666 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_insurance_to_dlt_insurance', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:29,666 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_investments_to_dlt_investments', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:29,670 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_insurance_to_dlt_insurance, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:29.222042+00:00, run_end_date=2024-07-18 01:45:29.555703+00:00, run_duration=0.333661, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2812, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2024-07-18 01:45:28.517654+00:00, queued_by_job_id=2569, pid=23409
2024-07-18 07:15:29,690 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:30,227 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_investments_to_dlt_investments manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:30,762 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:30,762 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:30,762 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:30,764 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_loans_to_dlt_loans', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 7 and queue default
2024-07-18 07:15:30,765 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_loans_to_dlt_loans', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:30,768 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_loans_to_dlt_loans', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:30,798 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:30,850 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_investments_to_dlt_investments', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:30,859 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_investments_to_dlt_investments, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:30.304172+00:00, run_end_date=2024-07-18 01:45:30.651369+00:00, run_duration=0.347197, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2813, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2024-07-18 01:45:29.659572+00:00, queued_by_job_id=2569, pid=23426
2024-07-18 07:15:31,481 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_loans_to_dlt_loans manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:32,524 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:32,524 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:32,525 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:32,531 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default
2024-07-18 07:15:32,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:32,534 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_loans_to_dlt_loans', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:32,535 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:32,540 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_loans_to_dlt_loans, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:31.622634+00:00, run_end_date=2024-07-18 01:45:32.103593+00:00, run_duration=0.480959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2814, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2024-07-18 01:45:30.763462+00:00, queued_by_job_id=2569, pid=23475
2024-07-18 07:15:32,581 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:33,455 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:34,334 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:34,335 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:34,335 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:34,341 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_online_banking_to_dlt_online_banking', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default
2024-07-18 07:15:34,342 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_online_banking_to_dlt_online_banking', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:34,345 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:34,345 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_online_banking_to_dlt_online_banking', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:34,354 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_mortgage_applications_to_dlt_mortgage_applications, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:33.640397+00:00, run_end_date=2024-07-18 01:45:34.050187+00:00, run_duration=0.40979, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2815, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2024-07-18 01:45:32.525491+00:00, queued_by_job_id=2569, pid=23572
2024-07-18 07:15:34,381 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:35,052 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_online_banking_to_dlt_online_banking manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:36,583 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:36,584 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:36,584 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:36,589 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2024-07-18 07:15:36,590 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:36,603 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:36,610 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_online_banking_to_dlt_online_banking', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:36,637 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_online_banking_to_dlt_online_banking, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:35.168641+00:00, run_end_date=2024-07-18 01:45:35.607691+00:00, run_duration=0.43905, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2816, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2024-07-18 01:45:34.338046+00:00, queued_by_job_id=2569, pid=23657
2024-07-18 07:15:36,676 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:37,399 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:38,833 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:38,834 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:38,834 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:38,838 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_savings_goals_to_dlt_savings_goals', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2024-07-18 07:15:38,839 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_savings_goals_to_dlt_savings_goals', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:38,842 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:38,841 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_savings_goals_to_dlt_savings_goals', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:38,846 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_recurring_deposits_to_dlt_recurring_deposits, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:37.517612+00:00, run_end_date=2024-07-18 01:45:37.895771+00:00, run_duration=0.378159, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2817, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2024-07-18 01:45:36.585446+00:00, queued_by_job_id=2569, pid=23696
2024-07-18 07:15:38,875 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:39,560 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_savings_goals_to_dlt_savings_goals manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:41,031 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:41,031 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:41,032 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:41,033 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_service_charges_to_dlt_service_charges', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2024-07-18 07:15:41,034 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_service_charges_to_dlt_service_charges', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:41,037 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_savings_goals_to_dlt_savings_goals', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:41,037 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_service_charges_to_dlt_service_charges', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:41,042 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_savings_goals_to_dlt_savings_goals, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:39.642595+00:00, run_end_date=2024-07-18 01:45:40.081467+00:00, run_duration=0.438872, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2818, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2024-07-18 01:45:38.835720+00:00, queued_by_job_id=2569, pid=23721
2024-07-18 07:15:41,064 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:41,542 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_service_charges_to_dlt_service_charges manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:42,172 INFO - 1 tasks up for execution:
	<TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:42,172 INFO - DAG dag_incremental_script has 0/16 running and queued tasks
2024-07-18 07:15:42,173 INFO - Setting the following tasks to queued state:
	<TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [scheduled]>
2024-07-18 07:15:42,176 INFO - Sending TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_transactions_to_dlt_transactions', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2024-07-18 07:15:42,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_transactions_to_dlt_transactions', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:42,181 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_service_charges_to_dlt_service_charges', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:42,180 INFO - QueuedLocalWorker running ['airflow', 'tasks', 'run', 'dag_incremental_script', 'transform_and_load_int_transactions_to_dlt_transactions', 'manual__2024-07-18T01:45:08.918618+00:00', '--local', '--subdir', 'DAGS_FOLDER/models/dlt_models/incremental_script.py']
2024-07-18 07:15:42,187 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_service_charges_to_dlt_service_charges, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:41.618096+00:00, run_end_date=2024-07-18 01:45:42.000352+00:00, run_duration=0.382256, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2819, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2024-07-18 01:45:41.032483+00:00, queued_by_job_id=2569, pid=23746
2024-07-18 07:15:42,222 INFO - Filling up the DagBag from //home/kali/Desktop/projects/git/bank_data_processing/dags/models/dlt_models/incremental_script.py
2024-07-18 07:15:43,081 INFO - Running <TaskInstance: dag_incremental_script.transform_and_load_int_transactions_to_dlt_transactions manual__2024-07-18T01:45:08.918618+00:00 [queued]> on host kali
2024-07-18 07:15:45,437 INFO - Marking run <DagRun dag_incremental_script @ 2024-07-18 01:45:08.918618+00:00: manual__2024-07-18T01:45:08.918618+00:00, state:running, queued_at: 2024-07-18 01:45:08.947679+00:00. externally triggered: True> successful
2024-07-18 07:15:45,437 INFO - DagRun Finished: dag_id=dag_incremental_script, execution_date=2024-07-18 01:45:08.918618+00:00, run_id=manual__2024-07-18T01:45:08.918618+00:00, run_start_date=2024-07-18 01:45:09.732984+00:00, run_end_date=2024-07-18 01:45:45.437656+00:00, run_duration=35.704672, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-07-17 00:00:00+00:00, data_interval_end=2024-07-18 00:00:00+00:00, dag_hash=a2e952aa7ce10146e64886eb9de60f00
2024-07-18 07:15:45,449 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dag_incremental_script', task_id='transform_and_load_int_transactions_to_dlt_transactions', run_id='manual__2024-07-18T01:45:08.918618+00:00', try_number=1, map_index=-1)
2024-07-18 07:15:45,453 INFO - TaskInstance Finished: dag_id=dag_incremental_script, task_id=transform_and_load_int_transactions_to_dlt_transactions, run_id=manual__2024-07-18T01:45:08.918618+00:00, map_index=-1, run_start_date=2024-07-18 01:45:43.207600+00:00, run_end_date=2024-07-18 01:45:44.467663+00:00, run_duration=1.26006, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2820, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-07-18 01:45:42.174008+00:00, queued_by_job_id=2569, pid=23843
2024-07-18 07:18:48,804 INFO - Adopting or resetting orphaned tasks for active dag runs
